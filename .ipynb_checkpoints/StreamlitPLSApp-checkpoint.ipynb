{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c5ee5-3a22-4c27-bdc8-e2a27ce3a164",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import streamlit as st\n",
    "\n",
    "# Placeholder function for processing the uploaded documents\n",
    "def process_documents(uploaded_files):\n",
    "    # Implement the document processing logic here\n",
    "    return \"Placeholder processed output\"\n",
    "\n",
    "# Placeholder function for postprocessing into PPT template\n",
    "def postprocess_to_ppt(processed_output, selected_template):\n",
    "    # Implement the postprocessing logic here\n",
    "    return \"Placeholder PPT content\"\n",
    "\n",
    "def main():\n",
    "    st.title(\"Document Processing and PPT Generation App\")\n",
    "\n",
    "    # Step 1: Document Upload\n",
    "    st.header(\"Step 1: Upload Documents\")\n",
    "    uploaded_files = st.file_uploader(\"Upload your documents\", accept_multiple_files=True, type=[\"pdf\"])\n",
    "    process_button = st.button(\"Process Documents\")\n",
    "    \n",
    "    if process_button:\n",
    "        if uploaded_files:\n",
    "            # Call the processing function on the uploaded documents\n",
    "            processed_output = process_documents(uploaded_files)\n",
    "            st.header(\"Processed Output\")\n",
    "            st.write(processed_output)\n",
    "            \n",
    "            # Store the processed output in session state\n",
    "            st.session_state.processed_output = processed_output\n",
    "\n",
    "    # Step 2: PPT Template Selection\n",
    "    st.header(\"Step 2: Select PPT Template\")\n",
    "    # Add radio buttons for template selection here\n",
    "    selected_template = st.radio(\"Select PPT Template\", options=[\"Template 1\", \"Template 2\", \"Template 3\"])\n",
    "    generate_ppt_button = st.button(\"Generate PPT\")\n",
    "\n",
    "    if generate_ppt_button:\n",
    "        # Retrieve the processed output from session state\n",
    "        processed_output = st.session_state.processed_output\n",
    "\n",
    "        if processed_output:\n",
    "            # Call the postprocessing function to generate PPT content\n",
    "            ppt_content = postprocess_to_ppt(processed_output, selected_template)\n",
    "            # Display the PPT content using st.markdown or st.write\n",
    "            st.markdown(ppt_content, unsafe_allow_html=True)\n",
    "\n",
    "            # Store the PPT content in session state\n",
    "            st.session_state.ppt_content = ppt_content\n",
    "\n",
    "    # Step 3: PPT Download\n",
    "    if \"ppt_content\" in st.session_state:\n",
    "        ppt_content = st.session_state.ppt_content\n",
    "        # Add a download button to download the PPT\n",
    "        st.download_button(\"Download PPT\", data=ppt_content, file_name=\"output.pptx\", mime=\"application/vnd.openxmlformats-officedocument.presentationml.presentation\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb68d0d-a408-4037-b90d-57ea63be573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app8.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app8.py\n",
    "#this is working smooth and perfect in the streamlit app. only thing left is the API call now\n",
    "import os\n",
    "import streamlit as st\n",
    "from pptx import Presentation\n",
    "from datetime import datetime  # Import the 'datetime' class from the 'datetime' module\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Placeholder function for processing the uploaded documents\n",
    "def process_documents(uploaded_files, tense, pls_grade):\n",
    "    # Implement the document processing logic here\n",
    "    # For demonstration purposes, we'll create a placeholder replacements dictionary\n",
    "    replacements = {\n",
    "        \"<Title>\": GPTAPIcall(\"title\", tense, pls_grade),\n",
    "        \"<Subtitle>\": GPTAPIcall(\"subtitle\", tense, pls_grade),\n",
    "        \"<Introduction>\": GPTAPIcall(\"introduction\", tense, pls_grade),\n",
    "        \"<Phonetics>\": GPTAPIcall(\"phonetics\", tense, pls_grade),\n",
    "        \"<Key takeaway>\": GPTAPIcall(\"keytakeaway\", tense, pls_grade),\n",
    "        \"<Results>\": GPTAPIcall(\"results\", tense, pls_grade),\n",
    "        \"<Intro summary>\": GPTAPIcall(\"conclusion\", tense, pls_grade)\n",
    "    }\n",
    "    return replacements\n",
    "\n",
    "# Placeholder function for GPT API call\n",
    "def GPTAPIcall(key, tense, pls_grade):\n",
    "    # Placeholder logic to generate values based on the key, tense, and PLS grade\n",
    "    # Replace this with your actual GPT API call or any other processing logic\n",
    "    # Convert tense strings\n",
    "    tense_mapping = {\"on-going\": \"present\", \"completed\": \"past\", \"upcoming\": \"future\"}\n",
    "    tense = tense_mapping.get(tense, tense)\n",
    "\n",
    "    # Placeholder value for the key with the tense and PLS grade\n",
    "    value = f\"Placeholder value for {key} (Tense: {tense}, PLS Grade: {pls_grade})\"\n",
    "    return value\n",
    "\n",
    "# Placeholder function for postprocessing into PPT template\n",
    "def postprocess_to_ppt(replacements, selected_template):\n",
    "    # Implement the postprocessing logic here\n",
    "    # For demonstration purposes, we'll load a presentation object and copy the text from replacements dictionary\n",
    "    \n",
    "    #rootdir = os.path.realpath('./')\n",
    "    rootdir = \"/home/cdsw/experimentation_project1/PLS_project\"\n",
    "    #selected_template = \"PLS_PPT_Template\"\n",
    "    ppt_file = f\"{selected_template}.pptx\"\n",
    "    prs = Presentation(os.path.join(rootdir, ppt_file))\n",
    "\n",
    "    for slide in prs.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if shape.has_text_frame:\n",
    "                text_frame = shape.text_frame\n",
    "                for paragraph in text_frame.paragraphs:\n",
    "                    for run in paragraph.runs:\n",
    "                        for placeholder, new_text in replacements.items():\n",
    "                            if run.text == placeholder:\n",
    "                                # Preserve formatting of the first run in the paragraph\n",
    "                                first_run = paragraph.runs[0]\n",
    "                                font_size = first_run.font.size\n",
    "                                font_name = first_run.font.name\n",
    "                                font_bold = first_run.font.bold\n",
    "                                font_italic = first_run.font.italic\n",
    "\n",
    "                                # Check if font color is explicitly defined\n",
    "                                if first_run.font.color.type == \"rgb\":\n",
    "                                    font_color = first_run.font.color.rgb\n",
    "                                else:\n",
    "                                    font_color = None\n",
    "\n",
    "                                # Replace text while preserving formatting\n",
    "                                run.text = new_text\n",
    "\n",
    "                                # Apply preserved formatting to the entire paragraph\n",
    "                                for run in paragraph.runs:\n",
    "                                    run.font.size = font_size\n",
    "                                    run.font.name = font_name\n",
    "                                    run.font.bold = font_bold\n",
    "                                    run.font.italic = font_italic\n",
    "                                    if font_color:\n",
    "                                        run.font.color.rgb = font_color\n",
    "\n",
    "    # Return the modified presentation object\n",
    "    return prs\n",
    "\n",
    "def main():\n",
    "    #Custom icons\n",
    "    img = Image.open('/home/cdsw/experimentation_project1/PLS_project/pfizer.png')\n",
    "    st.set_page_config(page_title = 'Pfizer PLS Generator', page_icon = img)\n",
    "    \n",
    "    st.title(\"RCT Document Processing and PLS Generation App\")\n",
    "\n",
    "    # Step 1: Document Upload\n",
    "    st.header(\"Step 1: Upload Documents\")\n",
    "    uploaded_files = st.file_uploader(\"Upload Clinical trial documents\", accept_multiple_files=True, type=[\"pdf\"])\n",
    "    \n",
    "    # Step 2: User Inputs\n",
    "    st.header(\"Step 2: User Inputs\")\n",
    "    # Set default values for radio button and slider\n",
    "    default_tense = \"completed\"\n",
    "    default_pls_grade = 10\n",
    "\n",
    "    # Radio button for tense selection\n",
    "    tense = st.radio(\"Current status of the study\", options=[\"on-going\", \"completed\", \"upcoming\"], key=\"tense\", index=[\"on-going\", \"completed\", \"upcoming\"].index(default_tense))\n",
    "\n",
    "    # Slider for PLS grade selection\n",
    "    pls_grade = st.slider(\"Select the Grade of Plain language summary\", min_value=1, max_value=10, step=1, key=\"pls_grade\", value=default_pls_grade)\n",
    "\n",
    "    process_button = st.button(\"Process Documents\")\n",
    "    \n",
    "    if process_button:\n",
    "        if uploaded_files:\n",
    "            # Retrieve user inputs\n",
    "            tense = st.session_state.tense\n",
    "            pls_grade = st.session_state.pls_grade\n",
    "\n",
    "            # Call the processing function on the uploaded documents with user inputs\n",
    "            replacements = process_documents(uploaded_files, tense, pls_grade)\n",
    "            st.header(\"Processed Output\")\n",
    "            st.write(replacements)\n",
    "            \n",
    "            # Store the replacements dictionary in session state\n",
    "            st.session_state.replacements = replacements\n",
    "\n",
    "    # Step 3: PPT Template Selection and Download\n",
    "    st.header(\"Step 3: Select PLS PPT Template and Download\")\n",
    "    # Add radio buttons for template selection here\n",
    "    \n",
    "    default_template = \"PLS_PPT_Template\"\n",
    "    selected_template = st.radio(\"Select PPT Template\", options=[\"PLS_PPT_Template\", \"Template2\", \"Template3\"], index=[\"PLS_PPT_Template\", \"Template2\", \"Template3\"].index(default_template))\n",
    "    generate_ppt_button = st.button(\"Generate PLS\")\n",
    "\n",
    "    if generate_ppt_button:\n",
    "        # Retrieve the replacements dictionary from session state\n",
    "        replacements = st.session_state.replacements\n",
    "\n",
    "        if replacements:\n",
    "            with st.spinner('Generating awesome slides for you...⏳'):\n",
    "                # Call the postprocessing function to generate PPT content\n",
    "                ppt_content = postprocess_to_ppt(replacements, selected_template)\n",
    "\n",
    "                # Display the PPT content using st.markdown or st.write\n",
    "                st.markdown(ppt_content, unsafe_allow_html=True)\n",
    "\n",
    "                # Store the PPT content in session state\n",
    "                st.session_state.ppt_content = ppt_content\n",
    "            \n",
    "            \n",
    "     # Step 3: PPT Download\n",
    "    if \"ppt_content\" in st.session_state:\n",
    "        ppt_content = st.session_state.ppt_content\n",
    "             \n",
    "        # Save the modified presentation object to a temporary file\n",
    "        #ppt_output_file = f\"PLS_{replacements['title']}_{datetime.now().strftime('%Y%m%d%H%M%S')}.pptx\"\n",
    "        ppt_output_file = \"PLS_output.pptx\"\n",
    "        #ppt_content.save(ppt_output_file)\n",
    "        \n",
    "        # save presentation as binary output\n",
    "        binary_output = BytesIO()\n",
    "        ppt_content.save(binary_output)\n",
    "        \n",
    "        # display success message and download button\n",
    "        st.success('The slides have been generated! :tada:')\n",
    "        \n",
    "        # Provide the download link for the generated PPT\n",
    "        st.download_button(\"Download PLS\", data=binary_output.getvalue(), file_name=ppt_output_file, mime=\"application/vnd.openxmlformats-officedocument.presentationml.presentation\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13ef54fe-1a55-4c85-b557-fc80fa99c8dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "#justwriting this code for debuggin the above code - not using webapp. this works well\n",
    "from pptx import Presentation\n",
    "import os\n",
    "rootdir = os.path.realpath('./')\n",
    "selected_template = \"PLS_PPT_Template\"\n",
    "ppt_file = f\"{selected_template}.pptx\"\n",
    "prs = Presentation(os.path.join(rootdir, ppt_file))\n",
    "\n",
    "replacements = {\n",
    "        \"<Title>\": 'GPTAPIcall(\"title\", tense, pls_grade)',\n",
    "        \"<Subtitle>\": 'GPTAPIcall(\"subtitle\", tense, pls_grade)',\n",
    "        \"<Introduction>\": 'GPTAPIcall(\"introduction\", tense, pls_grade)',\n",
    "        \"<Phonetics>\": 'GPTAPIcall(\"phonetics\", tense, pls_grade)',\n",
    "        \"<Key takeaway>\": 'GPTAPIcall(\"keytakeaway\", tense, pls_grade)',\n",
    "        \"<Results>\": 'GPTAPIcall(\"results\", tense, pls_grade)',\n",
    "        \"<Intro summary>\": 'GPTAPIcall(\"conclusion\", tense, pls_grade)'\n",
    "    }\n",
    "\n",
    "for slide in prs.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if shape.has_text_frame:\n",
    "                text_frame = shape.text_frame\n",
    "                for paragraph in text_frame.paragraphs:\n",
    "                    for run in paragraph.runs:\n",
    "                        for placeholder, new_text in replacements.items():\n",
    "                            if run.text == placeholder:\n",
    "                                # Preserve formatting of the first run in the paragraph\n",
    "                                first_run = paragraph.runs[0]\n",
    "                                font_size = first_run.font.size\n",
    "                                font_name = first_run.font.name\n",
    "                                font_bold = first_run.font.bold\n",
    "                                font_italic = first_run.font.italic\n",
    "\n",
    "                                # Check if font color is explicitly defined\n",
    "                                if first_run.font.color.type == \"rgb\":\n",
    "                                    font_color = first_run.font.color.rgb\n",
    "                                else:\n",
    "                                    font_color = None\n",
    "\n",
    "                                # Replace text while preserving formatting\n",
    "                                run.text = new_text\n",
    "\n",
    "                                # Apply preserved formatting to the entire paragraph\n",
    "                                for run in paragraph.runs:\n",
    "                                    run.font.size = font_size\n",
    "                                    run.font.name = font_name\n",
    "                                    run.font.bold = font_bold\n",
    "                                    run.font.italic = font_italic\n",
    "                                    if font_color:\n",
    "                                        run.font.color.rgb = font_color\n",
    "\n",
    "\n",
    "prs.save('updated_presentation.pptx')\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27562b31-e765-421d-a8ba-6a5998028fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cdsw/experimentation_project1/PLS_project/PLS_PPT_Template.pptx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "rootdir = os.path.realpath('./')\n",
    "selected_template = \"PLS_PPT_Template\"\n",
    "ppt_file = f\"{selected_template}.pptx\"\n",
    "print(os.path.join(rootdir, ppt_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3134eb73-fb68-4c6d-8325-b864cb7f4559",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cdsw/experimentation_project1/PLS_project/PLS_PPT_Template.pptx\n"
     ]
    }
   ],
   "source": [
    "rootdir = \"/home/cdsw/experimentation_project1/PLS_project\"\n",
    "selected_template = \"PLS_PPT_Template\"\n",
    "ppt_file = f\"{selected_template}.pptx\"\n",
    "print(os.path.join(rootdir, ppt_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b98ee-9e95-4ef8-83de-8aaf1e65733c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7e4995d-7b41-4f7d-bd42-a74666628e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app8.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app8.py\n",
    "#enhancing the above perfect code with GPT API call -- working smooth for title/intro/kt/results section; don't touch it\n",
    "import os\n",
    "import urllib\n",
    "import base64\n",
    "import json\n",
    "import streamlit as st\n",
    "from pptx import Presentation\n",
    "from datetime import datetime  # Import the 'datetime' class from the 'datetime' module\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from shakti3_index import llama_listvectorkeyword_index\n",
    "\n",
    "rootdir = \"/home/cdsw/experimentation_project1/PLS_project\"\n",
    "datadir = \"/home/cdsw/experimentation_project1/PLS_project/data\"\n",
    "\n",
    "#function to read prompt from corresponding text file\n",
    "def prompt(file):\n",
    "    with open(file) as f:\n",
    "        return f.read()\n",
    "    \n",
    "#function to save a file\n",
    "def save_uploadedfile(uploaded_file):\n",
    "     with open(os.path.join(datadir, uploaded_file.name),\"wb\") as f:\n",
    "         f.write(uploaded_file.getbuffer())\n",
    "     return st.success(f\"\"\"Saved File:{uploaded_file.name} to directory\"\"\")\n",
    "\n",
    "@st.cache_data\n",
    "#function to display the PDF of a given file \n",
    "def displayPDF(file):\n",
    "    # Opening file from file path\n",
    "    with open(file, \"rb\") as f:\n",
    "        base64_pdf = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "    # Embedding PDF in HTML\n",
    "    pdf_display = F'<iframe src=\"data:application/pdf;base64,{base64_pdf}\" width=\"300\" height=\"200\" type=\"application/pdf\"></iframe>'\n",
    "\n",
    "    # Displaying File\n",
    "    st.markdown(pdf_display, unsafe_allow_html=True)\n",
    "\n",
    "# Placeholder function for processing the uploaded documents\n",
    "def process_documents(uploaded_file, tense, pls_grade):\n",
    "    # Implement the document processing logic here\n",
    "    \n",
    "    tense_mapping = {\"on-going\": \"present\", \"completed\": \"past\", \"upcoming\": \"future\"}\n",
    "    tense = tense_mapping.get(tense, tense)\n",
    "    \n",
    "#     summary_query = f\"\"\"With the above instructions and the clinical trial document provided, write a detailed APLS with mentioned sections in {tense}, comprehendable by a grade {pls_grade} student. Provide the response in JSON format with section names as keys. Enclose each key in JSON in angular brackets for example '<Title>'. Enclose each value in JSON in double quotes. Make sure to complete the JSON with opening and closing flower brackets.\\n\"\"\"\n",
    "#     replacements = json.loads(llama_listvectorkeyword_index(uploaded_file , (prompt(os.path.join(rootdir, 'apls_persona_2606.txt')) + \"\\n\\n\\n\" + summary_query)))\n",
    "    \n",
    "     \n",
    "    title_query = f\"Strictly following the above instructions and the clinical trial document provided, write the content of 'Title' section of the APLS in {tense}, comprehendable by a grade {pls_grade} student. Do not violate the section-wise instructions provided in any case. The content should be strictly inferred from the clinical trial document provided only and not any other sources.\\n\"\n",
    "    intro_query = f\"Strictly following the above instructions and the clinical trial document provided, write the content of 'Introduction' section of the APLS in {tense}, comprehendable by a grade {pls_grade} student. Do not violate the section-wise instructions provided in any case. The content should be strictly inferred from the clinical trial document provided only and not any other sources.\\n\"\n",
    "    keytakeaway_query = f\"Strictly following the above instructions and the clinical trial document provided, write the content of 'Key Takeaway' section of the APLS in {tense}, comprehendable by a grade {pls_grade} student. Do not violate the section-wise instructions provided in any case. The content should be strictly inferred from the clinical trial document provided only and not any other sources.\\n\"\n",
    "    results_query = f\"Strictly following the above instructions and the clinical trial document provided, write the content of 'Results' section of the APLS in {tense}, comprehendable by a grade {pls_grade} student. Do not violate the section-wise instructions provided in any case. The content should be strictly inferred from the clinical trial document provided only and not any other sources.\\n\"\n",
    "    \n",
    "    # For demonstration purposes, we'll create a placeholder replacements dictionary\n",
    "    replacements = {\n",
    "        \"<Title>\": llama_listvectorkeyword_index(uploaded_file, prompt(os.path.join(rootdir, 'apls_persona_2606.txt')) + \"\\n\\n\\n\" + title_query),\n",
    "    #     \"<Subtitle>\": GPTAPIcall(\"subtitle\", tense, pls_grade),\n",
    "        \"<Introduction>\": llama_listvectorkeyword_index(uploaded_file, prompt(os.path.join(rootdir, 'apls_persona_2606.txt')) + \"\\n\\n\\n\" + intro_query),\n",
    "    #     \"<Phonetics>\": GPTAPIcall(\"phonetics\", tense, pls_grade),\n",
    "        \"<Key takeaway>\": llama_listvectorkeyword_index(uploaded_file, prompt(os.path.join(rootdir, 'apls_persona_2606.txt')) + \"\\n\\n\\n\" + keytakeaway_query),\n",
    "        \"<Results>\": llama_listvectorkeyword_index(uploaded_file, prompt(os.path.join(rootdir, 'apls_persona_2606.txt')) + \"\\n\\n\\n\" + results_query)\n",
    "    #     \"<Intro summary>\": GPTAPIcall(\"conclusion\", tense, pls_grade)\n",
    "    }\n",
    "    return replacements\n",
    "\n",
    "# Placeholder function for GPT API call\n",
    "def GPTAPIcall(key, tense, pls_grade):\n",
    "    # Placeholder logic to generate values based on the key, tense, and PLS grade\n",
    "    # Replace this with your actual GPT API call or any other processing logic\n",
    "    # Convert tense strings\n",
    "    tense_mapping = {\"on-going\": \"present\", \"completed\": \"past\", \"upcoming\": \"future\"}\n",
    "    tense = tense_mapping.get(tense, tense)\n",
    "\n",
    "    # Placeholder value for the key with the tense and PLS grade\n",
    "    value = f\"Placeholder value for {key} (Tense: {tense}, PLS Grade: {pls_grade})\"\n",
    "    return value\n",
    "\n",
    "# Placeholder function for postprocessing into PPT template\n",
    "def postprocess_to_ppt(replacements, selected_template):\n",
    "    # Implement the postprocessing logic here\n",
    "    # For demonstration purposes, we'll load a presentation object and copy the text from replacements dictionary\n",
    "    \n",
    "    #rootdir = os.path.realpath('./')\n",
    "    \n",
    "    #selected_template = \"PLS_PPT_Template\"\n",
    "    ppt_file = f\"{selected_template}.pptx\"\n",
    "    prs = Presentation(os.path.join(rootdir, ppt_file))\n",
    "\n",
    "    for slide in prs.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if shape.has_text_frame:\n",
    "                text_frame = shape.text_frame\n",
    "                for paragraph in text_frame.paragraphs:\n",
    "                    for run in paragraph.runs:\n",
    "                        for placeholder, new_text in replacements.items():\n",
    "                            if run.text == placeholder:\n",
    "                                # Preserve formatting of the first run in the paragraph\n",
    "                                first_run = paragraph.runs[0]\n",
    "                                font_size = first_run.font.size\n",
    "                                font_name = first_run.font.name\n",
    "                                font_bold = first_run.font.bold\n",
    "                                font_italic = first_run.font.italic\n",
    "\n",
    "                                # Check if font color is explicitly defined\n",
    "                                if first_run.font.color.type == \"rgb\":\n",
    "                                    font_color = first_run.font.color.rgb\n",
    "                                else:\n",
    "                                    font_color = None\n",
    "\n",
    "                                # Replace text while preserving formatting\n",
    "                                run.text = new_text\n",
    "\n",
    "                                # Apply preserved formatting to the entire paragraph\n",
    "                                for run in paragraph.runs:\n",
    "                                    run.font.size = font_size\n",
    "                                    run.font.name = font_name\n",
    "                                    run.font.bold = font_bold\n",
    "                                    run.font.italic = font_italic\n",
    "                                    if font_color:\n",
    "                                        run.font.color.rgb = font_color\n",
    "\n",
    "    # Return the modified presentation object\n",
    "    return prs\n",
    "\n",
    "def main():\n",
    "    #Custom icons\n",
    "    img = Image.open(os.path.join(rootdir, 'pfizer.png'))\n",
    "    st.set_page_config(page_title = 'Pfizer PLS Generator', page_icon = img)\n",
    "    \n",
    "    st.title(\"RCT Document Processing and PLS Generation App\")\n",
    "    with st.sidebar:\n",
    "        # Step 1: Document Upload\n",
    "        st.header(\"Step 1: Upload Documents\")\n",
    "        uploaded_file = st.file_uploader(\"Upload Clinical trial document\", accept_multiple_files=False, type=[\"pdf\"])\n",
    "\n",
    "        # Step 2: User Inputs\n",
    "        st.header(\"Step 2: User Inputs\")\n",
    "        # Set default values for radio button and slider\n",
    "        default_tense = \"completed\"\n",
    "        default_pls_grade = 5\n",
    "\n",
    "        # Radio button for tense selection\n",
    "        tense = st.radio(\"Current status of the study\", options=[\"on-going\", \"completed\", \"upcoming\"], key=\"tense\", index=[\"on-going\", \"completed\", \"upcoming\"].index(default_tense))\n",
    "        st.write('<style>div.row-widget.stRadio > div{flex-direction:row;}</style>', unsafe_allow_html=True)\n",
    "        \n",
    "        # Slider for PLS grade selection\n",
    "        pls_grade = st.slider(\"Select the Grade of Plain language summary\", min_value=1, max_value=10, step=1, key=\"pls_grade\", value=default_pls_grade)\n",
    "\n",
    "        process_button = st.button(\"Process Documents\")\n",
    "    \n",
    "    if process_button:\n",
    "        if uploaded_file:\n",
    "            # Retrieve user inputs\n",
    "            tense = st.session_state.tense\n",
    "            pls_grade = st.session_state.pls_grade\n",
    "            \n",
    "            col1, col2 = st.columns([1,2])\n",
    "            with col1:\n",
    "                input_file = save_uploadedfile(uploaded_file)\n",
    "                pdf_file = os.path.join(datadir, uploaded_file.name) #rootdir + \"/\" + uploaded_file.name\n",
    "                pdf_view = displayPDF(pdf_file)\n",
    "            with col2:\n",
    "                with st.spinner(text='Processing trial doc...⏳'):\n",
    "            \n",
    "                    # Call the processing function on the uploaded documents with user inputs\n",
    "                    replacements = process_documents(pdf_file, tense, pls_grade)\n",
    "                    st.success(\"Processed Output\")\n",
    "                    st.write(replacements)\n",
    "            \n",
    "            # Store the replacements dictionary in session state\n",
    "            st.session_state.replacements = replacements\n",
    "\n",
    "    # Step 3: PPT Template Selection and Download\n",
    "    st.header(\"Step 3: Select PLS PPT Template and Download\")\n",
    "    \n",
    "    # Add radio buttons for template selection here    \n",
    "    default_template = \"PLS_PPT_Template\"\n",
    "    selected_template = st.radio(\"Select PPT Template\", options=[\"PLS_PPT_Template\", \"Template2\", \"Template3\"], index=[\"PLS_PPT_Template\", \"Template2\", \"Template3\"].index(default_template))\n",
    "    st.write('<style>div.row-widget.stRadio > div{flex-direction:row;}</style>', unsafe_allow_html=True)\n",
    "    \n",
    "    generate_ppt_button = st.button(\"Generate PLS\")\n",
    "\n",
    "    if generate_ppt_button:\n",
    "        # Retrieve the replacements dictionary from session state\n",
    "        replacements = st.session_state.replacements\n",
    "\n",
    "        if replacements:\n",
    "            with st.spinner('Generating awesome slides for you...⏳'):\n",
    "                # Call the postprocessing function to generate PPT content\n",
    "                ppt_content = postprocess_to_ppt(replacements, selected_template)\n",
    "\n",
    "                # Display the PPT content using st.markdown or st.write\n",
    "                st.markdown(ppt_content, unsafe_allow_html=True)\n",
    "\n",
    "                # Store the PPT content in session state\n",
    "                st.session_state.ppt_content = ppt_content\n",
    "            \n",
    "            \n",
    "     # Step 3: PPT Download\n",
    "    if \"ppt_content\" in st.session_state:\n",
    "        ppt_content = st.session_state.ppt_content\n",
    "             \n",
    "        # Save the modified presentation object to a temporary file\n",
    "        #ppt_output_file = f\"PLS_{replacements['title']}_{datetime.now().strftime('%Y%m%d%H%M%S')}.pptx\"\n",
    "        ppt_output_file = \"PLS_output.pptx\"\n",
    "        #ppt_content.save(ppt_output_file)\n",
    "        \n",
    "        # save presentation as binary output\n",
    "        binary_output = BytesIO()\n",
    "        ppt_content.save(binary_output)\n",
    "        \n",
    "        # display success message and download button\n",
    "        st.success('The slides have been generated! :tada:')\n",
    "        \n",
    "        # Provide the download link for the generated PPT\n",
    "        st.download_button(\"Download PLS\", data=binary_output.getvalue(), file_name=ppt_output_file, mime=\"application/vnd.openxmlformats-officedocument.presentationml.presentation\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deffc579-9406-4d52-b6f1-66035ee585f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f9b0977-c8b2-4953-9bdc-ed3a260214e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app8.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app8.py\n",
    "#enhance the GPT API call function here..and put couple of banner/logo -- do not touch\n",
    "import os\n",
    "import urllib\n",
    "import base64\n",
    "import json\n",
    "import streamlit as st\n",
    "from pptx import Presentation\n",
    "from datetime import datetime  # Import the 'datetime' class from the 'datetime' module\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from shakti3_index import llama_listvectorkeyword_index\n",
    "\n",
    "rootdir = \"/home/cdsw/experimentation_project1/PLS_project\"\n",
    "datadir = \"/home/cdsw/experimentation_project1/PLS_project/data\"\n",
    "\n",
    "#function to set background image\n",
    "def set_bg_hack(main_bg):\n",
    "    '''\n",
    "    A function to unpack an image from root folder and set as bg.\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    The background.\n",
    "    '''\n",
    "    # set bg name\n",
    "    main_bg_ext = \"png\"\n",
    "        \n",
    "    st.markdown(\n",
    "         f\"\"\"\n",
    "         <style>\n",
    "         .stApp {{\n",
    "             background: url(data:image/{main_bg_ext};base64,{base64.b64encode(open(main_bg, \"rb\").read()).decode()});\n",
    "             background-size: cover\n",
    "         }}\n",
    "         </style>\n",
    "         \"\"\",\n",
    "         unsafe_allow_html=True\n",
    "     )\n",
    "\n",
    "#function to read prompt from corresponding text file\n",
    "def prompt(file):\n",
    "    with open(file) as f:\n",
    "        return f.read()\n",
    "    \n",
    "#function to save a file\n",
    "def save_uploadedfile(uploaded_file):\n",
    "     with open(os.path.join(datadir, uploaded_file.name),\"wb\") as f:\n",
    "         f.write(uploaded_file.getbuffer())\n",
    "     return st.success(f\"\"\"Saved File:{uploaded_file.name} to directory\"\"\")\n",
    "\n",
    "@st.cache_data\n",
    "#function to display the PDF of a given file \n",
    "def displayPDF(file):\n",
    "    # Opening file from file path\n",
    "    with open(file, \"rb\") as f:\n",
    "        base64_pdf = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "    # Embedding PDF in HTML\n",
    "    pdf_display = F'<iframe src=\"data:application/pdf;base64,{base64_pdf}\" width=\"300\" height=\"200\" type=\"application/pdf\"></iframe>'\n",
    "\n",
    "    # Displaying File\n",
    "    st.markdown(pdf_display, unsafe_allow_html=True)\n",
    "\n",
    "# Placeholder function for processing the uploaded documents\n",
    "def process_documents(uploaded_file, tense, pls_grade):\n",
    "    # Implement the document processing logic here\n",
    "    \n",
    "    # tense_mapping = {\"on-going\": \"present\", \"completed\": \"past\", \"upcoming\": \"future\"}\n",
    "    # tense = tense_mapping.get(tense, tense)\n",
    "    \n",
    "#     summary_query = f\"\"\"With the above instructions and the clinical trial document provided, write a detailed APLS with mentioned sections in {tense}, comprehendable by a grade {pls_grade} student. Provide the response in JSON format with section names as keys. Enclose each key in JSON in angular brackets for example '<Title>'. Enclose each value in JSON in double quotes. Make sure to complete the JSON with opening and closing flower brackets.\\n\"\"\"\n",
    "#     replacements = json.loads(llama_listvectorkeyword_index(uploaded_file , (prompt(os.path.join(rootdir, 'apls_persona_2606.txt')) + \"\\n\\n\\n\" + summary_query)))\n",
    "         \n",
    "#     title_query = f\"Strictly following the above instructions and the clinical trial document provided, write the content of 'Title' section of the APLS in {tense}, comprehendable by a grade {pls_grade} student. Do not violate the section-wise instructions provided in any case. The content should be strictly inferred from the clinical trial document provided only and not any other sources.\\n\"\n",
    "#     intro_query = f\"Strictly following the above instructions and the clinical trial document provided, write the content of 'Introduction' section of the APLS in {tense}, comprehendable by a grade {pls_grade} student. Do not violate the section-wise instructions provided in any case. The content should be strictly inferred from the clinical trial document provided only and not any other sources.\\n\"\n",
    "#     keytakeaway_query = f\"Strictly following the above instructions and the clinical trial document provided, write the content of 'Key Takeaway' section of the APLS in {tense}, comprehendable by a grade {pls_grade} student. Do not violate the section-wise instructions provided in any case. The content should be strictly inferred from the clinical trial document provided only and not any other sources.\\n\"\n",
    "#     results_query = f\"Strictly following the above instructions and the clinical trial document provided, write the content of 'Results' section of the APLS in {tense}, comprehendable by a grade {pls_grade} student. Do not violate the section-wise instructions provided in any case. The content should be strictly inferred from the clinical trial document provided only and not any other sources.\\n\"\n",
    "    \n",
    "#     # For demonstration purposes, we'll create a placeholder replacements dictionary\n",
    "#     replacements = {\n",
    "#         \"<Title>\": llama_listvectorkeyword_index(uploaded_file, prompt(os.path.join(rootdir, 'apls_persona_2606.txt')) + \"\\n\\n\\n\" + title_query),\n",
    "#     #     \"<Subtitle>\": GPTAPIcall(\"subtitle\", tense, pls_grade),\n",
    "#         \"<Introduction>\": llama_listvectorkeyword_index(uploaded_file, prompt(os.path.join(rootdir, 'apls_persona_2606.txt')) + \"\\n\\n\\n\" + intro_query),\n",
    "#     #     \"<Phonetics>\": GPTAPIcall(\"phonetics\", tense, pls_grade),\n",
    "#         \"<Key takeaway>\": llama_listvectorkeyword_index(uploaded_file, prompt(os.path.join(rootdir, 'apls_persona_2606.txt')) + \"\\n\\n\\n\" + keytakeaway_query),\n",
    "#         \"<Results>\": llama_listvectorkeyword_index(uploaded_file, prompt(os.path.join(rootdir, 'apls_persona_2606.txt')) + \"\\n\\n\\n\" + results_query)\n",
    "#     #     \"<Intro summary>\": GPTAPIcall(\"conclusion\", tense, pls_grade)\n",
    "#     }\n",
    "\n",
    "    replacements = {\n",
    "        \"<Title>\": GPTAPIcall(uploaded_file, \"'Title'\", tense, pls_grade),\n",
    "    #     \"<Subtitle>\": GPTAPIcall(uploaded_file, \"subtitle\", tense, pls_grade),\n",
    "    #    \"<Introduction>\": GPTAPIcall(uploaded_file, \"'Introduction'\", tense, pls_grade),\n",
    "    #     \"<Phonetics>\": GPTAPIcall(uploaded_file, \"phonetics\", tense, pls_grade),\n",
    "    #    \"<Key takeaway>\": GPTAPIcall(uploaded_file, \"'Key Takeaway'\", tense, pls_grade),\n",
    "    #    \"<Results>\": GPTAPIcall(uploaded_file, \"'Results'\", tense, pls_grade)\n",
    "    #     \"<Intro summary>\": GPTAPIcall(uploaded_file, \"conclusion\", tense, pls_grade)\n",
    "    }\n",
    "\n",
    "    return replacements\n",
    "\n",
    "# Placeholder function for GPT API call\n",
    "def GPTAPIcall(uploaded_file, key, tense, pls_grade):\n",
    "    # Placeholder logic to generate values based on the key, tense, and PLS grade\n",
    "    # Replace this with your actual GPT API call or any other processing logic\n",
    "    # Convert tense strings\n",
    "    tense_mapping = {\"on-going\": \"present\", \"completed\": \"past\", \"upcoming\": \"future\"}\n",
    "    tense = tense_mapping.get(tense, tense)\n",
    "\n",
    "    # Placeholder value for the key with the tense and PLS grade\n",
    "    #value = f\"Placeholder value for {key} (Tense: {tense}, PLS Grade: {pls_grade})\"\n",
    "    query = f\"Strictly following the above instructions and the clinical trial document provided, write the content of {key} section of the APLS in {tense}, comprehendable by a grade {pls_grade} student. Do not violate the section-wise instructions provided in any case. The content should be strictly inferred from the clinical trial document provided only and not any other sources.\\n\"\n",
    "    \n",
    "    return llama_listvectorkeyword_index(uploaded_file, prompt(os.path.join(rootdir, 'apls_persona_2606.txt')) + \"\\n\\n\\n\" + query)\n",
    "\n",
    "# Placeholder function for postprocessing into PPT template\n",
    "def postprocess_to_ppt(replacements, selected_template):\n",
    "    # Implement the postprocessing logic here\n",
    "    # For demonstration purposes, we'll load a presentation object and copy the text from replacements dictionary\n",
    "    \n",
    "    #rootdir = os.path.realpath('./')\n",
    "    \n",
    "    #selected_template = \"PLS_PPT_Template\"\n",
    "    ppt_file = f\"{selected_template}.pptx\"\n",
    "    prs = Presentation(os.path.join(rootdir, ppt_file))\n",
    "\n",
    "    for slide in prs.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if shape.has_text_frame:\n",
    "                text_frame = shape.text_frame\n",
    "                for paragraph in text_frame.paragraphs:\n",
    "                    for run in paragraph.runs:\n",
    "                        for placeholder, new_text in replacements.items():\n",
    "                            if run.text == placeholder:\n",
    "                                # Preserve formatting of the first run in the paragraph\n",
    "                                first_run = paragraph.runs[0]\n",
    "                                font_size = first_run.font.size\n",
    "                                font_name = first_run.font.name\n",
    "                                font_bold = first_run.font.bold\n",
    "                                font_italic = first_run.font.italic\n",
    "\n",
    "                                # Check if font color is explicitly defined\n",
    "                                if first_run.font.color.type == \"rgb\":\n",
    "                                    font_color = first_run.font.color.rgb\n",
    "                                else:\n",
    "                                    font_color = None\n",
    "\n",
    "                                # Replace text while preserving formatting\n",
    "                                run.text = new_text\n",
    "\n",
    "                                # Apply preserved formatting to the entire paragraph\n",
    "                                for run in paragraph.runs:\n",
    "                                    run.font.size = font_size\n",
    "                                    run.font.name = font_name\n",
    "                                    run.font.bold = font_bold\n",
    "                                    run.font.italic = font_italic\n",
    "                                    if font_color:\n",
    "                                        run.font.color.rgb = font_color\n",
    "\n",
    "    # Return the modified presentation object\n",
    "    return prs\n",
    "\n",
    "def main():\n",
    "    \n",
    "    #Page icons n tab name on browser tab\n",
    "    img = Image.open(os.path.join(rootdir, 'pfizer.png'))\n",
    "    st.set_page_config(page_title = 'Pfizer PLS Generator', page_icon = img)\n",
    "    \n",
    "    #hide padding above before title and footer\n",
    "    # st.markdown(f\"\"\" <style>\n",
    "    # #root > div:nth-child(1) > div > div > div > div > section > div {padding-top: 0rem;}\n",
    "    # #MainMenu {visibility: hidden;}\n",
    "    # footer {visibility: hidden;}\n",
    "    # header {visibility: hidden;}\n",
    "    # </style> \"\"\", unsafe_allow_html=True)\n",
    "    \n",
    "    #set bg image cover\n",
    "    #set_bg_hack(os.path.join(rootdir, 'pfizer-bg.png'))\n",
    "    \n",
    "    #setting banner image\n",
    "    st.image(Image.open(os.path.join(rootdir, 'Pfizer-AI.jpg')))\n",
    "    \n",
    "    #setting title\n",
    "    #st.header(\"IQVIA PLS Generator\")\n",
    "    \n",
    "    #setting input components on sidebar\n",
    "    with st.sidebar:\n",
    "        st.image(Image.open(os.path.join(rootdir, 'iqvia-pls-generator.png')))\n",
    "        # Step 1: Document Upload\n",
    "        st.subheader(\"Step 1: Upload Clinical trial document\")\n",
    "        uploaded_file = st.file_uploader(\"Upload document\", accept_multiple_files=False, type=[\"pdf\"])\n",
    "\n",
    "        # Step 2: User Inputs\n",
    "        st.subheader(\"Step 2: Define the tone and Grade of PLS\")\n",
    "        # Set default values for radio button and slider\n",
    "        default_tense = \"completed\"\n",
    "        default_pls_grade = 5\n",
    "\n",
    "        # Radio button for tense selection\n",
    "        tense = st.radio(\"Current status of the study\", options=[\"on-going\", \"completed\", \"upcoming\"], key=\"tense\", index=[\"on-going\", \"completed\", \"upcoming\"].index(default_tense))\n",
    "        st.write('<style>div.row-widget.stRadio > div{flex-direction:row;}</style>', unsafe_allow_html=True)\n",
    "        \n",
    "        # Slider for PLS grade selection\n",
    "        pls_grade = st.slider(\"Select the Health Literacy Grade Reading level\", min_value=1, max_value=10, step=1, key=\"pls_grade\", value=default_pls_grade)\n",
    "\n",
    "        process_button = st.button(\"Process Documents\")\n",
    "    \n",
    "    if process_button:\n",
    "        if uploaded_file:\n",
    "            # Retrieve user inputs\n",
    "            tense = st.session_state.tense\n",
    "            pls_grade = st.session_state.pls_grade\n",
    "            \n",
    "            col1, col2 = st.columns([1,2])\n",
    "            with col1:\n",
    "                input_file = save_uploadedfile(uploaded_file)\n",
    "                pdf_file = os.path.join(datadir, uploaded_file.name) #rootdir + \"/\" + uploaded_file.name\n",
    "                pdf_view = displayPDF(pdf_file)\n",
    "            with col2:\n",
    "                with st.spinner(text='Processing trial doc...⏳'):\n",
    "            \n",
    "                    # Call the processing function on the uploaded documents with user inputs\n",
    "                    replacements = process_documents(pdf_file, tense, pls_grade)\n",
    "                    st.success(\"Processed Output\")\n",
    "                    st.write(replacements)\n",
    "            \n",
    "            # Store the replacements dictionary in session state\n",
    "            st.session_state.replacements = replacements\n",
    "\n",
    "    # Step 3: PPT Template Selection and Download\n",
    "    st.subheader(\"Step 3: Select PLS PPT Template and Download\")\n",
    "    \n",
    "    # Add radio buttons for template selection here    \n",
    "    default_template = \"PLS_PPT_Template\"\n",
    "    selected_template = st.radio(\"Select PPT Template\", options=[\"PLS_PPT_Template\", \"Template2\", \"Template3\"], index=[\"PLS_PPT_Template\", \"Template2\", \"Template3\"].index(default_template))\n",
    "    st.write('<style>div.row-widget.stRadio > div{flex-direction:row;}</style>', unsafe_allow_html=True)\n",
    "    \n",
    "    generate_ppt_button = st.button(\"Generate PLS\")\n",
    "\n",
    "    if generate_ppt_button:\n",
    "        # Retrieve the replacements dictionary from session state\n",
    "        replacements = st.session_state.replacements\n",
    "\n",
    "        if replacements:\n",
    "            with st.spinner('Generating awesome slides for you...⏳'):\n",
    "                # Call the postprocessing function to generate PPT content\n",
    "                ppt_content = postprocess_to_ppt(replacements, selected_template)\n",
    "\n",
    "                # Display the PPT content using st.markdown or st.write\n",
    "                #st.markdown(ppt_content, unsafe_allow_html=True)\n",
    "                st.markdown(list(replacements.keys()))\n",
    "\n",
    "                # Store the PPT content in session state\n",
    "                st.session_state.ppt_content = ppt_content\n",
    "            \n",
    "            \n",
    "                 # Step 4: PPT Download\n",
    "                if \"ppt_content\" in st.session_state:\n",
    "                    ppt_content = st.session_state.ppt_content\n",
    "                    #replacements = st.session_state.replacements\n",
    "                    \n",
    "                    # Save the modified presentation object to a temporary file\n",
    "                    #ppt_output_file = f\"PLS_{replacements['<Title>']}_{datetime.now().strftime('%Y%m%d%H%M%S')}.pptx\"                    \n",
    "                    ppt_output_file = \"PLS_output.pptx\"\n",
    "                    #ppt_content.save(ppt_output_file)\n",
    "\n",
    "                    # save presentation as binary output\n",
    "                    binary_output = BytesIO()\n",
    "                    ppt_content.save(binary_output)\n",
    "\n",
    "                    # display success message and download button\n",
    "                    st.success(':tada: The PLS template has been filled with above sections ')\n",
    "\n",
    "                    # Provide the download link for the generated PPT\n",
    "                    st.download_button(\"Download PLS\", data=binary_output.getvalue(), file_name=ppt_output_file, mime=\"application/vnd.openxmlformats-officedocument.presentationml.presentation\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f52df597-1be8-47f4-8f1a-2eb3afcbc082",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLS_20230704074221.pptx\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime \n",
    "print( f\"PLS_{datetime.now().strftime('%Y%m%d%H%M%S')}.pptx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c28e2c52-f4f9-4ef7-963d-e176c54173b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app8.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app8.py\n",
    "#implemented all 3 ppt templates (streaming didnt work)-- baselined version - 6Jul -2:30pm - dont touch\n",
    "import os\n",
    "import urllib\n",
    "import base64\n",
    "import json\n",
    "import streamlit as st\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "from pptx.dml.color import RGBColor\n",
    "from datetime import datetime  # Import the 'datetime' class from the 'datetime' module\n",
    "import time\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from shakti3_index import llama_listvectorkeyword_index\n",
    "from streamlit_pills import pills\n",
    "\n",
    "rootdir = \"/home/cdsw/experimentation_project1/PLS_project\"\n",
    "datadir = \"/home/cdsw/experimentation_project1/PLS_project/data\"\n",
    "\n",
    "#function to set background image\n",
    "def set_bg_hack(main_bg):\n",
    "    '''\n",
    "    A function to unpack an image from root folder and set as bg.\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    The background.\n",
    "    '''\n",
    "    # set bg name\n",
    "    main_bg_ext = \"jpg\"\n",
    "        \n",
    "    st.markdown(\n",
    "         f\"\"\"\n",
    "         <style>\n",
    "         .stApp {{\n",
    "             background: url(data:image/{main_bg_ext};base64,{base64.b64encode(open(main_bg, \"rb\").read()).decode()});\n",
    "             background-size: cover\n",
    "         }}\n",
    "         </style>\n",
    "         \"\"\",\n",
    "         unsafe_allow_html=True\n",
    "     )\n",
    "\n",
    "def sidebar_bg(side_bg):\n",
    "\n",
    "   side_bg_ext = 'png'\n",
    "\n",
    "   st.markdown(\n",
    "      f\"\"\"\n",
    "      <style>\n",
    "      [data-testid=\"stSidebar\"] > div:first-child {{\n",
    "          background: url(data:image/{side_bg_ext};base64,{base64.b64encode(open(side_bg, \"rb\").read()).decode()});\n",
    "      }}\n",
    "      </style>\n",
    "      \"\"\",\n",
    "      unsafe_allow_html=True,\n",
    "      )\n",
    "    \n",
    "def header_bg(side_bg):\n",
    "\n",
    "   side_bg_ext = 'png'\n",
    "\n",
    "   st.markdown(\n",
    "      f\"\"\"\n",
    "      <style>\n",
    "      header.css-1avcm0n {{\n",
    "          background: url(data:image/{side_bg_ext};base64,{base64.b64encode(open(side_bg, \"rb\").read()).decode()});\n",
    "      }}\n",
    "      </style>\n",
    "      \"\"\",\n",
    "      unsafe_allow_html=True,\n",
    "      )\n",
    "    \n",
    "#function to read prompt from corresponding text file\n",
    "def prompt(file):\n",
    "    with open(file) as f:\n",
    "        return f.read()\n",
    "    \n",
    "#function to save a file\n",
    "def save_uploadedfile(uploaded_file):\n",
    "     with open(os.path.join(datadir, uploaded_file.name),\"wb\") as f:\n",
    "         f.write(uploaded_file.getbuffer())\n",
    "     return st.success(f\"\"\"Saved File:{uploaded_file.name} to directory\"\"\")\n",
    "\n",
    "@st.cache_data\n",
    "#function to display the PDF of a given file \n",
    "def displayPDF(file):\n",
    "    # Opening file from file path\n",
    "    with open(file, \"rb\") as f:\n",
    "        base64_pdf = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "    # Embedding PDF in HTML\n",
    "    pdf_display = F'<iframe src=\"data:application/pdf;base64,{base64_pdf}\" width=\"700\" height=\"900\" type=\"application/pdf\"></iframe>'\n",
    "\n",
    "    # Displaying File\n",
    "    st.markdown(pdf_display, unsafe_allow_html=True)\n",
    "\n",
    "# Placeholder function for processing the uploaded documents\n",
    "def process_documents(uploaded_file, tense, pls_grade):\n",
    "    # Implement the document processing logic here\n",
    "\n",
    "    '''\n",
    "        replacements = {\n",
    "            \"<Title>\": GPTAPIcall(uploaded_file, \"'Title'\", tense, pls_grade),\n",
    "        #     \"<Subtitle>\": GPTAPIcall(uploaded_file, \"subtitle\", tense, pls_grade),\n",
    "            \"<Introduction>\": GPTAPIcall(uploaded_file, \"'Introduction'\", tense, pls_grade),\n",
    "        #     \"<Phonetics>\": GPTAPIcall(uploaded_file, \"phonetics\", tense, pls_grade),\n",
    "        #    \"<Key takeaway>\": GPTAPIcall(uploaded_file, \"'Key Takeaway'\", tense, pls_grade),\n",
    "        #    \"<Results>\": GPTAPIcall(uploaded_file, \"'Results'\", tense, pls_grade)\n",
    "        #     \"<Intro summary>\": GPTAPIcall(uploaded_file, \"conclusion\", tense, pls_grade)\n",
    "        }\n",
    "    '''\n",
    "    replacements = {\n",
    "        \"<Title>\": \"\",\n",
    "        \"<Subtitle>\": \"\",\n",
    "        \"<Key takeaway>\": \"\",\n",
    "        \"<Phonetics>\": \"\",\n",
    "        \"<Introduction>\": \"\",\n",
    "        \"<Intro summary>\": \"\",\n",
    "        \"<Inclusion criteria>\": \"\",\n",
    "        \"<Exclusion crtieria>\": \"\",\n",
    "        \"<Results>\": \"\",\n",
    "        \"<Aims>\": \"\",\n",
    "        \"<Conclusions>\": \"\",\n",
    "        \"<Sponsor>\": \"\",\n",
    "        \"<More Information>\": \"\",\n",
    "    }\n",
    "        \n",
    "    # Get the text for each section using GPTAPIcall function\n",
    "    for section_name in replacements:\n",
    "        text = GPTAPIcall(uploaded_file, section_name, tense, pls_grade)\n",
    "        replacements[section_name] = str(text)\n",
    "    \n",
    "    return replacements\n",
    "\n",
    "# Placeholder function for GPT API call\n",
    "def GPTAPIcall(uploaded_file, key, tense, pls_grade):\n",
    "    # Placeholder logic to generate values based on the key, tense, and PLS grade\n",
    "    # Replace this with your actual GPT API call or any other processing logic\n",
    "    # Convert tense strings\n",
    "    tense_mapping = {\"on-going\": \"present\", \"completed\": \"past\", \"upcoming\": \"future\"}\n",
    "    tense = tense_mapping.get(tense, tense)\n",
    "\n",
    "    # Placeholder value for the key with the tense and PLS grade\n",
    "    #value = f\"Placeholder value for {key} (Tense: {tense}, PLS Grade: {pls_grade})\"\n",
    "    query = f\"Strictly following the above instructions and the clinical trial document provided, write the content of {key} section of the APLS in {tense}, comprehendable by a {pls_grade} health literacy grade person. Do not violate the section-wise instructions provided in any case. The content should be strictly inferred from the clinical trial document provided only and not any other sources.\"\n",
    "    \n",
    "    return llama_listvectorkeyword_index(uploaded_file, prompt(os.path.join(rootdir, 'apls_persona_2606.txt')) + \"\\n\" + query)\n",
    "\n",
    "# Placeholder function for postprocessing into PPT template\n",
    "def postprocess_to_ppt(replacements, selected_template):\n",
    "    # Implement the postprocessing logic here\n",
    "    # For demonstration purposes, we'll load a presentation object and copy the text from replacements dictionary\n",
    "    \n",
    "    #rootdir = os.path.realpath('./')\n",
    "    \n",
    "    #selected_template = \"PLS_PPT_Template\"\n",
    "    ppt_file = f\"{selected_template}.pptx\"\n",
    "    prs = Presentation(os.path.join(rootdir, ppt_file))\n",
    "\n",
    "    for slide in prs.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if shape.has_text_frame:\n",
    "                text_frame = shape.text_frame\n",
    "                for paragraph in text_frame.paragraphs:\n",
    "                    for run in paragraph.runs:\n",
    "                        for placeholder, new_text in replacements.items():\n",
    "                            if run.text == placeholder:\n",
    "                                # Preserve formatting of the first run in the paragraph\n",
    "                                first_run = paragraph.runs[0]\n",
    "                                font_size = first_run.font.size\n",
    "                                font_name = first_run.font.name\n",
    "                                font_bold = first_run.font.bold\n",
    "                                font_italic = first_run.font.italic\n",
    "\n",
    "                                # Check if font color is explicitly defined\n",
    "                                if first_run.font.color.type == \"rgb\":\n",
    "                                    font_color = first_run.font.color.rgb\n",
    "                                else:\n",
    "                                    font_color = None\n",
    "\n",
    "                                # Replace text while preserving formatting\n",
    "                                run.text = new_text\n",
    "\n",
    "                                # Apply preserved formatting to the entire paragraph\n",
    "                                for run in paragraph.runs:\n",
    "                                    run.font.size = font_size\n",
    "                                    run.font.name = font_name\n",
    "                                    run.font.bold = font_bold\n",
    "                                    run.font.italic = font_italic\n",
    "                                    if font_color:\n",
    "                                        run.font.color.rgb = font_color\n",
    "\n",
    "    # Return the modified presentation object\n",
    "    return prs\n",
    "\n",
    "def main():\n",
    "    \n",
    "    #Page icons n tab name on browser tab\n",
    "    #img = Image.open(os.path.join(rootdir, 'pfizer.png'))\n",
    "    st.set_page_config(page_title = 'MAIA', page_icon = \":robot_face:\", layout=\"wide\")\n",
    "    \n",
    "    #set bg image cover\n",
    "    set_bg_hack(os.path.join(rootdir, 'iqvia-bg.jpg'))\n",
    "    sidebar_bg(os.path.join(rootdir, 'iqvia-blue.png'))\n",
    "    header_bg(os.path.join(rootdir, 'iqvia-dark-blue.png'))\n",
    "    \n",
    "    #setting banner image\n",
    "    st.image(Image.open(os.path.join(rootdir, 'Pfizer-AI.jpg')))\n",
    "    \n",
    "    \n",
    "    #setting input components on sidebar\n",
    "    with st.sidebar:\n",
    "        st.image(Image.open(os.path.join(rootdir, 'iqvia-logo.png')))\n",
    "        #setting title\n",
    "        st.markdown(\"\"\"<h3 style='text-align: center; color:red'>MAIA - Medical Affairs Intelligence Assistant</h3>\"\"\", unsafe_allow_html=True)\n",
    "        \n",
    "        # Step 1: Document Upload\n",
    "        st.subheader(\"Step 1: Upload Clinical trial document\")\n",
    "        uploaded_file = st.file_uploader(\"Upload document\", accept_multiple_files=False, type=[\"pdf\"])\n",
    "\n",
    "        # Step 2: User Inputs\n",
    "        st.subheader(\"Step 2: Define the tone and Grade of PLS\")\n",
    "        # Set default values for radio button and slider\n",
    "        default_tense = \"completed\"\n",
    "        default_pls_grade = \"Moderate\"\n",
    "\n",
    "        # Radio button for tense selection\n",
    "        tense = st.radio(\"Current status of the study\", options=[\"on-going\", \"completed\", \"upcoming\"], key=\"tense\", index=[\"on-going\", \"completed\", \"upcoming\"].index(default_tense))\n",
    "        st.write('<style>div.row-widget.stRadio > div{flex-direction:row;}</style>', unsafe_allow_html=True)\n",
    "        \n",
    "        # Slider for PLS grade selection\n",
    "        #pls_grade = st.slider(\"Health Literacy Grade Reading level\", min_value=0, max_value=10, step=5, key=\"pls_grade\", value=default_pls_grade)\n",
    "        pls_grade = st.select_slider(\"Health Literacy Grade Reading level\", options=[\"Low\", \"Moderate\", \"High\"], key=\"pls_grade\", value = default_pls_grade)\n",
    "        \n",
    "        \n",
    "        process_button = st.button(\"Process Documents\")\n",
    "        \n",
    "    if process_button:\n",
    "        if uploaded_file:\n",
    "            # Retrieve user inputs if you haven't initialized them to any variable, then retrieve from streamlit session state\n",
    "            # st.session_state.tense = tense\n",
    "            # st.session_state.pls_grade = pls_grade\n",
    "            \n",
    "            col1, col2 = st.columns([0.3,0.7])\n",
    "            with col1:\n",
    "                input_file = save_uploadedfile(uploaded_file)\n",
    "                pdf_file = os.path.join(datadir, uploaded_file.name) #rootdir + \"/\" + uploaded_file.name\n",
    "                pdf_view = displayPDF(pdf_file)\n",
    "            with col2:\n",
    "                with st.spinner(text='Processing trial doc...⏳'):\n",
    "            \n",
    "                    # Call the processing function on the uploaded documents with user inputs\n",
    "                    replacements = process_documents(pdf_file, tense, pls_grade)\n",
    "                    st.success(\"Processed Output\")\n",
    "                    \n",
    "                    #Display processed output\n",
    "                    st.write(replacements)\n",
    "                    #st.dataframe(replacements)\n",
    "                    \n",
    "#                     output_text = st.empty()  # Create an empty element for real-time updates\n",
    "\n",
    "#                     # Display the processed output character by character\n",
    "#                     for section_name, text in replacements.items():\n",
    "#                         output_text.markdown(f\"{section_name}: \", unsafe_allow_html=True)\n",
    "#                         full_text = \"\"\n",
    "#                         for char in text:\n",
    "#                             full_text += char\n",
    "#                             time.sleep(0.001)  # Adjust the sleep time to control the streaming speed\n",
    "#                             output_text.markdown(full_text, unsafe_allow_html=True)\n",
    "                            \n",
    "                    # output_text.markdown(\"\\n\", unsafe_allow_html=True)\n",
    "            \n",
    "            # Store the replacements dictionary in session state\n",
    "            st.session_state.replacements = replacements\n",
    "\n",
    "    # Step 3: PPT Template Selection and Download\n",
    "    st.subheader(\"Step 3: Select PLS Template and Download\")\n",
    "    \n",
    "    # Add radio buttons for template selection here    \n",
    "    default_template = \"Pfizer_Blue_PLS_Template\"\n",
    "    selected_template = st.radio(\"Select PPT Template\", options=[\"Pfizer_Blue_PLS_Template\", \"Pfizer_Red_PLS_Template\", \"Pfizer_Long_PLS_Template\"], index=[\"Pfizer_Blue_PLS_Template\", \"Pfizer_Red_PLS_Template\", \"Pfizer_Long_PLS_Template\"].index(default_template))\n",
    "    st.write('<style>div.row-widget.stRadio > div{flex-direction:row;}</style>', unsafe_allow_html=True)\n",
    "    #selected_template = pills(\"\", [\"Pfizer_Blue_PLS_Template\", \"Pfizer_Red_PLS_Template\", \"Pfizer_Long_PLS_Template\"], [\"🍀\", \"🎈\", \"🌈\"])\n",
    "    \n",
    "    generate_ppt_button = st.button(\"Generate PLS\")\n",
    "\n",
    "    if generate_ppt_button:\n",
    "        # Retrieve the replacements dictionary from session state\n",
    "        replacements = st.session_state.replacements\n",
    "\n",
    "        if replacements:\n",
    "            with st.spinner('Generating awesome slides for you...⏳'):\n",
    "                # Call the postprocessing function to generate PPT content\n",
    "                ppt_content = postprocess_to_ppt(replacements, selected_template)\n",
    "\n",
    "                # Display the PPT content using st.markdown or st.write\n",
    "                #st.markdown(ppt_content, unsafe_allow_html=True)\n",
    "                st.markdown(list(replacements.keys()))\n",
    "\n",
    "                # Store the PPT content in session state\n",
    "                st.session_state.ppt_content = ppt_content\n",
    "            \n",
    "            \n",
    "                 # Step 4: PPT Download\n",
    "                if \"ppt_content\" in st.session_state:\n",
    "                    ppt_content = st.session_state.ppt_content\n",
    "                    #replacements = st.session_state.replacements\n",
    "                    \n",
    "                    # Save the modified presentation object to a temporary file\n",
    "                    #ppt_output_file = f\"PLS_{replacements['<Title>']}_{datetime.now().strftime('%Y%m%d%H%M%S')}.pptx\"                    \n",
    "                    ppt_output_file = \"PLS_output.pptx\"\n",
    "                    #ppt_content.save(ppt_output_file)\n",
    "\n",
    "                    # save presentation as binary output\n",
    "                    binary_output = BytesIO()\n",
    "                    ppt_content.save(binary_output)\n",
    "\n",
    "                    # display success message and download button\n",
    "                    st.success(':tada: The PLS template has been filled with above sections in ' + selected_template)\n",
    "\n",
    "                    # Provide the download link for the generated PPT\n",
    "                    st.download_button(\"Download PLS\", data=binary_output.getvalue(), file_name=ppt_output_file, mime=\"application/vnd.openxmlformats-officedocument.presentationml.presentation\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f135595-fcf0-4e55-bc05-14923925db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################version for Pfizer demo###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e533508a-da2c-4e45-bbb0-4dff8611878c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1afc9bab-798e-4f0c-8240-04f6e76d4bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app9.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app9.py\n",
    "#enhanced for taking csv input and producing graphs - baselined version\n",
    "import os\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import base64\n",
    "import json\n",
    "import streamlit as st\n",
    "from pptx import Presentation\n",
    "from datetime import datetime  # Import the 'datetime' class from the 'datetime' module\n",
    "import time\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from shakti3_index import llama_listvectorkeyword_index\n",
    "from shakti_pptreport import postprocess_to_ppt\n",
    "from streamlit_pills import pills\n",
    "\n",
    "rootdir = \"/home/cdsw/experimentation_project1/PLS_project\"\n",
    "datadir = \"/home/cdsw/experimentation_project1/PLS_project/data\"\n",
    "\n",
    "#function to set background image\n",
    "def set_bg_hack(main_bg):\n",
    "    '''\n",
    "    A function to unpack an image from root folder and set as bg.\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    The background.\n",
    "    '''\n",
    "    # set bg name\n",
    "    main_bg_ext = \"jpg\"\n",
    "        \n",
    "    st.markdown(\n",
    "         f\"\"\"\n",
    "         <style>\n",
    "         .stApp {{\n",
    "             background: url(data:image/{main_bg_ext};base64,{base64.b64encode(open(main_bg, \"rb\").read()).decode()});\n",
    "             background-size: cover\n",
    "         }}\n",
    "         </style>\n",
    "         \"\"\",\n",
    "         unsafe_allow_html=True\n",
    "     )\n",
    "\n",
    "def sidebar_bg(side_bg):\n",
    "\n",
    "   side_bg_ext = 'png'\n",
    "\n",
    "   st.markdown(\n",
    "      f\"\"\"\n",
    "      <style>\n",
    "      [data-testid=\"stSidebar\"] > div:first-child {{\n",
    "          background: url(data:image/{side_bg_ext};base64,{base64.b64encode(open(side_bg, \"rb\").read()).decode()});\n",
    "      }}\n",
    "      </style>\n",
    "      \"\"\",\n",
    "      unsafe_allow_html=True,\n",
    "      )\n",
    "    \n",
    "def header_bg(side_bg):\n",
    "\n",
    "   side_bg_ext = 'png'\n",
    "\n",
    "   st.markdown(\n",
    "      f\"\"\"\n",
    "      <style>\n",
    "      header.css-1avcm0n {{\n",
    "          background: url(data:image/{side_bg_ext};base64,{base64.b64encode(open(side_bg, \"rb\").read()).decode()});\n",
    "      }}\n",
    "      </style>\n",
    "      \"\"\",\n",
    "      unsafe_allow_html=True,\n",
    "      )\n",
    "    \n",
    "#function to read prompt from corresponding text file\n",
    "def prompt(file):\n",
    "    with open(file) as f:\n",
    "        return f.read()\n",
    "    \n",
    "#function to save a file\n",
    "def save_uploadedfile(uploaded_file):\n",
    "     with open(os.path.join(datadir, uploaded_file.name),\"wb\") as f:\n",
    "         f.write(uploaded_file.getbuffer())\n",
    "     return st.success(f\"\"\"Saved File:{uploaded_file.name} to directory\"\"\")\n",
    "\n",
    "@st.cache_data\n",
    "#function to display the PDF of a given file \n",
    "def displayPDF(file):\n",
    "    # Opening file from file path\n",
    "    with open(file, \"rb\") as f:\n",
    "        base64_pdf = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "    # Embedding PDF in HTML\n",
    "    pdf_display = F'<iframe src=\"data:application/pdf;base64,{base64_pdf}\" width=\"300\" height=\"200\" type=\"application/pdf\"></iframe>'\n",
    "\n",
    "    # Displaying File\n",
    "    st.markdown(pdf_display, unsafe_allow_html=True)\n",
    "\n",
    "# Placeholder function for processing the uploaded documents\n",
    "def process_documents(uploaded_file, tense, pls_grade):\n",
    "    # Implement the document processing logic here\n",
    "\n",
    "    '''\n",
    "        replacements = {\n",
    "            \"<Title>\": GPTAPIcall(uploaded_file, \"'Title'\", tense, pls_grade),\n",
    "        #     \"<Subtitle>\": GPTAPIcall(uploaded_file, \"subtitle\", tense, pls_grade),\n",
    "            \"<Introduction>\": GPTAPIcall(uploaded_file, \"'Introduction'\", tense, pls_grade),\n",
    "        #     \"<Phonetics>\": GPTAPIcall(uploaded_file, \"phonetics\", tense, pls_grade),\n",
    "        #    \"<Key takeaway>\": GPTAPIcall(uploaded_file, \"'Key Takeaway'\", tense, pls_grade),\n",
    "        #    \"<Results>\": GPTAPIcall(uploaded_file, \"'Results'\", tense, pls_grade)\n",
    "        #     \"<Intro summary>\": GPTAPIcall(uploaded_file, \"conclusion\", tense, pls_grade)\n",
    "        }\n",
    "    '''\n",
    "    replacements = {\n",
    "        \"<Title>\": \"\",\n",
    "        \"<Introduction>\": \"\",\n",
    "    }\n",
    "        \n",
    "    # Get the text for each section using GPTAPIcall function\n",
    "    for section_name in replacements:\n",
    "        text = GPTAPIcall(uploaded_file, section_name, tense, pls_grade)\n",
    "        replacements[section_name] = str(text)\n",
    "    \n",
    "    return replacements\n",
    "\n",
    "# Placeholder function for GPT API call\n",
    "def GPTAPIcall(uploaded_file, key, tense, pls_grade):\n",
    "    # Placeholder logic to generate values based on the key, tense, and PLS grade\n",
    "    # Replace this with your actual GPT API call or any other processing logic\n",
    "    # Convert tense strings\n",
    "    tense_mapping = {\"on-going\": \"present\", \"completed\": \"past\", \"upcoming\": \"future\"}\n",
    "    tense = tense_mapping.get(tense, tense)\n",
    "\n",
    "    # Placeholder value for the key with the tense and PLS grade\n",
    "    #value = f\"Placeholder value for {key} (Tense: {tense}, PLS Grade: {pls_grade})\"\n",
    "    query = f\"Strictly following the above instructions and the clinical trial document provided, write the content of {key} section of the APLS in {tense}, comprehendable by a {pls_grade} health literacy grade person. Do not violate the section-wise instructions provided in any case. The content should be strictly inferred from the clinical trial document provided only and not any other sources.\\n\"\n",
    "    \n",
    "    return llama_listvectorkeyword_index(uploaded_file, prompt(os.path.join(rootdir, 'apls_persona_2606.txt')) + \"\\n\\n\\n\" + query)\n",
    "\n",
    "# Placeholder function for postprocessing into PPT template\n",
    "# def postprocess_to_ppt(replacements, selected_template):\n",
    "#     # Implement the postprocessing logic here\n",
    "#     # For demonstration purposes, we'll load a presentation object and copy the text from replacements dictionary\n",
    "    \n",
    "#     #rootdir = os.path.realpath('./')\n",
    "    \n",
    "#     #selected_template = \"PLS_PPT_Template\"\n",
    "#     ppt_file = f\"{selected_template}.pptx\"\n",
    "#     prs = Presentation(os.path.join(rootdir, ppt_file))\n",
    "\n",
    "#     for slide in prs.slides:\n",
    "#         for shape in slide.shapes:\n",
    "#             if shape.has_text_frame:\n",
    "#                 text_frame = shape.text_frame\n",
    "#                 for paragraph in text_frame.paragraphs:\n",
    "#                     for run in paragraph.runs:\n",
    "#                         for placeholder, new_text in replacements.items():\n",
    "#                             if run.text == placeholder:\n",
    "#                                 # Preserve formatting of the first run in the paragraph\n",
    "#                                 first_run = paragraph.runs[0]\n",
    "#                                 font_size = first_run.font.size\n",
    "#                                 font_name = first_run.font.name\n",
    "#                                 font_bold = first_run.font.bold\n",
    "#                                 font_italic = first_run.font.italic\n",
    "\n",
    "#                                 # Check if font color is explicitly defined\n",
    "#                                 if first_run.font.color.type == \"rgb\":\n",
    "#                                     font_color = first_run.font.color.rgb\n",
    "#                                 else:\n",
    "#                                     font_color = None\n",
    "\n",
    "#                                 # Replace text while preserving formatting\n",
    "#                                 run.text = new_text\n",
    "\n",
    "#                                 # Apply preserved formatting to the entire paragraph\n",
    "#                                 for run in paragraph.runs:\n",
    "#                                     run.font.size = font_size\n",
    "#                                     run.font.name = font_name\n",
    "#                                     run.font.bold = font_bold\n",
    "#                                     run.font.italic = font_italic\n",
    "#                                     if font_color:\n",
    "#                                         run.font.color.rgb = font_color\n",
    "\n",
    "#     # Return the modified presentation object\n",
    "#     return prs\n",
    "\n",
    "def main():\n",
    "    \n",
    "    #Page icons n tab name on browser tab\n",
    "    img = Image.open(os.path.join(rootdir, 'pfizer.png'))\n",
    "    st.set_page_config(page_title = 'Pfizer PLS Generator', page_icon = img, layout=\"wide\")\n",
    "    \n",
    "    #set bg image cover\n",
    "    set_bg_hack(os.path.join(rootdir, 'iqvia-bg.jpg'))\n",
    "    sidebar_bg(os.path.join(rootdir, 'iqvia-blue.png'))\n",
    "    header_bg(os.path.join(rootdir, 'iqvia-dark-blue.png'))\n",
    "    \n",
    "    #setting banner image\n",
    "    st.image(Image.open(os.path.join(rootdir, 'Pfizer-AI.jpg')))\n",
    "    \n",
    "    \n",
    "    #setting input components on sidebar\n",
    "    with st.sidebar:\n",
    "        st.image(Image.open(os.path.join(rootdir, 'iqvia-logo.png')))\n",
    "        #setting title\n",
    "        st.header(\"PLS Generator\")\n",
    "        \n",
    "        # Step 1: Document Upload\n",
    "        st.subheader(\"Step 1: Upload Clinical trial document\")\n",
    "        uploaded_file = st.file_uploader(\"Upload document\", accept_multiple_files=False, type=[\"pdf\"])\n",
    "        \n",
    "        # Allow user to upload CSV file\n",
    "        csv_file = st.file_uploader(\"Upload csv file for Results related numericals\", accept_multiple_files=False, type=[\"csv\"])\n",
    "        \n",
    "        # Step 2: User Inputs\n",
    "        st.subheader(\"Step 2: Define the tone and Grade of PLS\")\n",
    "        # Set default values for radio button and slider\n",
    "        default_tense = \"completed\"\n",
    "        default_pls_grade = \"Moderate\"\n",
    "\n",
    "        # Radio button for tense selection\n",
    "        tense = st.radio(\"Current status of the study\", options=[\"on-going\", \"completed\", \"upcoming\"], key=\"tense\", index=[\"on-going\", \"completed\", \"upcoming\"].index(default_tense))\n",
    "        st.write('<style>div.row-widget.stRadio > div{flex-direction:row;}</style>', unsafe_allow_html=True)\n",
    "        \n",
    "        # Slider for PLS grade selection\n",
    "        #pls_grade = st.slider(\"Health Literacy Grade Reading level\", min_value=0, max_value=10, step=5, key=\"pls_grade\", value=default_pls_grade)\n",
    "        pls_grade = st.select_slider(\"Health Literacy Grade Reading level\", options=[\"Low\", \"Moderate\", \"High\"], key=\"pls_grade\", value = default_pls_grade)\n",
    "        \n",
    "        \n",
    "        process_button = st.button(\"Process Documents\")\n",
    "        \n",
    "    if process_button:\n",
    "        if uploaded_file and csv_file:\n",
    "            # Retrieve user inputs if you haven't initialized them to any variable, then retrieve from streamlit session state\n",
    "            # st.session_state.tense = tense\n",
    "            # st.session_state.pls_grade = pls_grade\n",
    "            \n",
    "            col1, col2 = st.columns([1,2])\n",
    "            with col1:\n",
    "                input_file = save_uploadedfile(uploaded_file)\n",
    "                pdf_file = os.path.join(datadir, uploaded_file.name) #rootdir + \"/\" + uploaded_file.name\n",
    "                pdf_view = displayPDF(pdf_file)\n",
    "                \n",
    "                df = pd.read_csv(csv_file)\n",
    "                st.write(df)\n",
    "                \n",
    "            with col2:\n",
    "                with st.spinner(text='Processing trial doc...⏳'):\n",
    "            \n",
    "                    # Call the processing function on the uploaded documents with user inputs\n",
    "                    replacements = process_documents(pdf_file, tense, pls_grade)\n",
    "                    st.success(\"Processed Output\")\n",
    "                    \n",
    "                    #Display processed output\n",
    "                    st.write(replacements)\n",
    "                    #st.dataframe(replacements)\n",
    "                    \n",
    "#                     output_text = st.empty()  # Create an empty element for real-time updates\n",
    "\n",
    "#                     # Display the processed output character by character\n",
    "#                     for section_name, text in replacements.items():\n",
    "#                         output_text.markdown(f\"{section_name}: \", unsafe_allow_html=True)\n",
    "#                         full_text = \"\"\n",
    "#                         for char in text:\n",
    "#                             full_text += char\n",
    "#                             time.sleep(0.001)  # Adjust the sleep time to control the streaming speed\n",
    "#                             output_text.markdown(full_text, unsafe_allow_html=True)\n",
    "                            \n",
    "                    # output_text.markdown(\"\\n\", unsafe_allow_html=True)\n",
    "            \n",
    "            # Store the replacements dictionary in session state\n",
    "            st.session_state.replacements = replacements\n",
    "\n",
    "    # Step 3: PPT Template Selection and Download\n",
    "    st.subheader(\"Step 3: Select PLS PPT Template and Download\")\n",
    "    \n",
    "    # Add radio buttons for template selection here    \n",
    "    default_template = \"PLS_PPT_Template\"\n",
    "    #selected_template = st.radio(\"Select PPT Template\", options=[\"PLS_PPT_Template\", \"Template2\", \"Template3\"], index=[\"PLS_PPT_Template\", \"Template2\", \"Template3\"].index(default_template))\n",
    "    #st.write('<style>div.row-widget.stRadio > div{flex-direction:row;}</style>', unsafe_allow_html=True)\n",
    "    selected_template = pills(\"\", [\"PLS_PPT_Template\", \"PLS_Red_PPT_Template\", \"Table_Chart_PPT_Template\"], [\"🍀\", \"🎈\", \"🌈\"])\n",
    "    \n",
    "    generate_ppt_button = st.button(\"Generate PLS\")\n",
    "\n",
    "    if generate_ppt_button:\n",
    "        # Retrieve the replacements dictionary from session state\n",
    "        replacements = st.session_state.replacements\n",
    "\n",
    "        if replacements:\n",
    "            with st.spinner('Generating awesome slides for you...⏳'):\n",
    "                # Call the postprocessing function to generate PPT content\n",
    "                ppt_content = postprocess_to_ppt(replacements, selected_template)\n",
    "\n",
    "                # Display the PPT content using st.markdown or st.write\n",
    "                #st.markdown(ppt_content, unsafe_allow_html=True)\n",
    "                st.markdown(list(replacements.keys()))\n",
    "\n",
    "                # Store the PPT content in session state\n",
    "                st.session_state.ppt_content = ppt_content\n",
    "            \n",
    "            \n",
    "                 # Step 4: PPT Download\n",
    "                if \"ppt_content\" in st.session_state:\n",
    "                    ppt_content = st.session_state.ppt_content\n",
    "                    #replacements = st.session_state.replacements\n",
    "                    \n",
    "                    # Save the modified presentation object to a temporary file\n",
    "                    #ppt_output_file = f\"PLS_{replacements['<Title>']}_{datetime.now().strftime('%Y%m%d%H%M%S')}.pptx\"                    \n",
    "                    ppt_output_file = \"PLS_output.pptx\"\n",
    "                    #ppt_content.save(ppt_output_file)\n",
    "\n",
    "                    # save presentation as binary output\n",
    "                    binary_output = BytesIO()\n",
    "                    ppt_content.save(binary_output)\n",
    "\n",
    "                    # display success message and download button\n",
    "                    st.success(':tada: The PLS template has been filled with above sections in ' + selected_template)\n",
    "\n",
    "                    # Provide the download link for the generated PPT\n",
    "                    st.download_button(\"Download PLS\", data=binary_output.getvalue(), file_name=ppt_output_file, mime=\"application/vnd.openxmlformats-officedocument.presentationml.presentation\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f77d3-0398-4023-ba7e-b348fe626334",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################yet to add authenticator page and streaming text###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb565f0-c83b-48f6-a541-6dd7873fbe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################adding one word answers and doc download#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9a68693-3ef0-4d0d-933c-88318e1466ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app8.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app8.py\n",
    "#enhancing - baselined version with QnA feature added. dont touch --Pfizer version\n",
    "import os\n",
    "import urllib\n",
    "import base64\n",
    "import json\n",
    "import streamlit as st\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "from pptx.dml.color import RGBColor\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "from datetime import datetime  # Import the 'datetime' class from the 'datetime' module\n",
    "import time\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from shakti_stream_index import llama_vector_index\n",
    "from streamlit_pills import pills\n",
    "import streamlit_authenticator as stauth\n",
    "from streamlit_option_menu import option_menu\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "\n",
    "rootdir = \"/home/cdsw/experimentation_project1/PLS_project\"\n",
    "datadir = \"/home/cdsw/experimentation_project1/PLS_project/data\"\n",
    "\n",
    "#function to set background image\n",
    "def set_bg_hack(main_bg):\n",
    "    '''\n",
    "    A function to unpack an image from root folder and set as bg.\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    The background.\n",
    "    '''\n",
    "    # set bg name\n",
    "    main_bg_ext = \"jpg\"\n",
    "        \n",
    "    st.markdown(\n",
    "         f\"\"\"\n",
    "         <style>\n",
    "         .stApp {{\n",
    "             background: url(data:image/{main_bg_ext};base64,{base64.b64encode(open(main_bg, \"rb\").read()).decode()});\n",
    "             background-size: cover\n",
    "         }}\n",
    "         </style>\n",
    "         \"\"\",\n",
    "         unsafe_allow_html=True\n",
    "     )\n",
    "\n",
    "def sidebar_bg(side_bg):\n",
    "\n",
    "   side_bg_ext = 'png'\n",
    "\n",
    "   st.markdown(\n",
    "      f\"\"\"\n",
    "      <style>\n",
    "      [data-testid=\"stSidebar\"] > div:first-child {{\n",
    "          background: url(data:image/{side_bg_ext};base64,{base64.b64encode(open(side_bg, \"rb\").read()).decode()});\n",
    "      }}\n",
    "      </style>\n",
    "      \"\"\",\n",
    "      unsafe_allow_html=True,\n",
    "      )\n",
    "    \n",
    "def header_bg(side_bg):\n",
    "\n",
    "   side_bg_ext = 'png'\n",
    "\n",
    "   st.markdown(\n",
    "      f\"\"\"\n",
    "      <style>\n",
    "      header.css-1avcm0n {{\n",
    "          background: url(data:image/{side_bg_ext};base64,{base64.b64encode(open(side_bg, \"rb\").read()).decode()});\n",
    "      }}\n",
    "      </style>\n",
    "      \"\"\",\n",
    "      unsafe_allow_html=True,\n",
    "      )\n",
    "    \n",
    "#function to read prompt from corresponding text file\n",
    "def prompt(file):\n",
    "    with open(file) as f:\n",
    "        return f.read()\n",
    "    \n",
    "#function to save a file\n",
    "def save_uploadedfile(uploaded_file):\n",
    "     with open(os.path.join(datadir, uploaded_file.name),\"wb\") as f:\n",
    "         f.write(uploaded_file.getbuffer())\n",
    "     return st.success(f\"\"\"Saved File:{uploaded_file.name} to directory\"\"\")\n",
    "\n",
    "@st.cache_data\n",
    "#function to display the PDF of a given file \n",
    "def displayPDF(file):\n",
    "    # Opening file from file path\n",
    "    with open(file, \"rb\") as f:\n",
    "        base64_pdf = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "    # Embedding PDF in HTML\n",
    "    pdf_display = F'<iframe src=\"data:application/pdf;base64,{base64_pdf}\" width=\"300\" height=\"1100\" type=\"application/pdf\"></iframe>'\n",
    "\n",
    "    # Displaying File\n",
    "    st.markdown(pdf_display, unsafe_allow_html=True)\n",
    "\n",
    "# Placeholder function for processing the uploaded documents\n",
    "def process_documents(uploaded_file, tense, pls_grade):\n",
    "    # Implement the document processing logic here\n",
    "\n",
    "    '''\n",
    "        replacements = {\n",
    "            \"<Title>\": GPTAPIcall(uploaded_file, \"'Title'\", tense, pls_grade),\n",
    "        #     \"<Subtitle>\": GPTAPIcall(uploaded_file, \"subtitle\", tense, pls_grade),\n",
    "            \"<Introduction>\": GPTAPIcall(uploaded_file, \"'Introduction'\", tense, pls_grade),\n",
    "        #     \"<Phonetics>\": GPTAPIcall(uploaded_file, \"phonetics\", tense, pls_grade),\n",
    "        #    \"<Key takeaway>\": GPTAPIcall(uploaded_file, \"'Key Takeaway'\", tense, pls_grade),\n",
    "        #    \"<Results>\": GPTAPIcall(uploaded_file, \"'Results'\", tense, pls_grade)\n",
    "        #     \"<Intro summary>\": GPTAPIcall(uploaded_file, \"conclusion\", tense, pls_grade)\n",
    "        }\n",
    "    '''\n",
    "    replacements = {\n",
    "        \"<Title>\": \"\",\n",
    "        \"<Subtitle>\": \"\",\n",
    "        \"<Key takeaway>\": \"\",\n",
    "        \"<Phonetics>\": \"\",\n",
    "        \"<Introduction>\": \"\",\n",
    "        \"<Intro summary>\": \"\",\n",
    "        \"<Inclusion criteria>\": \"\",\n",
    "        \"<Exclusion crtieria>\": \"\",\n",
    "        \"<Results>\": \"\",\n",
    "        \"<Aims>\": \"\",\n",
    "        \"<Conclusions>\": \"\",\n",
    "        \"<Sponsor>\": \"\",\n",
    "        \"<More Information>\": \"\",\n",
    "    }\n",
    "        \n",
    "    # Get the text for each section using GPTAPIcall function\n",
    "    for section_name in replacements:\n",
    "        \n",
    "        st.subheader(f\"\"\":red[{section_name[1:-1]} :]\"\"\")\n",
    "        text = GPTAPIcall(uploaded_file, section_name, tense, pls_grade)\n",
    "        replacements[section_name] = str(text)\n",
    "        \n",
    "    replacements = {**replacements, \n",
    "                    \"<Participants>\": \"274\",\n",
    "                    \"<Disease condition>\": \"Sickle cell disease\",\n",
    "                    \"<Demographics>\": \"Aged 12 to 65 years\",\n",
    "                    \"<treatment arm>\": \"182\",\n",
    "                    \"<control arm>\": \"92\",\n",
    "                    \"<Study number>\": \"NCT03036813\",\n",
    "                    \"<Start date>\": \"April 2018\",\n",
    "                    \"<End date>\": \"April 2021\",\n",
    "                    \"<clinical trials gov link>\": \"https://clinicaltrials.gov/ct2/show/NCT03036813\",\n",
    "                    \"<Summary date>\": datetime.now().strftime('%d-%b-%Y'),\n",
    "                   }\n",
    "    \n",
    "    return replacements\n",
    "\n",
    "# Placeholder function for GPT API call\n",
    "def GPTAPIcall(uploaded_file, key, tense, pls_grade):\n",
    "    # Placeholder logic to generate values based on the key, tense, and PLS grade\n",
    "    # Replace this with your actual GPT API call or any other processing logic\n",
    "    # Convert tense strings\n",
    "    tense_mapping = {\"on-going\": \"present\", \"completed\": \"past\", \"upcoming\": \"future\"}\n",
    "    tense = tense_mapping.get(tense, tense)\n",
    "\n",
    "    # Placeholder value for the key with the tense and PLS grade\n",
    "    #value = f\"Placeholder value for {key} (Tense: {tense}, PLS Grade: {pls_grade})\"\n",
    "    query = f\"Strictly following the above instructions and the clinical trial document provided, write the content of {key} section of the APLS in {tense}, comprehendable by a {pls_grade} health literacy grade person. Do not violate the section-wise instructions provided in any case. The content should be strictly inferred from the clinical trial document provided only and not any other sources.\"\n",
    "    \n",
    "    return llama_vector_index(uploaded_file, prompt(os.path.join(rootdir, 'apls_persona_2606.txt')) + \"\\n\" + query)\n",
    "\n",
    "# Placeholder function for postprocessing into PPT template\n",
    "def postprocess_to_ppt(replacements, selected_template):\n",
    "    # Implement the postprocessing logic here\n",
    "    # For demonstration purposes, we'll load a presentation object and copy the text from replacements dictionary\n",
    "    \n",
    "    #rootdir = os.path.realpath('./')\n",
    "    \n",
    "    #selected_template = \"PLS_PPT_Template\"\n",
    "    ppt_file = f\"{selected_template}.pptx\"\n",
    "    prs = Presentation(os.path.join(rootdir, ppt_file))\n",
    "\n",
    "    for slide in prs.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if shape.has_text_frame:\n",
    "                text_frame = shape.text_frame\n",
    "                for paragraph in text_frame.paragraphs:\n",
    "                    for run in paragraph.runs:\n",
    "                        for placeholder, new_text in replacements.items():\n",
    "                            if run.text == placeholder:\n",
    "                                # Preserve formatting of the first run in the paragraph\n",
    "                                first_run = paragraph.runs[0]\n",
    "                                font_size = first_run.font.size\n",
    "                                font_name = first_run.font.name\n",
    "                                font_bold = first_run.font.bold\n",
    "                                font_italic = first_run.font.italic\n",
    "\n",
    "                                # Check if font color is explicitly defined\n",
    "                                if first_run.font.color.type == \"rgb\":\n",
    "                                    font_color = first_run.font.color.rgb\n",
    "                                else:\n",
    "                                    font_color = None\n",
    "\n",
    "                                # Replace text while preserving formatting\n",
    "                                run.text = new_text\n",
    "\n",
    "                                # Apply preserved formatting to the entire paragraph\n",
    "                                for run in paragraph.runs:\n",
    "                                    run.font.size = font_size\n",
    "                                    run.font.name = font_name\n",
    "                                    run.font.bold = font_bold\n",
    "                                    run.font.italic = font_italic\n",
    "                                    if font_color:\n",
    "                                        run.font.color.rgb = font_color\n",
    "\n",
    "    # Return the modified presentation object\n",
    "    return prs\n",
    "\n",
    "\n",
    "# Placeholder function for postprocessing into DOC template\n",
    "def postprocess_to_doc(replacements):\n",
    "    # Create a new document\n",
    "    document = Document()\n",
    "\n",
    "    # Set the font size of the document\n",
    "    style = document.styles['Normal']\n",
    "    font = style.font\n",
    "    font.size = Pt(11)\n",
    "\n",
    "    # Set the title\n",
    "    title = replacements.get(\"Title\")\n",
    "    if title:\n",
    "        document.add_heading(title, level=1).bold = True\n",
    "\n",
    "    # Add sections and paragraphs\n",
    "    section_count = 0\n",
    "    for key, value in replacements.items():\n",
    "        if key != \"Title\":\n",
    "            section_count += 1\n",
    "            if section_count <= 12:\n",
    "                document.add_heading(key, level=1)\n",
    "                if value:\n",
    "                    document.add_paragraph(value)\n",
    "\n",
    "    # Add the table\n",
    "    table_replacements = {k: v for k, v in replacements.items() if k != \"Title\" and k not in list(replacements.keys())[1:13]}\n",
    "    if table_replacements:\n",
    "        table_heading = \"Additional Information\"\n",
    "        document.add_heading(table_heading, level=1)\n",
    "\n",
    "        # Create the table\n",
    "        table = document.add_table(rows=1, cols=2)\n",
    "        table.style = 'Table Grid'\n",
    "        \n",
    "        # Set table column widths\n",
    "        table.autofit = False\n",
    "        table.columns[0].width = Pt(200)\n",
    "        table.columns[1].width = Pt(300)\n",
    "\n",
    "        # Add table headers\n",
    "        table_header_cells = table.rows[0].cells\n",
    "        table_header_cells[0].text = \"Variable\"\n",
    "        table_header_cells[1].text = \"Value\"\n",
    "        for cell in table_header_cells:\n",
    "            cell.paragraphs[0].alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "            cell.paragraphs[0].bold = True\n",
    "\n",
    "        # Add table rows\n",
    "        for key, value in table_replacements.items():\n",
    "            row_cells = table.add_row().cells\n",
    "            row_cells[0].text = key\n",
    "            row_cells[1].text = value\n",
    "\n",
    "    return document\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    \n",
    "    #Page icons n tab name on browser tab\n",
    "    #img = Image.open(os.path.join(rootdir, 'pfizer.png'))\n",
    "    st.set_page_config(page_title = 'MAIA', page_icon = \":robot_face:\", layout=\"wide\")\n",
    "    \n",
    "    hide_default_format = \"\"\"\n",
    "       <style>\n",
    "       #MainMenu {visibility: hidden; }\n",
    "       footer {visibility: hidden;}\n",
    "       </style>\n",
    "       \"\"\"\n",
    "    st.markdown(hide_default_format, unsafe_allow_html=True)\n",
    "    \n",
    "    names = [\"admin\",\"shakti\"]\n",
    "    usernames = [\"adm\", \"shrp\"]\n",
    "    passwords = [\"abc123\", \"def456\"]\n",
    "\n",
    "    credentials = {\"usernames\":{}}\n",
    "    hashed_passwords = stauth.Hasher(passwords).generate()\n",
    "    \n",
    "    for uname, name, pwd in zip(usernames, names, hashed_passwords):\n",
    "        user_dict = {\"name\": name, \"password\": pwd}\n",
    "        credentials[\"usernames\"].update({uname: user_dict})\n",
    "\n",
    "    \n",
    "    #add a cookie which will be stored on client browser to save credentials till 30days\n",
    "    authenticator = stauth.Authenticate(credentials, \"pls_generator\", \"abcdef\", cookie_expiry_days = 30)\n",
    "\n",
    "    #u can locate the authenticator in the main body or the sidebar\n",
    "    name, authentication_status, username = authenticator.login(\"Login\", \"main\")\n",
    "    \n",
    "    if st.session_state[\"authentication_status\"] == False:\n",
    "        st.error(\"Username/password is incorrect\")\n",
    "        \n",
    "    if st.session_state[\"authentication_status\"] == None:\n",
    "        st.warning(\"Please enter your username and password\")\n",
    "        \n",
    "    if st.session_state[\"authentication_status\"]:\n",
    "        \n",
    "        #logout button on main container\n",
    "        authenticator.logout('Logout', 'main')\n",
    "        st.subheader(f'Welcome *{st.session_state[\"name\"]}*')\n",
    "        \n",
    "        #set bg image cover\n",
    "        set_bg_hack(os.path.join(rootdir, 'iqvia-bg.jpg'))\n",
    "        sidebar_bg(os.path.join(rootdir, 'iqvia-blue.png'))\n",
    "        header_bg(os.path.join(rootdir, 'iqvia-dark-blue.png'))\n",
    "\n",
    "        #setting banner image\n",
    "        st.image(Image.open(os.path.join(rootdir, 'Pfizer-AI.jpg')))\n",
    "        \n",
    "        selected_tab = option_menu(\n",
    "            menu_title=None,  # required\n",
    "            options=[\"PLS Generator\", \"RCT QnA\", \"RCT Chatbot\"],  # required\n",
    "            icons=[\"house\", \"book\", \"envelope\"],  # optional\n",
    "            menu_icon=\"cast\",  # optional\n",
    "            default_index=0,  # optional\n",
    "            orientation=\"horizontal\",\n",
    "            # styles={\n",
    "            #     \"container\": {\"padding\": \"0!important\"},\n",
    "            #     \"icon\": {\"color\": \"orange\", \"font-size\": \"25px\"},\n",
    "            #     \"nav-link\": {\n",
    "            #         \"font-size\": \"25px\",\n",
    "            #         \"text-align\": \"left\",\n",
    "            #         \"margin\": \"0px\",\n",
    "            #         \"--hover-color\": \"#eee\",\n",
    "            #     },\n",
    "            #     \"nav-link-selected\": {\"background-color\": \"green\"},\n",
    "            # },\n",
    "        )\n",
    "        \n",
    "        #setting input components on sidebar\n",
    "        with st.sidebar:\n",
    "\n",
    "            st.image(Image.open(os.path.join(rootdir, 'iqvia-logo.png')))\n",
    "            #setting title\n",
    "            st.markdown(\"\"\"<h3 style='text-align: center'>MAIA - Medical Affairs Intelligence Assistant</h3>\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "            # Step 1: Document Upload\n",
    "            st.subheader(\"Step 1: Upload Clinical trial document\")\n",
    "            uploaded_file = st.file_uploader(\"Upload document\", accept_multiple_files=False, type=[\"pdf\"])\n",
    "\n",
    "            # Step 2: User Inputs\n",
    "            st.subheader(\"Step 2: Define the tone and Grade of PLS\")\n",
    "            # Set default values for radio button and slider\n",
    "            default_tense = \"Completed\"\n",
    "            default_pls_grade = \"Low\"\n",
    "\n",
    "            # Radio button for tense selection\n",
    "            tense = st.radio(\"Current status of the study for writing tense\", options=[\"On-going\", \"Completed\", \"Upcoming\"], key=\"tense\", index=[\"On-going\", \"Completed\", \"Upcoming\"].index(default_tense), horizontal=True)\n",
    "            #st.write('<style>div.row-widget.stRadio > div{flex-direction:row;}</style>', unsafe_allow_html=True)\n",
    "\n",
    "            # Slider for PLS grade selection\n",
    "            #pls_grade = st.slider(\"Health Literacy Grade Reading level\", min_value=0, max_value=10, step=5, key=\"pls_grade\", value=default_pls_grade)\n",
    "            pls_grade = st.select_slider(\"Health Literacy Grade of audience\", options=[\"Low\", \"High\"], key=\"pls_grade\", value = default_pls_grade)\n",
    "\n",
    "            st.session_state.process_button = False\n",
    "            process_button = st.button(\"Process Documents\")\n",
    "            st.session_state.process_button = process_button\n",
    "            st.session_state.uploaded_file = uploaded_file\n",
    "            st.session_state.selected_tab = selected_tab\n",
    "        \n",
    "        #if st.session_state.process_button and st.session_state.uploaded_file:\n",
    "        #if process_button and uploaded_file:\n",
    "            \n",
    "            # Retrieve user inputs if you haven't initialized them to any variable, then retrieve from streamlit session state\n",
    "            # st.session_state.tense = tense\n",
    "            # st.session_state.pls_grade = pls_grade\n",
    "            \n",
    "        if st.session_state.selected_tab == \"RCT QnA\":\n",
    "            st.subheader(\"Ask your PDF 💬\")\n",
    "            # show user input\n",
    "            user_question = st.text_input(\"Ask a question about your PDF:\")\n",
    "            \n",
    "            if st.session_state.uploaded_file:              \n",
    "                \n",
    "                # extract the text\n",
    "                if uploaded_file is not None:\n",
    "                  pdf_reader = PdfReader(uploaded_file)\n",
    "                  text = \"\"\n",
    "                  for page in pdf_reader.pages:\n",
    "                    text += page.extract_text()\n",
    "\n",
    "                  # split into chunks\n",
    "                  text_splitter = CharacterTextSplitter(\n",
    "                    separator=\"\\n\",\n",
    "                    chunk_size=1000,\n",
    "                    chunk_overlap=200,\n",
    "                    length_function=len\n",
    "                  )\n",
    "                  chunks = text_splitter.split_text(text)\n",
    "\n",
    "                  # create embeddings\n",
    "                  embeddings = OpenAIEmbeddings()\n",
    "                  knowledge_base = FAISS.from_texts(chunks, embeddings)\n",
    "\n",
    "                  if user_question:\n",
    "                    docs = knowledge_base.similarity_search(user_question)\n",
    "\n",
    "                    llm = OpenAI()\n",
    "                    chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "                    with get_openai_callback() as cb:\n",
    "                      response = chain.run(input_documents=docs, question=user_question)\n",
    "                      print(cb)\n",
    "\n",
    "                    st.write(response)    \n",
    "            \n",
    "        if st.session_state.selected_tab == \"RCT Chatbot\":    \n",
    "            st.subheader(f\"You have selected {selected_tab}\")\n",
    "\n",
    "        if st.session_state.selected_tab == \"PLS Generator\":\n",
    "            if st.session_state.process_button and st.session_state.uploaded_file:\n",
    "                col1, col2 = st.columns([0.2,0.8], gap=\"large\")\n",
    "                with col1:\n",
    "                    input_file = save_uploadedfile(uploaded_file)\n",
    "                    pdf_file = os.path.join(datadir, uploaded_file.name) #rootdir + \"/\" + uploaded_file.name\n",
    "                    pdf_view = displayPDF(pdf_file)\n",
    "                with col2:\n",
    "                    with st.spinner(text='Processing research document you gave on the left to generate Plain Language Summary for you...⏳'):\n",
    "\n",
    "                        # Call the processing function on the uploaded documents with user inputs\n",
    "                        replacements = process_documents(pdf_file, tense, pls_grade)\n",
    "                        st.success(\"Processed Output to be filled up in the preferred PLS template\")\n",
    "\n",
    "                        #Display processed output\n",
    "                        #st.write(replacements)\n",
    "\n",
    "                # Store the replacements dictionary in session state\n",
    "                st.session_state.replacements = replacements\n",
    "\n",
    "            # Step 3: PPT Template Selection and Download\n",
    "            st.subheader(\"Step 3: Select PLS Template and Download\")\n",
    "\n",
    "            # Add radio buttons for template selection here    \n",
    "            default_template = \"Pfizer_Blue_PLS_Template\"\n",
    "            selected_template = st.radio(\"Select PPT Template\", options=[\"Pfizer_Blue_PLS_Template\", \"Pfizer_Red_PLS_Template\", \"Pfizer_Long_PLS_Template\"], index=[\"Pfizer_Blue_PLS_Template\", \"Pfizer_Red_PLS_Template\", \"Pfizer_Long_PLS_Template\"].index(default_template), horizontal=True)\n",
    "            #st.write('<style>div.row-widget.stRadio > div{flex-direction:row;}</style>', unsafe_allow_html=True)\n",
    "            #selected_template = pills(\"\", [\"Pfizer_Blue_PLS_Template\", \"Pfizer_Red_PLS_Template\", \"Pfizer_Long_PLS_Template\"], [\"🍀\", \"🎈\", \"🌈\"])\n",
    "\n",
    "            generate_ppt_button = st.button(\"Generate PLS\")\n",
    "\n",
    "            if generate_ppt_button:\n",
    "                # Retrieve the replacements dictionary from session state\n",
    "                replacements = st.session_state.replacements\n",
    "                st.session_state.process_button = False\n",
    "\n",
    "                if replacements:\n",
    "                    with st.spinner('Generating PLS slides for you...⏳'):\n",
    "                        # Call the postprocessing function to generate PPT content\n",
    "                        ppt_content = postprocess_to_ppt(replacements, selected_template)\n",
    "\n",
    "                        doc_content = postprocess_to_doc(replacements)\n",
    "\n",
    "                        # Display the PPT content using st.markdown or st.write\n",
    "                        #st.markdown(ppt_content, unsafe_allow_html=True)\n",
    "                        st.markdown(list(replacements.keys()))\n",
    "\n",
    "                        # Store the PPT content in session state\n",
    "                        st.session_state.ppt_content = ppt_content\n",
    "                        st.session_state.doc_content = doc_content\n",
    "\n",
    "                         # Step 4: PPT Download\n",
    "                        if \"ppt_content\" and \"doc_content\" in st.session_state:\n",
    "                            ppt_content = st.session_state.ppt_content\n",
    "                            doc_content = st.session_state.doc_content\n",
    "\n",
    "                            st.session_state.replacements = replacements\n",
    "                            st.session_state.process_button = False\n",
    "\n",
    "                            # Save the modified presentation object to a temporary file\n",
    "                            #ppt_output_file = f\"PLS_{replacements['<Title>']}_{datetime.now().strftime('%Y%m%d%H%M%S')}.pptx\"                    \n",
    "                            ppt_output_file = \"PLS_PPT.pptx\"\n",
    "                            #ppt_content.save(ppt_output_file)\n",
    "\n",
    "                            # save presentation as binary output\n",
    "                            binary_output = BytesIO()\n",
    "                            ppt_content.save(binary_output)\n",
    "\n",
    "                            binary_output_doc = BytesIO()\n",
    "                            doc_content.save(binary_output_doc)\n",
    "\n",
    "                            # display success message and download button\n",
    "                            st.success(':tada: The PLS template has been filled with above sections in ' + selected_template)\n",
    "\n",
    "                            # Provide the download link for the generated PPT\n",
    "                            st.download_button(\"Download PLS PPT\", data=binary_output.getvalue(), file_name=ppt_output_file, mime=\"application/vnd.openxmlformats-officedocument.presentationml.presentation\")\n",
    "                            st.download_button(\"Download PLS Doc\", data=binary_output_doc.getvalue(), file_name=\"PLS_DOC.docx\", mime=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\")\n",
    "                    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed87cce9-6d25-4174-9d38-ef54fa96de60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app9.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app9.py\n",
    "#enhancing - anonymized version for chandresh, removed pfizer banner and changed bg color; hidden the header running and footer;\n",
    "#anonymized the PPT generation buttons -  added image selector --add ctgov api call for some fields with streaming --baselined 7/26\n",
    "import os\n",
    "import urllib\n",
    "import urllib.request\n",
    "import base64\n",
    "import json\n",
    "import streamlit as st\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "from pptx.dml.color import RGBColor\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "from datetime import datetime  # Import the 'datetime' class from the 'datetime' module\n",
    "import time\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from shakti_stream_index import llama_vector_index\n",
    "from streamlit_pills import pills\n",
    "import streamlit_authenticator as stauth\n",
    "from streamlit_option_menu import option_menu\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.agents import create_json_agent, AgentExecutor\n",
    "from langchain.agents.agent_toolkits import JsonToolkit\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.requests import TextRequestsWrapper\n",
    "from langchain.tools.json.tool import JsonSpec\n",
    "from streamlit_image_select import image_select\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "from stqdm import stqdm\n",
    "import pickle\n",
    "\n",
    "rootdir = \"/home/cdsw/experimentation_project1/PLS_project\"\n",
    "datadir = \"/home/cdsw/experimentation_project1/PLS_project/data\"\n",
    "\n",
    "# def progress_bar_method(secs):\n",
    "#     # Code for your second asynchronous method goes here\n",
    "#     for i in stqdm(range(secs), backend=True, frontend=True):\n",
    "#         sleep(0.5)\n",
    "\n",
    "class StreamHandler(BaseCallbackHandler):\n",
    "    def __init__(self, container, initial_text=\"\", display_method='markdown'):\n",
    "        self.container = container\n",
    "        self.text = initial_text\n",
    "        self.display_method = display_method\n",
    "\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        self.text += token + \"/\"\n",
    "        display_function = getattr(self.container, self.display_method, None)\n",
    "        if display_function is not None:\n",
    "            display_function(self.text)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid display_method: {self.display_method}\")\n",
    "\n",
    "#function to set background image\n",
    "def set_bg_hack(main_bg):\n",
    "    '''\n",
    "    A function to unpack an image from root folder and set as bg.\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    The background.\n",
    "    '''\n",
    "    # set bg name\n",
    "    main_bg_ext = \"png\"\n",
    "        \n",
    "    st.markdown(\n",
    "         f\"\"\"\n",
    "         <style>\n",
    "         .stApp {{\n",
    "             background: url(data:image/{main_bg_ext};base64,{base64.b64encode(open(main_bg, \"rb\").read()).decode()});\n",
    "             background-size: cover\n",
    "         }}\n",
    "         </style>\n",
    "         \"\"\",\n",
    "         unsafe_allow_html=True\n",
    "     )\n",
    "\n",
    "def sidebar_bg(side_bg):\n",
    "\n",
    "   side_bg_ext = 'png'\n",
    "\n",
    "   st.markdown(\n",
    "      f\"\"\"\n",
    "      <style>\n",
    "      [data-testid=\"stSidebar\"] > div:first-child {{\n",
    "          background: url(data:image/{side_bg_ext};base64,{base64.b64encode(open(side_bg, \"rb\").read()).decode()});\n",
    "      }}\n",
    "      </style>\n",
    "      \"\"\",\n",
    "      unsafe_allow_html=True,\n",
    "      )\n",
    "    \n",
    "def header_bg(side_bg):\n",
    "\n",
    "   side_bg_ext = 'png'\n",
    "\n",
    "   st.markdown(\n",
    "      f\"\"\"\n",
    "      <style>\n",
    "      header.css-1avcm0n {{\n",
    "          background: url(data:image/{side_bg_ext};base64,{base64.b64encode(open(side_bg, \"rb\").read()).decode()});\n",
    "      }}\n",
    "      </style>\n",
    "      \"\"\",\n",
    "      unsafe_allow_html=True,\n",
    "      )\n",
    "    \n",
    "#function to read prompt from corresponding text file\n",
    "def prompt(file):\n",
    "    with open(file) as f:\n",
    "        return f.read()\n",
    "    \n",
    "#function to save a file\n",
    "def save_uploadedfile(uploaded_file):\n",
    "     with open(os.path.join(datadir, uploaded_file.name),\"wb\") as f:\n",
    "         f.write(uploaded_file.getbuffer())\n",
    "     return st.success(f\"\"\"Saved File:{uploaded_file.name} to directory\"\"\")\n",
    "\n",
    "@st.cache_data\n",
    "#function to display the PDF of a given file \n",
    "def displayPDF(file):\n",
    "    # Opening file from file path\n",
    "    with open(file, \"rb\") as f:\n",
    "        base64_pdf = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "    # Embedding PDF in HTML\n",
    "    pdf_display = F'<iframe src=\"data:application/pdf;base64,{base64_pdf}\" width=\"300\" height=\"1100\" type=\"application/pdf\"></iframe>'\n",
    "\n",
    "    # Displaying File\n",
    "    st.markdown(pdf_display, unsafe_allow_html=True)\n",
    "\n",
    "# Placeholder function for processing the uploaded documents\n",
    "def process_documents(NCT, uploaded_file, tense, pls_grade):\n",
    "    # Implement the document processing logic here\n",
    "\n",
    "    '''\n",
    "        replacements = {\n",
    "            \"<Title>\": GPTAPIcall(uploaded_file, \"'Title'\", tense, pls_grade),\n",
    "        #     \"<Subtitle>\": GPTAPIcall(uploaded_file, \"subtitle\", tense, pls_grade),\n",
    "            \"<Introduction>\": GPTAPIcall(uploaded_file, \"'Introduction'\", tense, pls_grade),\n",
    "        #     \"<Phonetics>\": GPTAPIcall(uploaded_file, \"phonetics\", tense, pls_grade),\n",
    "        #    \"<Key takeaway>\": GPTAPIcall(uploaded_file, \"'Key Takeaway'\", tense, pls_grade),\n",
    "        #    \"<Results>\": GPTAPIcall(uploaded_file, \"'Results'\", tense, pls_grade)\n",
    "        #     \"<Intro summary>\": GPTAPIcall(uploaded_file, \"conclusion\", tense, pls_grade)\n",
    "        }\n",
    "    '''\n",
    "    summary_replacements = {\n",
    "        \"<Title>\": \"\", #prompt(os.path.join(rootdir, 'title.txt'))\n",
    "        \"<Subtitle>\": \"\", #prompt(os.path.join(rootdir, 'subtitle.txt'))\n",
    "        \"<Key takeaway>\": \"\",\n",
    "        \"<Phonetics>\": \"\",\n",
    "        \"<Introduction>\": \"\",\n",
    "        \"<Intro summary>\": \"\",\n",
    "        # \"<Inclusion criteria>\": \"\",\n",
    "        # \"<Exclusion crtieria>\": \"\",\n",
    "        # \"<Results>\": \"\",\n",
    "        \"<Aims>\": \"\",\n",
    "        \"<Conclusions>\": \"\",\n",
    "        # \"<Sponsor>\": \"\",\n",
    "        # \"<More Information>\": \"\",\n",
    "    }\n",
    "        \n",
    "    # Get the text for each section using GPTAPIcall function\n",
    "    for section_name in summary_replacements:\n",
    "        \n",
    "        st.subheader(f\"\"\":red[{section_name[1:-1]} :]\"\"\")\n",
    "        text = GPTAPIcall(uploaded_file, section_name, tense, pls_grade)\n",
    "        summary_replacements[section_name] = str(text)\n",
    "        \n",
    "    ctgov_replacements = {\n",
    "                    \"<Start date>\": \"Answer the Study Start date in ```MMM-YYYY``` format\",\n",
    "                    \"<End date>\": \"Answer the Study End date in ```MMM-YYYY``` format\",\n",
    "                    \"<Participants>\": \"Total number of Participants in the study including drug arms, placebo arm, soc arm. Give one number answer\",\n",
    "                    \"<Arms count>\": \"Number of arms in the study including the drug arms, placebo arm, soc arm. Give one number answer\",\n",
    "                    \"<Disease condition>\": \"What is the disease condition for which drug is undergoing trials on patients in the study. Give answer as one disease\",\n",
    "                    \"<Demographics>\": \"What are the Demographics of participants in the study\",\n",
    "                    \"<treatment arm>\": \"Number of participants only in the drug arms of the study, do not count the participants from placebo arm or soc arm. Give one number answer\",\n",
    "                    \"<control arm>\": \"Number of participants in the placebo arm or soc arm. Give one number answer\",\n",
    "                    \"<Inclusion criteria>\": \"Inclusion criteria in EligibilityCriteria\",\n",
    "                    \"<Exclusion criteria>\": \"Exclusion criteria in EligibilityCriteria\",\n",
    "                    \"<Results>\": \"list all outcome measure results in bullets interms of outcome measure type, outcome measure title, outcome measure description, outcome measure value\",\n",
    "                    # \"<clinical trials gov link>\": \"https://clinicaltrials.gov/ct2/show/NCT03036813\",\n",
    "                    # \"<Summary date>\": datetime.now().strftime('%d-%b-%Y'),\n",
    "                    \"<Sponsor>\": \"Lead Sponsor Name\",\n",
    "                   }\n",
    "    \n",
    "    for section_name, query in ctgov_replacements.items():\n",
    "        \n",
    "        st.subheader(f\"\"\":red[{section_name[1:-1]} :]\"\"\")\n",
    "        text = CTGovAPIcall(NCT, query)\n",
    "        ctgov_replacements[section_name] = str(text)\n",
    "    \n",
    "    \n",
    "    replacements = {**summary_replacements, \n",
    "                    **ctgov_replacements, \n",
    "                    \"<Study number>\": f\"{NCT}\",\n",
    "                    \"<clinical trials gov link>\": f\"https://clinicaltrials.gov/ct2/show/{NCT}\",\n",
    "                    \"<Summary date>\": datetime.now().strftime('%d-%b-%Y'),\n",
    "                   }\n",
    "    \n",
    "    return replacements\n",
    "\n",
    "def CTGovAPIcall(NCT, query):\n",
    "    file_format = '&fmt=JSON'\n",
    "    expr = NCT #'A+Phase+3+Randomized+Trial+of+Voxelotor+in+Sickle+Cell+Disease' #or give NCT number here NCT03036813\n",
    "    ctgov = 'https://classic.clinicaltrials.gov/api/query/full_studies?expr='\n",
    "\n",
    "    your_url = (ctgov + expr + file_format)\n",
    "\n",
    "    with urllib.request.urlopen(your_url) as url:\n",
    "        ini_dict = json.loads(url.read().decode())\n",
    "        \n",
    "    json_spec = JsonSpec(dict_=ini_dict[\"FullStudiesResponse\"][\"FullStudies\"][0][\"Study\"], max_value_length=31000)\n",
    "    json_toolkit = JsonToolkit(spec=json_spec)\n",
    "    \n",
    "    chat_box = st.empty()\n",
    "    stream_handler = StreamHandler(chat_box, display_method='write')\n",
    "    \n",
    "    json_agent_executor = create_json_agent(\n",
    "        llm=ChatOpenAI(temperature=0, model_name=\"gpt-4-32k\", streaming=True, callbacks=[stream_handler],), toolkit=json_toolkit, verbose=True\n",
    "    )\n",
    "    resp = json_agent_executor.run(query)\n",
    "    st.write(resp)\n",
    "    return resp\n",
    "\n",
    "# Placeholder function for GPT API call\n",
    "def GPTAPIcall(uploaded_file, key, tense, pls_grade):\n",
    "    # Placeholder logic to generate values based on the key, tense, and PLS grade\n",
    "    # Replace this with your actual GPT API call or any other processing logic\n",
    "    # Convert tense strings\n",
    "    tense_mapping = {\"on-going\": \"present\", \"completed\": \"past\", \"upcoming\": \"future\"}\n",
    "    tense = tense_mapping.get(tense, tense)\n",
    "\n",
    "    # Placeholder value for the key with the tense and PLS grade\n",
    "    #value = f\"Placeholder value for {key} (Tense: {tense}, PLS Grade: {pls_grade})\"\n",
    "    query = f\"Strictly following the above instructions and the clinical trial document provided, write the content of {key} section of the APLS in {tense}, comprehendable by a {pls_grade} health literacy grade person. Do not violate the section-wise instructions provided in any case. The content should be strictly inferred from the clinical trial document provided only and not any other sources.\"\n",
    "    \n",
    "    return llama_vector_index(uploaded_file, prompt(os.path.join(rootdir, 'apls_persona_2606.txt')) + \"\\n\" + query) #f\"{key}.txt + instr\n",
    "\n",
    "# Placeholder function for postprocessing into PPT template\n",
    "def postprocess_to_ppt(replacements, selected_template):\n",
    "    # Implement the postprocessing logic here\n",
    "    # For demonstration purposes, we'll load a presentation object and copy the text from replacements dictionary\n",
    "    \n",
    "    #rootdir = os.path.realpath('./')\n",
    "    \n",
    "    #selected_template = \"PLS_PPT_Template\"\n",
    "    ppt_file = f\"{selected_template}.pptx\"\n",
    "    prs = Presentation(os.path.join(rootdir, ppt_file))\n",
    "\n",
    "    for slide in prs.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if shape.has_text_frame:\n",
    "                text_frame = shape.text_frame\n",
    "                for paragraph in text_frame.paragraphs:\n",
    "                    for run in paragraph.runs:\n",
    "                        for placeholder, new_text in replacements.items():\n",
    "                            if run.text == placeholder:\n",
    "                                # Preserve formatting of the first run in the paragraph\n",
    "                                first_run = paragraph.runs[0]\n",
    "                                font_size = first_run.font.size\n",
    "                                font_name = first_run.font.name\n",
    "                                font_bold = first_run.font.bold\n",
    "                                font_italic = first_run.font.italic\n",
    "\n",
    "                                # Check if font color is explicitly defined\n",
    "                                if first_run.font.color.type == \"rgb\":\n",
    "                                    font_color = first_run.font.color.rgb\n",
    "                                else:\n",
    "                                    font_color = None\n",
    "\n",
    "                                # Replace text while preserving formatting\n",
    "                                run.text = new_text\n",
    "\n",
    "                                # Apply preserved formatting to the entire paragraph\n",
    "                                for run in paragraph.runs:\n",
    "                                    run.font.size = font_size\n",
    "                                    run.font.name = font_name\n",
    "                                    run.font.bold = font_bold\n",
    "                                    run.font.italic = font_italic\n",
    "                                    if font_color:\n",
    "                                        run.font.color.rgb = font_color\n",
    "\n",
    "    # Return the modified presentation object\n",
    "    return prs\n",
    "\n",
    "\n",
    "# Placeholder function for postprocessing into DOC template\n",
    "def postprocess_to_doc(replacements):\n",
    "    # Create a new document\n",
    "    document = Document()\n",
    "\n",
    "    # Set the font size of the document\n",
    "    style = document.styles['Normal']\n",
    "    font = style.font\n",
    "    font.size = Pt(11)\n",
    "\n",
    "    # Set the title\n",
    "    title = replacements.get(\"Title\")\n",
    "    if title:\n",
    "        document.add_heading(title, level=1).bold = True\n",
    "\n",
    "    # Add sections and paragraphs\n",
    "    section_count = 0\n",
    "    for key, value in replacements.items():\n",
    "        if key != \"Title\":\n",
    "            section_count += 1\n",
    "            if section_count <= 12:\n",
    "                document.add_heading(key, level=1)\n",
    "                if value:\n",
    "                    document.add_paragraph(value)\n",
    "\n",
    "    # Add the table\n",
    "    table_replacements = {k: v for k, v in replacements.items() if k != \"Title\" and k not in list(replacements.keys())[1:13]}\n",
    "    if table_replacements:\n",
    "        table_heading = \"Additional Information\"\n",
    "        document.add_heading(table_heading, level=1)\n",
    "\n",
    "        # Create the table\n",
    "        table = document.add_table(rows=1, cols=2)\n",
    "        table.style = 'Table Grid'\n",
    "        \n",
    "        # Set table column widths\n",
    "        table.autofit = False\n",
    "        table.columns[0].width = Pt(200)\n",
    "        table.columns[1].width = Pt(300)\n",
    "\n",
    "        # Add table headers\n",
    "        table_header_cells = table.rows[0].cells\n",
    "        table_header_cells[0].text = \"Variable\"\n",
    "        table_header_cells[1].text = \"Value\"\n",
    "        for cell in table_header_cells:\n",
    "            cell.paragraphs[0].alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "            cell.paragraphs[0].bold = True\n",
    "\n",
    "        # Add table rows\n",
    "        for key, value in table_replacements.items():\n",
    "            row_cells = table.add_row().cells\n",
    "            row_cells[0].text = key\n",
    "            row_cells[1].text = value\n",
    "\n",
    "    return document\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    \n",
    "    #Page icons n tab name on browser tab\n",
    "    #img = Image.open(os.path.join(rootdir, 'pfizer.png'))\n",
    "    st.set_page_config(page_title = 'MAIA', page_icon = \":robot_face:\", layout=\"wide\")\n",
    "    \n",
    "    #to hide the hamburger running on top right and footer of streamlit\n",
    "    hide_default_format = \"\"\"\n",
    "       <style>\n",
    "       #MainMenu {visibility: hidden; }\n",
    "       footer {visibility: hidden;}\n",
    "       </style>\n",
    "       \"\"\"\n",
    "    st.markdown(hide_default_format, unsafe_allow_html=True)\n",
    "    \n",
    "    names = [\"admin\",\"shakti\"]\n",
    "    usernames = [\"adm\", \"shrp\"]\n",
    "    passwords = [\"abc123\", \"def456\"]\n",
    "\n",
    "    credentials = {\"usernames\":{}}\n",
    "    hashed_passwords = stauth.Hasher(passwords).generate()\n",
    "    \n",
    "    for uname, name, pwd in zip(usernames, names, hashed_passwords):\n",
    "        user_dict = {\"name\": name, \"password\": pwd}\n",
    "        credentials[\"usernames\"].update({uname: user_dict})\n",
    "\n",
    "    \n",
    "    #add a cookie which will be stored on client browser to save credentials till 30days\n",
    "    authenticator = stauth.Authenticate(credentials, \"pls_generator\", \"abcdef\", cookie_expiry_days = 30)\n",
    "\n",
    "    #u can locate the authenticator in the main body or the sidebar\n",
    "    name, authentication_status, username = authenticator.login(\"Login\", \"main\")\n",
    "    \n",
    "    if st.session_state[\"authentication_status\"] == False:\n",
    "        st.error(\"Username/password is incorrect\")\n",
    "        \n",
    "    if st.session_state[\"authentication_status\"] == None:\n",
    "        st.warning(\"Please enter your username and password\")\n",
    "        \n",
    "    if st.session_state[\"authentication_status\"]:\n",
    "        \n",
    "        #logout button on main container\n",
    "        authenticator.logout('Logout', 'main')\n",
    "        st.subheader(f'Welcome *{st.session_state[\"name\"]}*')\n",
    "        \n",
    "        #set bg image cover\n",
    "        #set_bg_hack(os.path.join(rootdir, 'iqvia-dark-blue.png'))\n",
    "        sidebar_bg(os.path.join(rootdir, 'iqvia-blue.png'))\n",
    "        #header_bg(os.path.join(rootdir, 'iqvia-dark-blue.png'))\n",
    "\n",
    "        #setting banner image\n",
    "        #st.image(Image.open(os.path.join(rootdir, 'Pfizer-AI.jpg')))\n",
    "        \n",
    "        selected_tab = option_menu(\n",
    "            menu_title=None,  # required\n",
    "            options=[\"PLS Generator\", \"RCT QnA\", \"RCT WordCloud\"],  # required\n",
    "            icons=[\"house\", \"book\", \"envelope\"],  # optional\n",
    "            menu_icon=\"cast\",  # optional\n",
    "            default_index=0,  # optional\n",
    "            orientation=\"horizontal\",\n",
    "            # styles={\n",
    "            #     \"container\": {\"padding\": \"0!important\"},\n",
    "            #     \"icon\": {\"color\": \"orange\", \"font-size\": \"25px\"},\n",
    "            #     \"nav-link\": {\n",
    "            #         \"font-size\": \"25px\",\n",
    "            #         \"text-align\": \"left\",\n",
    "            #         \"margin\": \"0px\",\n",
    "            #         \"--hover-color\": \"#eee\",\n",
    "            #     },\n",
    "            #     \"nav-link-selected\": {\"background-color\": \"green\"},\n",
    "            # },\n",
    "        )\n",
    "        \n",
    "        #setting input components on sidebar\n",
    "        with st.sidebar:\n",
    "\n",
    "            st.image(Image.open(os.path.join(rootdir, 'iqvia-logo.png')))\n",
    "            #setting title\n",
    "            st.markdown(\"\"\"<h3 style='text-align: center'>*MAIA - Medical Affairs Intelligence Assistant*</h3>\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "            # Step 1: Document Upload\n",
    "            st.subheader(\"Step 1: Upload Clinical trial document\")\n",
    "            uploaded_file = st.file_uploader(\"Upload document\", accept_multiple_files=False, type=[\"pdf\"])\n",
    "            \n",
    "            NCT = st.text_input(\"Enter the NCT number:\", \"NCT\", key=\"NCT\")\n",
    "            \n",
    "            # Step 2: User Inputs\n",
    "            st.subheader(\"Step 2: Define the tone and Grade of PLS\")\n",
    "            # Set default values for radio button and slider\n",
    "            default_tense = \"Completed\"\n",
    "            default_pls_grade = \"Low\"\n",
    "\n",
    "            # Radio button for tense selection\n",
    "            tense = st.radio(\"Current status of the study for writing tense\", options=[\"On-going\", \"Completed\", \"Upcoming\"], key=\"tense\", index=[\"On-going\", \"Completed\", \"Upcoming\"].index(default_tense), horizontal=True)\n",
    "            #st.write('<style>div.row-widget.stRadio > div{flex-direction:row;}</style>', unsafe_allow_html=True)\n",
    "\n",
    "            # Slider for PLS grade selection\n",
    "            #pls_grade = st.slider(\"Health Literacy Grade Reading level\", min_value=0, max_value=10, step=5, key=\"pls_grade\", value=default_pls_grade)\n",
    "            pls_grade = st.select_slider(\"Health Literacy Grade of audience\", options=[\"Low\", \"High\"], key=\"pls_grade\", value = default_pls_grade)\n",
    "\n",
    "            st.session_state.process_button = False\n",
    "            process_button = st.button(\"Process Documents\")\n",
    "            st.session_state.process_button = process_button\n",
    "            st.session_state.uploaded_file = uploaded_file\n",
    "            st.session_state.selected_tab = selected_tab\n",
    "        \n",
    "        #if st.session_state.process_button and st.session_state.uploaded_file:\n",
    "        #if process_button and uploaded_file:\n",
    "            \n",
    "            # Retrieve user inputs if you haven't initialized them to any variable, then retrieve from streamlit session state\n",
    "            # st.session_state.tense = tense\n",
    "            # st.session_state.pls_grade = pls_grade\n",
    "            \n",
    "        if st.session_state.selected_tab == \"RCT QnA\":\n",
    "            st.subheader(\"Ask your PDF 💬\")\n",
    "            # show user input\n",
    "            user_question = st.text_input(\"Ask a question about your PDF:\", placeholder=\"Number of participants? \", disabled=not uploaded_file,)\n",
    "            \n",
    "            if st.session_state.uploaded_file:              \n",
    "                \n",
    "                # extract the text\n",
    "                if uploaded_file is not None:\n",
    "                  pdf_reader = PdfReader(uploaded_file)\n",
    "                  text = \"\"\n",
    "                  for page in pdf_reader.pages:\n",
    "                    text += page.extract_text()\n",
    "\n",
    "                  # split into chunks\n",
    "                  text_splitter = CharacterTextSplitter(\n",
    "                    separator=\"\\n\",\n",
    "                    chunk_size=1000,\n",
    "                    chunk_overlap=200,\n",
    "                    length_function=len\n",
    "                  )\n",
    "                  chunks = text_splitter.split_text(text)\n",
    "                    \n",
    "                  # create embeddings\n",
    "                  store_name = uploaded_file.name[:-4]\n",
    "                  if os.path.exists(os.path.join(datadir, f\"{store_name}.pkl\")):\n",
    "                    with open(os.path.join(datadir, f\"{store_name}.pkl\"), \"rb\") as f:\n",
    "                        knowledge_base = pickle.load(f)\n",
    "                        st.write('Embeddings loaded from the Disk:')\n",
    "                  else:\n",
    "                    embeddings = OpenAIEmbeddings()\n",
    "                    knowledge_base = FAISS.from_texts(chunks, embeddings)\n",
    "                    with open(os.path.join(datadir, f\"{store_name}.pkl\"), \"wb\") as f:\n",
    "                        pickle.dump(knowledge_base, f)\n",
    "                        st.write('Embeddings newly created')\n",
    "\n",
    "                  if user_question:\n",
    "                    docs = knowledge_base.similarity_search(user_question, k=3)\n",
    "\n",
    "                    chat_box = st.empty()\n",
    "                    stream_handler = StreamHandler(chat_box, display_method='write')\n",
    "        \n",
    "                    llm = ChatOpenAI(temperature=0, callbacks=[stream_handler], streaming=True)\n",
    "                    chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "                    \n",
    "                    #get_openai_callback() gives the cost on console\n",
    "                    # with get_openai_callback() as cb:\n",
    "                    #   response = chain.run(input_documents=docs, question=user_question)\n",
    "                    #   print(cb)\n",
    "                    response = chain.run(input_documents=docs, question=user_question)\n",
    "                    st.write(response)    \n",
    "            \n",
    "        if st.session_state.selected_tab == \"RCT WordCloud\":    \n",
    "            #st.subheader(f\"You have selected {selected_tab}\")\n",
    "            \n",
    "            # extract the text\n",
    "            if uploaded_file is not None:\n",
    "                pdf_reader = PdfReader(uploaded_file)\n",
    "                text = \"\"\n",
    "                for page in pdf_reader.pages:\n",
    "                    text += page.extract_text()\n",
    "\n",
    "                # Create and generate a word cloud image:\n",
    "                wordcloud = WordCloud().generate(text)\n",
    "\n",
    "                # Display the generated image:\n",
    "                plt.imshow(wordcloud, interpolation='bilinear')\n",
    "                plt.axis(\"off\")\n",
    "                plt.show()\n",
    "                st.set_option('deprecation.showPyplotGlobalUse', False)\n",
    "                st.pyplot()\n",
    "            \n",
    "        if st.session_state.selected_tab == \"PLS Generator\":\n",
    "            if st.session_state.process_button and st.session_state.uploaded_file and st.session_state.NCT!='NCT':\n",
    "                col1, col2 = st.columns([0.2,0.8], gap=\"large\")\n",
    "                with col1:\n",
    "                    input_file = save_uploadedfile(uploaded_file)\n",
    "                    pdf_file = os.path.join(datadir, uploaded_file.name) #rootdir + \"/\" + uploaded_file.name\n",
    "                    pdf_view = displayPDF(pdf_file)\n",
    "                with col2:\n",
    "                    with st.spinner(text='Processing research document you gave on the left to generate Plain Language Summary for you...⏳'):\n",
    "\n",
    "                        # Progress bar\n",
    "                        #progress_bar_method(50) or st.progress(0, \"text\")\n",
    "                        \n",
    "                        # Call the processing function on the uploaded documents with user inputs\n",
    "                        replacements = process_documents(NCT, pdf_file, tense, pls_grade)\n",
    "                        st.success(\"Processed Output to be filled up in the preferred PLS template\")\n",
    "\n",
    "                        #Display processed output\n",
    "                        #st.write(replacements)\n",
    "                        st.snow()\n",
    "                        st.balloons()\n",
    "                        \n",
    "                # Store the replacements dictionary in session state\n",
    "                st.session_state.replacements = replacements\n",
    "\n",
    "            # Step 3: PPT Template Selection and Download\n",
    "            st.subheader(\"Step 3: Select PLS Template and Download\")\n",
    "            \n",
    "            default_format = \"PPT format\"\n",
    "            st.session_state.select_format = pills(\"Select PPT or Word format\", [\"PPT format\", \"Word format\"], [\"🎈\", \"🌈\"], index=[\"PPT format\", \"Word format\"].index(default_format))\n",
    "            \n",
    "            if st.session_state.select_format == \"PPT format\":\n",
    "                # Add radio buttons for template selection here    \n",
    "                default_template = \"Blue_PLS_Template\"\n",
    "                selected_template = image_select(\n",
    "                    label=\"Select PPT Template\",\n",
    "                    images=[\n",
    "                        os.path.join(rootdir, 'Pfizer_Blue_PLS_Template.png'),\n",
    "                        os.path.join(rootdir, 'Pfizer_Red_PLS_Template.png'),\n",
    "                        os.path.join(rootdir, 'Pfizer_Long_PLS_Template.png'),\n",
    "                    ],\n",
    "                    captions=[\"Blue_PLS_Template\", \"Red_PLS_Template\", \"Long_PLS_Template\"],\n",
    "                    index=[\"Blue_PLS_Template\", \"Red_PLS_Template\", \"Long_PLS_Template\"].index(default_template),\n",
    "                    use_container_width = False,\n",
    "                )\n",
    "                #selected_template = st.radio(\"Select PPT Template\", options=[\"Blue_PLS_Template\", \"Red_PLS_Template\", \"Long_PLS_Template\"], index=[\"Blue_PLS_Template\", \"Red_PLS_Template\", \"Long_PLS_Template\"].index(default_template), horizontal=True)\n",
    "                #selected_template = pills(\"\", [\"Pfizer_Blue_PLS_Template\", \"Pfizer_Red_PLS_Template\", \"Pfizer_Long_PLS_Template\"], [\"🍀\", \"🎈\", \"🌈\"])\n",
    "            \n",
    "            if st.session_state.select_format == \"Word format\":\n",
    "                default_template = \"Word_PLS_Template\"\n",
    "                selected_template = \"Blue_PLS_Template\"\n",
    "                image_select(\n",
    "                    label=\"Select Word Template\",\n",
    "                    images=[\n",
    "                        os.path.join(rootdir, 'Pfizer_Word_PLS_Template.png'),\n",
    "                    ],\n",
    "                    captions=[\"Word_PLS_Template\"],\n",
    "                    index=[\"Word_PLS_Template\"].index(default_template),\n",
    "                    use_container_width = False,\n",
    "                )\n",
    "            \n",
    "            generate_ppt_button = st.button(\"Generate PLS\")\n",
    "\n",
    "            if generate_ppt_button:\n",
    "                # Retrieve the replacements dictionary from session state\n",
    "                replacements = st.session_state.replacements\n",
    "                st.session_state.process_button = False\n",
    "\n",
    "                if replacements:\n",
    "                    with st.spinner('Generating PLS slides for you...⏳'):\n",
    "                        # Call the postprocessing function to generate PPT content\n",
    "                        ppt_content = postprocess_to_ppt(replacements, selected_template)\n",
    "\n",
    "                        doc_content = postprocess_to_doc(replacements)\n",
    "\n",
    "                        # Display the PPT content using st.markdown or st.write\n",
    "                        #st.markdown(ppt_content, unsafe_allow_html=True)\n",
    "                        st.markdown(list(replacements.keys()))\n",
    "\n",
    "                        # Store the PPT content in session state\n",
    "                        st.session_state.ppt_content = ppt_content\n",
    "                        st.session_state.doc_content = doc_content\n",
    "\n",
    "                         # Step 4: PPT Download\n",
    "                        if \"ppt_content\" and \"doc_content\" in st.session_state:\n",
    "                            ppt_content = st.session_state.ppt_content\n",
    "                            doc_content = st.session_state.doc_content\n",
    "\n",
    "                            st.session_state.replacements = replacements\n",
    "                            st.session_state.process_button = False\n",
    "\n",
    "                            # Save the modified presentation object to a temporary file\n",
    "                            #ppt_output_file = f\"PLS_{replacements['<Title>']}_{datetime.now().strftime('%Y%m%d%H%M%S')}.pptx\"                    \n",
    "                            ppt_output_file = \"PLS_PPT.pptx\"\n",
    "                            #ppt_content.save(ppt_output_file)\n",
    "\n",
    "                            # save presentation as binary output\n",
    "                            binary_output = BytesIO()\n",
    "                            ppt_content.save(binary_output)\n",
    "\n",
    "                            binary_output_doc = BytesIO()\n",
    "                            doc_content.save(binary_output_doc)\n",
    "\n",
    "                            # display success message and download button\n",
    "                            st.success(':tada: The PLS template has been filled with above sections in ' + selected_template)\n",
    "\n",
    "                            # Provide the download link for the generated PPT and DOC\n",
    "                            if st.session_state.select_format == \"PPT format\":\n",
    "                                st.download_button(\"Download PLS PPT\", data=binary_output.getvalue(), file_name=ppt_output_file, mime=\"application/vnd.openxmlformats-officedocument.presentationml.presentation\")\n",
    "                            if st.session_state.select_format == \"Word format\":\n",
    "                                st.download_button(\"Download PLS Doc\", data=binary_output_doc.getvalue(), file_name=\"PLS_DOC.docx\", mime=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\")\n",
    "                    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f7b1c1e-fd20-44ce-bd03-27215ba16e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app8.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app8.py\n",
    "#enhancing - working version, adding independent prompts to compare outputs; fixed ppt call error .png, fixed word formatting; \n",
    "#compare this file with previous file and incorporate changes in prev file; added regex for participants\n",
    "#added chatbot on docs and sentiment analyzer; removed stop words and query words in word cloud\n",
    "#added wordfreq bars also as Word Analytics --- baselining it and creating a separate version below for adding pubmed/ctgov\n",
    "import os\n",
    "import re\n",
    "import urllib\n",
    "import urllib.request\n",
    "import base64\n",
    "import json\n",
    "import streamlit as st\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "from pptx.dml.color import RGBColor\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "from datetime import datetime  # Import the 'datetime' class from the 'datetime' module\n",
    "import time\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from shakti_stream_index import llama_vector_index\n",
    "from streamlit_pills import pills\n",
    "import streamlit_authenticator as stauth\n",
    "from streamlit_option_menu import option_menu\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.agents import create_json_agent, AgentExecutor\n",
    "from langchain.agents.agent_toolkits import JsonToolkit\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.requests import TextRequestsWrapper\n",
    "from langchain.tools.json.tool import JsonSpec\n",
    "from streamlit_image_select import image_select\n",
    "from streamlit_chat import message\n",
    "from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index import download_loader, StorageContext, load_index_from_storage\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#load inthe NTLK stopwords to remove articles, preposition and other words that are not actionable\n",
    "from nltk.corpus import stopwords\n",
    "# This allows to create individual objects from a bog of words\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Lemmatizer helps to reduce words to the base form\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Ngrams allows to group words in common pairs or trigrams..etc\n",
    "from nltk import ngrams\n",
    "# We can use counter to count the objects\n",
    "from collections import Counter\n",
    "# This is our visual library\n",
    "import seaborn as sns\n",
    "from time import sleep\n",
    "from stqdm import stqdm\n",
    "import itertools\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "saved_path = \"/home/cdsw/experimentation_project1/PLS_project/bot_data\"\n",
    "rootdir = \"/home/cdsw/experimentation_project1/PLS_project\"\n",
    "datadir = \"/home/cdsw/experimentation_project1/PLS_project/data\"\n",
    "promptdir = \"/home/cdsw/experimentation_project1/PLS_project/prompts\"\n",
    "\n",
    "# def progress_bar_method(secs):\n",
    "#     # Code for your second asynchronous method goes here\n",
    "#     for i in stqdm(range(secs), backend=True, frontend=True):\n",
    "#         sleep(0.5)\n",
    "\n",
    "class StreamHandler(BaseCallbackHandler):\n",
    "    def __init__(self, container, initial_text=\"\", display_method='markdown'):\n",
    "        self.container = container\n",
    "        self.text = initial_text\n",
    "        self.display_method = display_method\n",
    "\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        self.text += token + \"/\"\n",
    "        display_function = getattr(self.container, self.display_method, None)\n",
    "        if display_function is not None:\n",
    "            display_function(self.text)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid display_method: {self.display_method}\")\n",
    "\n",
    "#function to set background image\n",
    "def set_bg_hack(main_bg):\n",
    "    '''\n",
    "    A function to unpack an image from root folder and set as bg.\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    The background.\n",
    "    '''\n",
    "    # set bg name\n",
    "    main_bg_ext = \"png\"\n",
    "        \n",
    "    st.markdown(\n",
    "         f\"\"\"\n",
    "         <style>\n",
    "         .stApp {{\n",
    "             background: url(data:image/{main_bg_ext};base64,{base64.b64encode(open(main_bg, \"rb\").read()).decode()});\n",
    "             background-size: cover\n",
    "         }}\n",
    "         </style>\n",
    "         \"\"\",\n",
    "         unsafe_allow_html=True\n",
    "     )\n",
    "\n",
    "def sidebar_bg(side_bg):\n",
    "\n",
    "   side_bg_ext = 'png'\n",
    "\n",
    "   st.markdown(\n",
    "      f\"\"\"\n",
    "      <style>\n",
    "      [data-testid=\"stSidebar\"] > div:first-child {{\n",
    "          background: url(data:image/{side_bg_ext};base64,{base64.b64encode(open(side_bg, \"rb\").read()).decode()});\n",
    "      }}\n",
    "      </style>\n",
    "      \"\"\",\n",
    "      unsafe_allow_html=True,\n",
    "      )\n",
    "    \n",
    "def header_bg(side_bg):\n",
    "\n",
    "   side_bg_ext = 'png'\n",
    "\n",
    "   st.markdown(\n",
    "      f\"\"\"\n",
    "      <style>\n",
    "      header.css-1avcm0n {{\n",
    "          background: url(data:image/{side_bg_ext};base64,{base64.b64encode(open(side_bg, \"rb\").read()).decode()});\n",
    "      }}\n",
    "      </style>\n",
    "      \"\"\",\n",
    "      unsafe_allow_html=True,\n",
    "      )\n",
    "\n",
    "def get_sentiment(polarity):\n",
    "    if polarity < 0.0:\n",
    "        return 'Negative'\n",
    "    elif polarity > 0.2:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "    \n",
    "def word_frequency(sentence):\n",
    "    # joins all the sentenses\n",
    "    #sentence = \" \".join(sentence)\n",
    "    # creates tokens, creates lower class, removes numbers and lemmatizes the words\n",
    "    new_tokens = word_tokenize(sentence)\n",
    "    new_tokens = [t.lower() for t in new_tokens]\n",
    "    new_tokens =[t for t in new_tokens if t not in stopwords.words('english')]\n",
    "    new_tokens = [t for t in new_tokens if t.isalpha()]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    new_tokens =[lemmatizer.lemmatize(t) for t in new_tokens]\n",
    "    #counts the words, pairs and trigrams\n",
    "    counted = Counter(new_tokens)\n",
    "    counted_2= Counter(ngrams(new_tokens,2))\n",
    "    counted_3= Counter(ngrams(new_tokens,3))\n",
    "    #creates 3 data frames and returns thems\n",
    "    word_freq = pd.DataFrame(counted.items(),columns=['word','frequency']).sort_values(by='frequency',ascending=False)\n",
    "    word_pairs =pd.DataFrame(counted_2.items(),columns=['pairs','frequency']).sort_values(by='frequency',ascending=False)\n",
    "    trigrams =pd.DataFrame(counted_3.items(),columns=['trigrams','frequency']).sort_values(by='frequency',ascending=False)\n",
    "    return word_freq,word_pairs,trigrams    \n",
    "    \n",
    "#function to read prompt from corresponding text file\n",
    "def prompt(file):\n",
    "    with open(file) as f:\n",
    "        return f.read()\n",
    "    \n",
    "#function to save a file\n",
    "def save_uploadedfile(uploaded_file):\n",
    "     with open(os.path.join(datadir, uploaded_file.name),\"wb\") as f:\n",
    "         f.write(uploaded_file.getbuffer())\n",
    "     return st.success(f\"\"\"Saved File:{uploaded_file.name} to directory\"\"\")\n",
    "\n",
    "def create_vector():\n",
    "    documents = SimpleDirectoryReader(saved_path).load_data()\n",
    "    index = GPTVectorStoreIndex.from_documents(documents)\n",
    "\n",
    "    storage_context = StorageContext.from_defaults()\n",
    "    index.storage_context.persist(\"./vectordatabase\")\n",
    "    #print (\"Done\")\n",
    "\n",
    "def generate_response(prompt):\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"./vectordatabase\")\n",
    "    index = load_index_from_storage(storage_context)\n",
    "    query_engin = index.as_query_engine() \n",
    "    question = prompt\n",
    "    response = query_engin.query(question)\n",
    "    return str(response)\n",
    "    #print (\"\\n\", response)\n",
    "\n",
    "@st.cache_data\n",
    "#function to display the PDF of a given file \n",
    "def displayPDF(file):\n",
    "    # Opening file from file path\n",
    "    with open(file, \"rb\") as f:\n",
    "        base64_pdf = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "    # Embedding PDF in HTML\n",
    "    pdf_display = F'<iframe src=\"data:application/pdf;base64,{base64_pdf}\" width=\"300\" height=\"1100\" type=\"application/pdf\"></iframe>'\n",
    "\n",
    "    # Displaying File\n",
    "    st.markdown(pdf_display, unsafe_allow_html=True)\n",
    "\n",
    "# Placeholder function for processing the uploaded documents\n",
    "def process_documents(NCT, uploaded_file, tense, pls_grade):\n",
    "    # Implement the document processing logic here\n",
    "\n",
    "    # Convert tense strings\n",
    "    tense_mapping = {\"on-going\": \"present\", \"completed\": \"past\", \"upcoming\": \"future\"}\n",
    "    tense = tense_mapping.get(tense, tense)\n",
    "    \n",
    "    summary_replacements = {\n",
    "        \"<Title>\": prompt(os.path.join(promptdir, 'title.txt')),\n",
    "        \"<Subtitle>\": prompt(os.path.join(promptdir, 'subtitle.txt')),\n",
    "        \"<Key takeaway>\": prompt(os.path.join(promptdir, 'key_takeaway.txt')),\n",
    "        \"<Phonetics>\": prompt(os.path.join(promptdir, 'phonetics.txt')), \n",
    "        \"<Introduction>\": prompt(os.path.join(promptdir, 'introduction.txt')), \n",
    "        \"<Intro summary>\": prompt(os.path.join(promptdir, 'intro_summary.txt')),\n",
    "        # \"<Inclusion criteria>\": \"\",\n",
    "        # \"<Exclusion crtieria>\": \"\",\n",
    "        # \"<Results>\": \"\",\n",
    "        \"<Aims>\": prompt(os.path.join(promptdir, 'aims.txt')),\n",
    "        \"<Conclusions>\": prompt(os.path.join(promptdir, 'conclusions.txt')),\n",
    "        # \"<Sponsor>\": \"\",\n",
    "        # \"<More Information>\": \"\",\n",
    "    }\n",
    "        \n",
    "    # Get the text for each section using GPTAPIcall function\n",
    "    for section_name, summary_prompt in summary_replacements.items():\n",
    "        \n",
    "        #prompt for pls grade and tense\n",
    "        query = f\"Strictly following the above instructions and the research document provided, write the content of {section_name} section of the plain language summary in {tense} tense.\\\n",
    "        Do not violate the section-wise instructions provided in any case. The content should be strictly inferred from the research document provided and not any other sources.\"\n",
    "        \n",
    "        st.subheader(f\"\"\":red[{section_name[1:-1]} :]\"\"\")\n",
    "        text = llama_vector_index(uploaded_file, prompt(os.path.join(promptdir, f'apls_persona_{pls_grade}_literacy.txt')) + \"\\n\" + summary_prompt + \"\\n\" + query)\n",
    "        summary_replacements[section_name] = str(text)\n",
    "        \n",
    "    ctgov_replacements = {\n",
    "                    \"<Start date>\": \"Answer the Study Start date in ```MMM-YYYY``` format\",\n",
    "                    \"<End date>\": \"Answer the Study End date in ```MMM-YYYY``` format\",\n",
    "                    \"<Participants>\": \"Total number of Participants in the study including drug arms, placebo arm, soc arm. Give one number answer\",\n",
    "                    \"<Arms count>\": \"Number of arms in the study including the drug arms, placebo arm, soc arm. Give one number answer\",\n",
    "                    \"<Disease condition>\": \"What is the disease condition for which drug is undergoing trials on patients in the study. Give answer as one disease\",\n",
    "                    \"<Demographics>\": \"What are the Demographics of participants in the study\",\n",
    "                    \"<treatment arm>\": \"Number of participants only in the drug arms of the study, do not count the participants from placebo arm or soc arm. Give one number answer\",\n",
    "                    \"<control arm>\": \"Number of participants in the placebo arm or soc arm. Give one number answer\",\n",
    "                    \"<Inclusion criteria>\": \"Inclusion criteria in EligibilityCriteria\",\n",
    "                    \"<Exclusion criteria>\": \"Exclusion criteria in EligibilityCriteria\",\n",
    "                    \"<Results>\": \"list all outcome measure results in bullets interms of outcome measure type, outcome measure title, outcome measure description, outcome measure value\",\n",
    "                    # \"<clinical trials gov link>\": \"https://clinicaltrials.gov/ct2/show/NCT03036813\",\n",
    "                    # \"<Summary date>\": datetime.now().strftime('%d-%b-%Y'),\n",
    "                    \"<Sponsor>\": \"Lead Sponsor Name\",\n",
    "                   }\n",
    "    \n",
    "    for section_name, ctgov_prompt in ctgov_replacements.items():\n",
    "        \n",
    "        st.subheader(f\"\"\":red[{section_name[1:-1]} :]\"\"\")\n",
    "        text = CTGovAPIcall(NCT, ctgov_prompt)\n",
    "        if section_name==\"<Participants>\":\n",
    "            text = re.findall(r'\\d+', text)\n",
    "        ctgov_replacements[section_name] = str(text)\n",
    "    \n",
    "    \n",
    "    replacements = {**summary_replacements, \n",
    "                    **ctgov_replacements, \n",
    "                    \"<Study number>\": f\"{NCT}\",\n",
    "                    \"<clinical trials gov link>\": f\"https://clinicaltrials.gov/ct2/show/{NCT}\",\n",
    "                    \"<Summary date>\": datetime.now().strftime('%d-%b-%Y'),\n",
    "                   }\n",
    "    \n",
    "    return replacements\n",
    "\n",
    "def CTGovAPIcall(NCT, query):\n",
    "    file_format = '&fmt=JSON'\n",
    "    expr = NCT #'A+Phase+3+Randomized+Trial+of+Voxelotor+in+Sickle+Cell+Disease' #or give NCT number here NCT03036813\n",
    "    ctgov = 'https://classic.clinicaltrials.gov/api/query/full_studies?expr='\n",
    "\n",
    "    your_url = (ctgov + expr + file_format)\n",
    "\n",
    "    with urllib.request.urlopen(your_url) as url:\n",
    "        ini_dict = json.loads(url.read().decode())\n",
    "        \n",
    "    json_spec = JsonSpec(dict_=ini_dict[\"FullStudiesResponse\"][\"FullStudies\"][0][\"Study\"], max_value_length=31000)\n",
    "    json_toolkit = JsonToolkit(spec=json_spec)\n",
    "    \n",
    "    chat_box = st.empty()\n",
    "    stream_handler = StreamHandler(chat_box, display_method='write')\n",
    "    \n",
    "    json_agent_executor = create_json_agent(\n",
    "        llm=ChatOpenAI(temperature=0, model_name=\"gpt-4-32k\", streaming=True, callbacks=[stream_handler],), toolkit=json_toolkit, verbose=True\n",
    "    )\n",
    "    resp = json_agent_executor.run(query)\n",
    "    st.write(resp)\n",
    "    return resp\n",
    "    \n",
    "# Placeholder function for postprocessing into PPT template\n",
    "def postprocess_to_ppt(replacements, selected_template):\n",
    "    # Implement the postprocessing logic here\n",
    "    # For demonstration purposes, we'll load a presentation object and copy the text from replacements dictionary\n",
    "    \n",
    "    #rootdir = os.path.realpath('./')\n",
    "    \n",
    "    #selected_template = \"PLS_PPT_Template\"\n",
    "    selected_template = selected_template[:-4]\n",
    "    ppt_file = f\"{selected_template}.pptx\"\n",
    "    prs = Presentation(os.path.join(rootdir, ppt_file))\n",
    "\n",
    "    for slide in prs.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if shape.has_text_frame:\n",
    "                text_frame = shape.text_frame\n",
    "                for paragraph in text_frame.paragraphs:\n",
    "                    for run in paragraph.runs:\n",
    "                        for placeholder, new_text in replacements.items():\n",
    "                            if run.text == placeholder:\n",
    "                                # Preserve formatting of the first run in the paragraph\n",
    "                                first_run = paragraph.runs[0]\n",
    "                                font_size = first_run.font.size\n",
    "                                font_name = first_run.font.name\n",
    "                                font_bold = first_run.font.bold\n",
    "                                font_italic = first_run.font.italic\n",
    "\n",
    "                                # Check if font color is explicitly defined\n",
    "                                if first_run.font.color.type == \"rgb\":\n",
    "                                    font_color = first_run.font.color.rgb\n",
    "                                else:\n",
    "                                    font_color = None\n",
    "\n",
    "                                # Replace text while preserving formatting\n",
    "                                run.text = new_text\n",
    "\n",
    "                                # Apply preserved formatting to the entire paragraph\n",
    "                                for run in paragraph.runs:\n",
    "                                    run.font.size = font_size\n",
    "                                    run.font.name = font_name\n",
    "                                    run.font.bold = font_bold\n",
    "                                    run.font.italic = font_italic\n",
    "                                    if font_color:\n",
    "                                        run.font.color.rgb = font_color\n",
    "\n",
    "    # Return the modified presentation object\n",
    "    return prs\n",
    "\n",
    "\n",
    "# Placeholder function for postprocessing into DOC template\n",
    "def postprocess_to_doc(replacements):\n",
    "    \n",
    "    para_variable_list = [\"<Subtitle>\", \"<Key takeaway>\", \"<Phonetics>\", \"<Introduction>\", \"<Intro summary>\", \"<Demographics>\", \"<Inclusion criteria>\", \"<Exclusion criteria>\", \"<Results>\", \"<Aims>\", \"<Conclusions>\"]\n",
    "    table_variable_list = [\"<Study number>\", \"<Start date>\", \"<End date>\", \"<Participants>\", \"<Arms count>\", \"<treatment arm>\", \"<control arm>\", \"<Sponsor>\", \"<Summary date>\", \"<clinical trials gov link>\"]\n",
    "    # Create a new document\n",
    "    document = Document()\n",
    "\n",
    "    # Set the font size of the document\n",
    "    style = document.styles['Normal']\n",
    "    font = style.font\n",
    "    font.size = Pt(11)\n",
    "\n",
    "    # Set the title\n",
    "    title = replacements.get(\"<Title>\")\n",
    "    if title:\n",
    "        document.add_heading(title, level=1).bold = True\n",
    "\n",
    "    # Add paragraphs for para_variable_list with the same header formatting\n",
    "    for variable in para_variable_list:\n",
    "        value = replacements.get(variable)\n",
    "        if value:\n",
    "            p = document.add_paragraph(style='Heading 1')\n",
    "            p.text = variable[1:-1]\n",
    "            p.bold = True\n",
    "            document.add_paragraph(value)\n",
    "\n",
    "    # Add the table for table_variable_list\n",
    "    table_replacements = {variable: replacements.get(variable) for variable in table_variable_list}\n",
    "    if table_replacements:\n",
    "        table_heading = \"Additional Information\"\n",
    "        document.add_heading(table_heading, level=1)\n",
    "\n",
    "        # Create the table\n",
    "        table = document.add_table(rows=1, cols=2)\n",
    "        table.style = 'Table Grid'\n",
    "        \n",
    "        # Set table column widths\n",
    "        table.autofit = False\n",
    "        table.columns[0].width = Pt(200)\n",
    "        table.columns[1].width = Pt(300)\n",
    "\n",
    "        # Add table headers\n",
    "        table_header_cells = table.rows[0].cells\n",
    "        table_header_cells[0].text = \"Variable\"\n",
    "        table_header_cells[1].text = \"Value\"\n",
    "        for cell in table_header_cells:\n",
    "            cell.paragraphs[0].alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "            cell.paragraphs[0].bold = True\n",
    "\n",
    "        # Add table rows\n",
    "        for variable, value in table_replacements.items():\n",
    "            row_cells = table.add_row().cells\n",
    "            row_cells[0].text = variable[1:-1]\n",
    "            row_cells[1].text = value\n",
    "\n",
    "    return document\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    \n",
    "    #Page icons n tab name on browser tab\n",
    "    #img = Image.open(os.path.join(rootdir, 'pfizer.png'))\n",
    "    st.set_page_config(page_title = 'MAIA', page_icon = \":robot_face:\", layout=\"wide\")\n",
    "    \n",
    "    #to hide the hamburger running on top right and footer of streamlit\n",
    "    hide_default_format = \"\"\"\n",
    "       <style>\n",
    "       #MainMenu {visibility: hidden; }\n",
    "       footer {visibility: hidden;}\n",
    "       </style>\n",
    "       \"\"\"\n",
    "    st.markdown(hide_default_format, unsafe_allow_html=True)\n",
    "    \n",
    "    names = [\"admin\",\"shakti\"]\n",
    "    usernames = [\"adm\", \"shrp\"]\n",
    "    passwords = [\"abc123\", \"def456\"]\n",
    "\n",
    "    credentials = {\"usernames\":{}}\n",
    "    hashed_passwords = stauth.Hasher(passwords).generate()\n",
    "    \n",
    "    for uname, name, pwd in zip(usernames, names, hashed_passwords):\n",
    "        user_dict = {\"name\": name, \"password\": pwd}\n",
    "        credentials[\"usernames\"].update({uname: user_dict})\n",
    "\n",
    "    \n",
    "    #add a cookie which will be stored on client browser to save credentials till 30days\n",
    "    authenticator = stauth.Authenticate(credentials, \"pls_generator\", \"abcdef\", cookie_expiry_days = 30)\n",
    "\n",
    "    #u can locate the authenticator in the main body or the sidebar\n",
    "    name, authentication_status, username = authenticator.login(\"Login\", \"main\")\n",
    "    \n",
    "    if st.session_state[\"authentication_status\"] == False:\n",
    "        st.error(\"Username/password is incorrect\")\n",
    "        \n",
    "    if st.session_state[\"authentication_status\"] == None:\n",
    "        st.warning(\"Please enter your username and password\")\n",
    "        \n",
    "    if st.session_state[\"authentication_status\"]:\n",
    "        \n",
    "        #logout button on main container\n",
    "        authenticator.logout('Logout', 'main')\n",
    "        st.subheader(f'Welcome *{st.session_state[\"name\"]}*')\n",
    "        \n",
    "        #set bg image cover\n",
    "        #set_bg_hack(os.path.join(rootdir, 'iqvia-dark-blue.png'))\n",
    "        sidebar_bg(os.path.join(rootdir, 'iqvia-blue.png'))\n",
    "        #header_bg(os.path.join(rootdir, 'iqvia-dark-blue.png'))\n",
    "\n",
    "        #setting banner image\n",
    "        #st.image(Image.open(os.path.join(rootdir, 'Pfizer-AI.jpg')))\n",
    "        \n",
    "        selected_tab = option_menu(\n",
    "            menu_title=None,  # required\n",
    "            options=[\"PLS Generator\", \"RCT QnA\", \"RCT WordAnalytics\", \"RCT Chatbot\",],  # required\n",
    "            icons=[\"house\", \"book\", \"envelope\", \"bot\"],  # optional\n",
    "            menu_icon=\"cast\",  # optional\n",
    "            default_index=0,  # optional\n",
    "            orientation=\"horizontal\",\n",
    "            # styles={\n",
    "            #     \"container\": {\"padding\": \"0!important\"},\n",
    "            #     \"icon\": {\"color\": \"orange\", \"font-size\": \"25px\"},\n",
    "            #     \"nav-link\": {\n",
    "            #         \"font-size\": \"25px\",\n",
    "            #         \"text-align\": \"left\",\n",
    "            #         \"margin\": \"0px\",\n",
    "            #         \"--hover-color\": \"#eee\",\n",
    "            #     },\n",
    "            #     \"nav-link-selected\": {\"background-color\": \"green\"},\n",
    "            # },\n",
    "        )\n",
    "        \n",
    "        #setting input components on sidebar\n",
    "        with st.sidebar:\n",
    "\n",
    "            st.image(Image.open(os.path.join(rootdir, 'iqvia-logo.png')))\n",
    "            #setting title\n",
    "            st.markdown(\"\"\"<h3 style='text-align: center'>*MAIA - Medical Affairs Intelligence Assistant*</h3>\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "            # Step 1: Document Upload\n",
    "            st.subheader(\"Step 1: Upload Clinical trial document\")\n",
    "            uploaded_file = st.file_uploader(\"Upload document\", accept_multiple_files=False, type=[\"pdf\"])\n",
    "            \n",
    "            NCT = st.text_input(\"Enter the NCT number:\", \"NCT\", key=\"NCT\")\n",
    "            \n",
    "            # Step 2: User Inputs\n",
    "            st.subheader(\"Step 2: Define the tone and Grade of PLS\")\n",
    "            # Set default values for radio button and slider\n",
    "            default_tense = \"Completed\"\n",
    "            default_pls_grade = \"Low\"\n",
    "\n",
    "            # Radio button for tense selection\n",
    "            tense = st.radio(\"Current status of the study for writing tense\", options=[\"On-going\", \"Completed\", \"Upcoming\"], key=\"tense\", index=[\"On-going\", \"Completed\", \"Upcoming\"].index(default_tense), horizontal=True)\n",
    "            #st.write('<style>div.row-widget.stRadio > div{flex-direction:row;}</style>', unsafe_allow_html=True)\n",
    "\n",
    "            # Slider for PLS grade selection\n",
    "            #pls_grade = st.slider(\"Health Literacy Grade Reading level\", min_value=0, max_value=10, step=5, key=\"pls_grade\", value=default_pls_grade)\n",
    "            pls_grade = st.select_slider(\"Health Literacy Grade of audience\", options=[\"Low\", \"High\"], key=\"pls_grade\", value = default_pls_grade)\n",
    "\n",
    "            st.session_state.process_button = False\n",
    "            process_button = st.button(\"Process Documents\")\n",
    "            st.session_state.process_button = process_button\n",
    "            st.session_state.uploaded_file = uploaded_file\n",
    "            st.session_state.selected_tab = selected_tab\n",
    "        \n",
    "        #if st.session_state.process_button and st.session_state.uploaded_file:\n",
    "        #if process_button and uploaded_file:\n",
    "            \n",
    "            # Retrieve user inputs if you haven't initialized them to any variable, then retrieve from streamlit session state\n",
    "            # st.session_state.tense = tense\n",
    "            # st.session_state.pls_grade = pls_grade\n",
    "            \n",
    "        if st.session_state.selected_tab == \"RCT QnA\":\n",
    "            st.subheader(\"Ask your PDF 💬\")\n",
    "            # show user input\n",
    "            user_question = st.text_input(\"Ask a question about your PDF:\", placeholder=\"Number of participants? \", disabled=not uploaded_file,)\n",
    "            \n",
    "            if st.session_state.uploaded_file:              \n",
    "                \n",
    "                # extract the text\n",
    "                if uploaded_file is not None:\n",
    "                  pdf_reader = PdfReader(uploaded_file)\n",
    "                  text = \"\"\n",
    "                  for page in pdf_reader.pages:\n",
    "                    text += page.extract_text()\n",
    "\n",
    "                  # split into chunks\n",
    "                  text_splitter = CharacterTextSplitter(\n",
    "                    separator=\"\\n\",\n",
    "                    chunk_size=1000,\n",
    "                    chunk_overlap=200,\n",
    "                    length_function=len\n",
    "                  )\n",
    "                  chunks = text_splitter.split_text(text)\n",
    "                    \n",
    "                  # create embeddings\n",
    "                  store_name = uploaded_file.name[:-4]\n",
    "                  if os.path.exists(os.path.join(datadir, f\"{store_name}.pkl\")):\n",
    "                    with open(os.path.join(datadir, f\"{store_name}.pkl\"), \"rb\") as f:\n",
    "                        knowledge_base = pickle.load(f)\n",
    "                        st.write('Embeddings loaded from the Disk:')\n",
    "                  else:\n",
    "                    embeddings = OpenAIEmbeddings()\n",
    "                    knowledge_base = FAISS.from_texts(chunks, embeddings)\n",
    "                    with open(os.path.join(datadir, f\"{store_name}.pkl\"), \"wb\") as f:\n",
    "                        pickle.dump(knowledge_base, f)\n",
    "                        st.write('Embeddings newly created')\n",
    "\n",
    "                  if user_question:\n",
    "                    docs = knowledge_base.similarity_search(user_question, k=3)\n",
    "\n",
    "                    chat_box = st.empty()\n",
    "                    stream_handler = StreamHandler(chat_box, display_method='write')\n",
    "        \n",
    "                    llm = ChatOpenAI(temperature=0, callbacks=[stream_handler], streaming=True)\n",
    "                    chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "                    \n",
    "                    #get_openai_callback() gives the cost on console\n",
    "                    # with get_openai_callback() as cb:\n",
    "                    #   response = chain.run(input_documents=docs, question=user_question)\n",
    "                    #   print(cb)\n",
    "                    response = chain.run(input_documents=docs, question=user_question)\n",
    "                    st.write(response)    \n",
    "        \n",
    "        if st.session_state.selected_tab == \"RCT Chatbot\":\n",
    "            # Ensure the directory exists\n",
    "            if not os.path.exists(saved_path):\n",
    "                os.makedirs(saved_path)\n",
    "        \n",
    "            if uploaded_file is not None:\n",
    "                # To read file as bytes:\n",
    "                bytes_data = uploaded_file.getvalue()\n",
    "\n",
    "                # Save the uploaded file to the 'data' directory\n",
    "                with open(os.path.join(saved_path, uploaded_file.name), 'wb') as out_file:\n",
    "                    out_file.write(bytes_data)\n",
    "\n",
    "                st.success('PDF file saved in data directory')\n",
    "                create_vector()\n",
    "                #remove_all_files(saved_path)\n",
    "                st.success('Vector created')\n",
    "\n",
    "            # Initialise session state variables\n",
    "            if 'generated' not in st.session_state:\n",
    "                st.session_state['generated'] = []\n",
    "            if 'past' not in st.session_state:\n",
    "                st.session_state['past'] = []\n",
    "            if 'messages' not in st.session_state:\n",
    "                st.session_state['messages'] = [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "                ]\n",
    "\n",
    "            response_container = st.container()\n",
    "            # container for text box\n",
    "            container = st.container()\n",
    "\n",
    "            with container:\n",
    "                with st.form(key='my_form', clear_on_submit=True):\n",
    "                    user_input = st.text_area(\"You:\", key='input', height=50)\n",
    "                    submit_button = st.form_submit_button(label='Send')\n",
    "\n",
    "                if submit_button and user_input:\n",
    "                    output = generate_response(user_input)\n",
    "                    st.session_state['past'].append(user_input)\n",
    "                    st.session_state['generated'].append(output)\n",
    "                    #st.session_state['model_name'].append(model_name)\n",
    "\n",
    "            if st.session_state['generated']:\n",
    "                with response_container:\n",
    "                    for i in range(len(st.session_state['generated'])):\n",
    "                        message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user1')\n",
    "                        message(st.session_state[\"generated\"][i], key=str(i))\n",
    "                        \n",
    "        if st.session_state.selected_tab == \"RCT WordAnalytics\":    \n",
    "            #st.subheader(f\"You have selected {selected_tab}\")\n",
    "            \n",
    "            # extract the text\n",
    "            if uploaded_file is not None:\n",
    "                pdf_reader = PdfReader(uploaded_file)\n",
    "                text = \"\"\n",
    "                for page in pdf_reader.pages:\n",
    "                    text += page.extract_text()\n",
    "                \n",
    "                #Remove un-important words:\n",
    "                stop_words = set(stopwords.words('english'))\n",
    "                query_words={'participants', 'Participants' }\n",
    "                stop_words.update(query_words)\n",
    "                for word in query_words:\n",
    "                    text = text.replace(word, '')\n",
    "                    \n",
    "                # Create and generate a word cloud image:\n",
    "                wordcloud = WordCloud(stopwords=stop_words, collocations=False, max_font_size=55, max_words=25, background_color=\"black\").generate(text)\n",
    "\n",
    "                # Display the generated image:\n",
    "                plt.figure(figsize=(10,12))\n",
    "                plt.imshow(wordcloud, interpolation='bilinear')\n",
    "                plt.axis(\"off\")\n",
    "                plt.show()\n",
    "                st.set_option('deprecation.showPyplotGlobalUse', False)\n",
    "                st.pyplot()\n",
    "                \n",
    "                col1, col2 = st.columns(2)\n",
    "                \n",
    "                with col1:\n",
    "                    #overall doc sentiment\n",
    "                    analyzer=SentimentIntensityAnalyzer()\n",
    "                    polarity = analyzer.polarity_scores(text)['compound']\n",
    "                    st.caption(f\"\\nOverall Research document sentiment is: {get_sentiment(polarity)}\", )\n",
    "            \n",
    "                    # splitting modified single string into list of strings using groupby() function\n",
    "                    grouped_strings = [\"\".join(g) for k, g in itertools.groupby(text, lambda x: x == \" \") if not k]\n",
    "\n",
    "                    df = pd.DataFrame()\n",
    "                    df['polarity']=[analyzer.polarity_scores(text)['compound'] for text in grouped_strings]\n",
    "                    df['sentiment']=df.polarity.apply(get_sentiment)\n",
    "                    plt.figure(figsize=(3,3))\n",
    "                    df.sentiment.value_counts().plot.bar()\n",
    "                    st.pyplot()\n",
    "                    \n",
    "                with col2:\n",
    "                    st.caption(\"\\nWord frequency of the words in the research doc is: \")\n",
    "                    data2,data3,data4 = word_frequency(text)\n",
    "                    fig, axes = plt.subplots(3,1,figsize=(8,20))\n",
    "                    sns.barplot(ax=axes[0],x='frequency',y='word',data=data2.head(30))\n",
    "                    sns.barplot(ax=axes[1],x='frequency',y='pairs',data=data3.head(30))\n",
    "                    sns.barplot(ax=axes[2],x='frequency',y='trigrams',data=data4.head(30))\n",
    "                    st.pyplot(fig)\n",
    "                \n",
    "        if st.session_state.selected_tab == \"PLS Generator\":\n",
    "            if st.session_state.process_button and st.session_state.uploaded_file and st.session_state.NCT!='NCT':\n",
    "                col1, col2 = st.columns([0.2,0.8], gap=\"large\")\n",
    "                with col1:\n",
    "                    input_file = save_uploadedfile(uploaded_file)\n",
    "                    pdf_file = os.path.join(datadir, uploaded_file.name) #rootdir + \"/\" + uploaded_file.name\n",
    "                    pdf_view = displayPDF(pdf_file)\n",
    "                with col2:\n",
    "                    with st.spinner(text='Processing research document you gave on the left to generate Plain Language Summary for you...⏳'):\n",
    "\n",
    "                        # Progress bar\n",
    "                        #progress_bar_method(50) or st.progress(0, \"text\")\n",
    "                        \n",
    "                        # Call the processing function on the uploaded documents with user inputs\n",
    "                        replacements = process_documents(NCT, pdf_file, tense, pls_grade)\n",
    "                        st.success(\"Processed Output to be filled up in the preferred PLS template\")\n",
    "\n",
    "                        #Display processed output\n",
    "                        #st.write(replacements)\n",
    "                        st.snow()\n",
    "                        st.balloons()\n",
    "                        \n",
    "                # Store the replacements dictionary in session state\n",
    "                st.session_state.replacements = replacements\n",
    "\n",
    "            # Step 3: PPT Template Selection and Download\n",
    "            st.subheader(\"Step 3: Select PLS Template and Download\")\n",
    "            \n",
    "            default_format = \"PPT format\"\n",
    "            st.session_state.select_format = pills(\"Select PPT or Word format\", [\"PPT format\", \"Word format\"], [\"🎈\", \"🌈\"], index=[\"PPT format\", \"Word format\"].index(default_format))\n",
    "            \n",
    "            if st.session_state.select_format == \"PPT format\":\n",
    "                # Add radio buttons for template selection here    \n",
    "                default_template = \"Blue_PLS_Template.png\"\n",
    "                selected_template = image_select(\n",
    "                    label=\"Select PPT Template\",\n",
    "                    images=[\n",
    "                        os.path.join(rootdir, 'Pfizer_Blue_PLS_Template.png'),\n",
    "                        os.path.join(rootdir, 'Pfizer_Red_PLS_Template.png'),\n",
    "                        os.path.join(rootdir, 'Pfizer_Long_PLS_Template.png'),\n",
    "                    ],\n",
    "                    captions=[\"Blue_PLS_Template\", \"Red_PLS_Template\", \"Long_PLS_Template\"],\n",
    "                    index=[\"Blue_PLS_Template.png\", \"Red_PLS_Template.png\", \"Long_PLS_Template.png\"].index(default_template),\n",
    "                    use_container_width = False,\n",
    "                )\n",
    "                #selected_template = st.radio(\"Select PPT Template\", options=[\"Blue_PLS_Template\", \"Red_PLS_Template\", \"Long_PLS_Template\"], index=[\"Blue_PLS_Template\", \"Red_PLS_Template\", \"Long_PLS_Template\"].index(default_template), horizontal=True)\n",
    "                #selected_template = pills(\"\", [\"Pfizer_Blue_PLS_Template\", \"Pfizer_Red_PLS_Template\", \"Pfizer_Long_PLS_Template\"], [\"🍀\", \"🎈\", \"🌈\"])\n",
    "            \n",
    "            if st.session_state.select_format == \"Word format\":\n",
    "                default_template = \"Word_PLS_Template\"\n",
    "                selected_template = \"Blue_PLS_Template.png\"\n",
    "                image_select(\n",
    "                    label=\"Select Word Template\",\n",
    "                    images=[\n",
    "                        os.path.join(rootdir, 'Pfizer_Word_PLS_Template.png'),\n",
    "                    ],\n",
    "                    captions=[\"Word_PLS_Template\"],\n",
    "                    index=[\"Word_PLS_Template\"].index(default_template),\n",
    "                    use_container_width = False,\n",
    "                )\n",
    "            \n",
    "            generate_ppt_button = st.button(\"Generate PLS\")\n",
    "\n",
    "            if generate_ppt_button:\n",
    "                # Retrieve the replacements dictionary from session state\n",
    "                replacements = st.session_state.replacements\n",
    "                st.session_state.process_button = False\n",
    "\n",
    "                if replacements:\n",
    "                    with st.spinner('Generating PLS slides for you...⏳'):\n",
    "                        # Call the postprocessing function to generate PPT content\n",
    "                        ppt_content = postprocess_to_ppt(replacements, selected_template)\n",
    "\n",
    "                        doc_content = postprocess_to_doc(replacements)\n",
    "\n",
    "                        # Display the PPT content using st.markdown or st.write\n",
    "                        #st.markdown(ppt_content, unsafe_allow_html=True)\n",
    "                        st.markdown(list(replacements.keys()))\n",
    "\n",
    "                        # Store the PPT content in session state\n",
    "                        st.session_state.ppt_content = ppt_content\n",
    "                        st.session_state.doc_content = doc_content\n",
    "\n",
    "                         # Step 4: PPT Download\n",
    "                        if \"ppt_content\" and \"doc_content\" in st.session_state:\n",
    "                            ppt_content = st.session_state.ppt_content\n",
    "                            doc_content = st.session_state.doc_content\n",
    "\n",
    "                            st.session_state.replacements = replacements\n",
    "                            st.session_state.process_button = False\n",
    "\n",
    "                            # Save the modified presentation object to a temporary file\n",
    "                            #ppt_output_file = f\"PLS_{replacements['<Title>']}_{datetime.now().strftime('%Y%m%d%H%M%S')}.pptx\"                    \n",
    "                            ppt_output_file = \"PLS_PPT.pptx\"\n",
    "                            #ppt_content.save(ppt_output_file)\n",
    "\n",
    "                            # save presentation as binary output\n",
    "                            binary_output = BytesIO()\n",
    "                            ppt_content.save(binary_output)\n",
    "\n",
    "                            binary_output_doc = BytesIO()\n",
    "                            doc_content.save(binary_output_doc)\n",
    "\n",
    "                            # display success message and download button\n",
    "                            st.success(':tada: The PLS template has been filled with above sections in ' + selected_template)\n",
    "\n",
    "                            # Provide the download link for the generated PPT and DOC\n",
    "                            if st.session_state.select_format == \"PPT format\":\n",
    "                                st.download_button(\"Download PLS PPT\", data=binary_output.getvalue(), file_name=ppt_output_file, mime=\"application/vnd.openxmlformats-officedocument.presentationml.presentation\")\n",
    "                            if st.session_state.select_format == \"Word format\":\n",
    "                                st.download_button(\"Download PLS Doc\", data=binary_output_doc.getvalue(), file_name=\"PLS_DOC.docx\", mime=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\")\n",
    "                    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e682b71-2e44-4c5d-bda0-ff6e751efd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app8.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app8.py\n",
    "#enhancing - working version of the above app; adding the pubmed/ctgov and word freq graph\n",
    "import os\n",
    "import re\n",
    "import urllib\n",
    "import urllib.request\n",
    "import base64\n",
    "import json\n",
    "import nltk\n",
    "import streamlit as st\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "from pptx.dml.color import RGBColor\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "from datetime import datetime  # Import the 'datetime' class from the 'datetime' module\n",
    "import requests\n",
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "import time\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from shakti_stream_index import llama_vector_index\n",
    "from streamlit_pills import pills\n",
    "import streamlit_authenticator as stauth\n",
    "from streamlit_option_menu import option_menu\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.agents import create_json_agent, AgentExecutor\n",
    "from langchain.agents import create_pandas_dataframe_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from streamlit_chat import message\n",
    "from langchain.agents.agent_toolkits import JsonToolkit\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.requests import TextRequestsWrapper\n",
    "from langchain.tools.json.tool import JsonSpec\n",
    "from streamlit_image_select import image_select\n",
    "from streamlit_chat import message\n",
    "from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index import download_loader, StorageContext, load_index_from_storage\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#load inthe NTLK stopwords to remove articles, preposition and other words that are not actionable\n",
    "from nltk.corpus import stopwords\n",
    "# This allows to create individual objects from a bog of words\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Lemmatizer helps to reduce words to the base form\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Ngrams allows to group words in common pairs or trigrams..etc\n",
    "from nltk import ngrams\n",
    "# We can use counter to count the objects\n",
    "from collections import Counter\n",
    "# This is our word freq distribution library\n",
    "from nltk import FreqDist\n",
    "import seaborn as sns\n",
    "from time import sleep\n",
    "from stqdm import stqdm\n",
    "import itertools\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "saved_path = \"/home/cdsw/experimentation_project1/PLS_project/bot_data\"\n",
    "rootdir = \"/home/cdsw/experimentation_project1/PLS_project\"\n",
    "datadir = \"/home/cdsw/experimentation_project1/PLS_project/data\"\n",
    "promptdir = \"/home/cdsw/experimentation_project1/PLS_project/prompts\"\n",
    "Entrez.email = \"shakti20889@gmail.com\"\n",
    "\n",
    "# def progress_bar_method(secs):\n",
    "#     # Code for your second asynchronous method goes here\n",
    "#     for i in stqdm(range(secs), backend=True, frontend=True):\n",
    "#         sleep(0.5)\n",
    "\n",
    "def generate_response1(input_text, df):\n",
    "    agent = create_pandas_dataframe_agent(ChatOpenAI(temperature =0, model_name=\"gpt-4\", streaming = True), df, verbose=False)\n",
    "    query_response = agent.run(input_text)\n",
    "    return query_response\n",
    "\n",
    "\n",
    "def search_pubmed(article_title, retmax=5):\n",
    "    # Perform the PubMed search using the article title\n",
    "    handle = Entrez.esearch(db=\"pubmed\", term=article_title, retmax=retmax)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    \n",
    "    # Retrieve the full study articles based on the search results\n",
    "    id_list = record[\"IdList\"]\n",
    "    handle = Entrez.efetch(db=\"pubmed\", id=id_list, rettype=\"medline\", retmode=\"text\")\n",
    "    records = Medline.parse(handle)\n",
    "    records = list(records)\n",
    "    handle.close()\n",
    "    \n",
    "    # Extract relevant information from the articles and return as JSON or CSV\n",
    "    articles = []\n",
    "    for record in records:\n",
    "        article = {\n",
    "            \"PMID\": record[\"PMID\"],\n",
    "            \"Title\": record[\"TI\"],\n",
    "            \"Abstract\": record.get(\"AB\", \"\"),\n",
    "            \"Citations\": f\"https://pubmed.ncbi.nlm.nih.gov/{record['PMID']}/\",\n",
    "        }\n",
    "        articles.append(article)\n",
    "    \n",
    "    # Return the articles as JSON or CSV\n",
    "    return articles\n",
    "\n",
    "def search_ctgov(article_title, retmax=5):\n",
    "    # Perform the ClinicalTrials.gov search using the article title\n",
    "    api_url = \"https://clinicaltrials.gov/api/query/full_studies\"\n",
    "    params = {\n",
    "        \"expr\": article_title,\n",
    "        \"min_rnk\": 1,\n",
    "        \"max_rnk\": retmax,\n",
    "        \"fmt\": \"json\",\n",
    "    }\n",
    "    response = requests.get(api_url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Extract relevant information from the ctgov results and return as JSON or CSV\n",
    "    articles = []\n",
    "    for study in data.get(\"FullStudiesResponse\", {}).get(\"FullStudies\", []):\n",
    "        article = {\n",
    "            \"PMID\": study.get(\"Study\", {}).get(\"ProtocolSection\", {}).get(\"IdentificationModule\", {}).get(\"NCTId\", \"\"),\n",
    "            \"Title\": study.get(\"Study\", {}).get(\"ProtocolSection\", {}).get(\"IdentificationModule\", {}).get(\"OfficialTitle\", \"\"),\n",
    "            \"Abstract\": study.get(\"Study\", {}).get(\"ProtocolSection\", {}).get(\"DescriptionModule\", {}).get(\"BriefSummary\", \"\"),\n",
    "            \"Citations\": f\"https://clinicaltrials.gov/ct2/show/{study['Study']['ProtocolSection']['IdentificationModule']['NCTId']}\",\n",
    "        }\n",
    "        articles.append(article)\n",
    "    \n",
    "    # Return the articles as JSON or CSV\n",
    "    return articles\n",
    "\n",
    "# Function to display the article details in the main container\n",
    "def display_articles(articles):\n",
    "    for article in articles:\n",
    "        title = article[\"Title\"]\n",
    "        abstract = article[\"Abstract\"].strip().split(\". \", 3)[0] + \"...\"  # First 3 lines of abstract\n",
    "        citations_url = article[\"Citations\"]\n",
    "        st.write(f\"**Title:** {title}\")\n",
    "        st.write(f\"**Abstract:** {abstract}\")\n",
    "        st.write(f\"[Read More]({citations_url})\")\n",
    "        st.write(\"--------\")\n",
    "\n",
    "class StreamHandler(BaseCallbackHandler):\n",
    "    def __init__(self, container, initial_text=\"\", display_method='markdown'):\n",
    "        self.container = container\n",
    "        self.text = initial_text\n",
    "        self.display_method = display_method\n",
    "\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        self.text += token + \"/\"\n",
    "        display_function = getattr(self.container, self.display_method, None)\n",
    "        if display_function is not None:\n",
    "            display_function(self.text)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid display_method: {self.display_method}\")\n",
    "\n",
    "#function to set background image\n",
    "def set_bg_hack(main_bg):\n",
    "    '''\n",
    "    A function to unpack an image from root folder and set as bg.\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    The background.\n",
    "    '''\n",
    "    # set bg name\n",
    "    main_bg_ext = \"png\"\n",
    "        \n",
    "    st.markdown(\n",
    "         f\"\"\"\n",
    "         <style>\n",
    "         .stApp {{\n",
    "             background: url(data:image/{main_bg_ext};base64,{base64.b64encode(open(main_bg, \"rb\").read()).decode()});\n",
    "             background-size: cover\n",
    "         }}\n",
    "         </style>\n",
    "         \"\"\",\n",
    "         unsafe_allow_html=True\n",
    "     )\n",
    "\n",
    "def sidebar_bg(side_bg):\n",
    "\n",
    "   side_bg_ext = 'png'\n",
    "\n",
    "   st.markdown(\n",
    "      f\"\"\"\n",
    "      <style>\n",
    "      [data-testid=\"stSidebar\"] > div:first-child {{\n",
    "          background: url(data:image/{side_bg_ext};base64,{base64.b64encode(open(side_bg, \"rb\").read()).decode()});\n",
    "      }}\n",
    "      </style>\n",
    "      \"\"\",\n",
    "      unsafe_allow_html=True,\n",
    "      )\n",
    "    \n",
    "def header_bg(side_bg):\n",
    "\n",
    "   side_bg_ext = 'png'\n",
    "\n",
    "   st.markdown(\n",
    "      f\"\"\"\n",
    "      <style>\n",
    "      header.css-1avcm0n {{\n",
    "          background: url(data:image/{side_bg_ext};base64,{base64.b64encode(open(side_bg, \"rb\").read()).decode()});\n",
    "      }}\n",
    "      </style>\n",
    "      \"\"\",\n",
    "      unsafe_allow_html=True,\n",
    "      )\n",
    "\n",
    "def get_sentiment(polarity):\n",
    "    if polarity < 0.0:\n",
    "        return 'Negative'\n",
    "    elif polarity > 0.2:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "    \n",
    "def word_frequency(sentence):\n",
    "    # joins all the sentenses\n",
    "    #sentence = \" \".join(sentence)\n",
    "    # creates tokens, creates lower class, removes numbers and lemmatizes the words\n",
    "    new_tokens = word_tokenize(sentence)\n",
    "    new_tokens = [t.lower() for t in new_tokens]\n",
    "    new_tokens =[t for t in new_tokens if t not in stopwords.words('english')]\n",
    "    new_tokens = [t for t in new_tokens if t.isalpha()]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    new_tokens =[lemmatizer.lemmatize(t) for t in new_tokens]\n",
    "    #counts the words, pairs and trigrams\n",
    "    counted = Counter(new_tokens)\n",
    "    counted_2= Counter(ngrams(new_tokens,2))\n",
    "    counted_3= Counter(ngrams(new_tokens,3))\n",
    "    #creates 3 data frames and returns thems\n",
    "    word_freq = pd.DataFrame(counted.items(),columns=['word','frequency']).sort_values(by='frequency',ascending=False)\n",
    "    word_pairs =pd.DataFrame(counted_2.items(),columns=['pairs','frequency']).sort_values(by='frequency',ascending=False)\n",
    "    trigrams =pd.DataFrame(counted_3.items(),columns=['trigrams','frequency']).sort_values(by='frequency',ascending=False)\n",
    "    return word_freq,word_pairs,trigrams    \n",
    "    \n",
    "#function to read prompt from corresponding text file\n",
    "def prompt(file):\n",
    "    with open(file) as f:\n",
    "        return f.read()\n",
    "    \n",
    "#function to save a file\n",
    "def save_uploadedfile(uploaded_file):\n",
    "     with open(os.path.join(datadir, uploaded_file.name),\"wb\") as f:\n",
    "         f.write(uploaded_file.getbuffer())\n",
    "     return st.success(f\"\"\"Saved File:{uploaded_file.name} to directory\"\"\")\n",
    "\n",
    "def create_vector():\n",
    "    documents = SimpleDirectoryReader(saved_path).load_data()\n",
    "    index = GPTVectorStoreIndex.from_documents(documents)\n",
    "\n",
    "    storage_context = StorageContext.from_defaults()\n",
    "    index.storage_context.persist(\"./vectordatabase\")\n",
    "    #print (\"Done\")\n",
    "\n",
    "def generate_response(prompt):\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"./vectordatabase\")\n",
    "    index = load_index_from_storage(storage_context)\n",
    "    query_engin = index.as_query_engine() \n",
    "    question = prompt\n",
    "    response = query_engin.query(question)\n",
    "    return str(response)\n",
    "    #print (\"\\n\", response)\n",
    "\n",
    "@st.cache_data\n",
    "#function to display the PDF of a given file \n",
    "def displayPDF(file):\n",
    "    # Opening file from file path\n",
    "    with open(file, \"rb\") as f:\n",
    "        base64_pdf = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "    # Embedding PDF in HTML\n",
    "    pdf_display = F'<iframe src=\"data:application/pdf;base64,{base64_pdf}\" width=\"300\" height=\"1100\" type=\"application/pdf\"></iframe>'\n",
    "\n",
    "    # Displaying File\n",
    "    st.markdown(pdf_display, unsafe_allow_html=True)\n",
    "\n",
    "# Placeholder function for processing the uploaded documents\n",
    "def process_documents(NCT, uploaded_file, tense, pls_grade):\n",
    "    # Implement the document processing logic here\n",
    "\n",
    "    # Convert tense strings\n",
    "    tense_mapping = {\"on-going\": \"present\", \"completed\": \"past\", \"upcoming\": \"future\"}\n",
    "    tense = tense_mapping.get(tense, tense)\n",
    "    \n",
    "    summary_replacements = {\n",
    "        \"<Title>\": prompt(os.path.join(promptdir, 'title.txt')),\n",
    "        \"<Subtitle>\": prompt(os.path.join(promptdir, 'subtitle.txt')),\n",
    "        \"<Key takeaway>\": prompt(os.path.join(promptdir, 'key_takeaway.txt')),\n",
    "        \"<Phonetics>\": prompt(os.path.join(promptdir, 'phonetics.txt')), \n",
    "        \"<Introduction>\": prompt(os.path.join(promptdir, 'introduction.txt')), \n",
    "        \"<Intro summary>\": prompt(os.path.join(promptdir, 'intro_summary.txt')),\n",
    "        # \"<Inclusion criteria>\": \"\",\n",
    "        # \"<Exclusion crtieria>\": \"\",\n",
    "        # \"<Results>\": \"\",\n",
    "        \"<Aims>\": prompt(os.path.join(promptdir, 'aims.txt')),\n",
    "        \"<Conclusions>\": prompt(os.path.join(promptdir, 'conclusions.txt')),\n",
    "        # \"<Sponsor>\": \"\",\n",
    "        # \"<More Information>\": \"\",\n",
    "    }\n",
    "        \n",
    "    # Get the text for each section using GPTAPIcall function\n",
    "    for section_name, summary_prompt in summary_replacements.items():\n",
    "        \n",
    "        #prompt for pls grade and tense\n",
    "        query = f\"Strictly following the above instructions and the research document provided, write the content of {section_name} section of the plain language summary in {tense} tense.\\\n",
    "        Do not violate the section-wise instructions provided in any case. The content should be strictly inferred from the research document provided and not any other sources.\"\n",
    "        \n",
    "        st.subheader(f\"\"\":red[{section_name[1:-1]} :]\"\"\")\n",
    "        text = llama_vector_index(uploaded_file, prompt(os.path.join(promptdir, f'apls_persona_{pls_grade}_literacy.txt')) + \"\\n\" + summary_prompt + \"\\n\" + query)\n",
    "        summary_replacements[section_name] = str(text)\n",
    "        \n",
    "    ctgov_replacements = {\n",
    "                    \"<Start date>\": \"Answer the Study Start date in ```MMM-YYYY``` format\",\n",
    "                    \"<End date>\": \"Answer the Study End date in ```MMM-YYYY``` format\",\n",
    "                    \"<Participants>\": \"Total number of Participants in the study including drug arms, placebo arm, soc arm. Give one number answer\",\n",
    "                    \"<Arms count>\": \"Number of arms in the study including the drug arms, placebo arm, soc arm. Give one number answer\",\n",
    "                    \"<Disease condition>\": \"What is the disease condition for which drug is undergoing trials on patients in the study. Give answer as one disease\",\n",
    "                    \"<Demographics>\": \"What are the Demographics of participants in the study\",\n",
    "                    \"<treatment arm>\": \"Number of participants only in the drug arms of the study, do not count the participants from placebo arm or soc arm. Give one number answer\",\n",
    "                    \"<control arm>\": \"Number of participants in the placebo arm or soc arm. Give one number answer\",\n",
    "                    \"<Inclusion criteria>\": \"Inclusion criteria in EligibilityCriteria\",\n",
    "                    \"<Exclusion criteria>\": \"Exclusion criteria in EligibilityCriteria\",\n",
    "                    \"<Results>\": \"list all outcome measure results in bullets interms of outcome measure type, outcome measure title, outcome measure description, outcome measure value\",\n",
    "                    # \"<clinical trials gov link>\": \"https://clinicaltrials.gov/ct2/show/NCT03036813\",\n",
    "                    # \"<Summary date>\": datetime.now().strftime('%d-%b-%Y'),\n",
    "                    \"<Sponsor>\": \"Lead Sponsor Name\",\n",
    "                   }\n",
    "    \n",
    "    for section_name, ctgov_prompt in ctgov_replacements.items():\n",
    "        \n",
    "        st.subheader(f\"\"\":red[{section_name[1:-1]} :]\"\"\")\n",
    "        text = CTGovAPIcall(NCT, ctgov_prompt)\n",
    "        if section_name==\"<Participants>\":\n",
    "            text = re.findall(r'\\d+', text)\n",
    "        ctgov_replacements[section_name] = str(text)\n",
    "    \n",
    "    \n",
    "    replacements = {**summary_replacements, \n",
    "                    **ctgov_replacements, \n",
    "                    \"<Study number>\": f\"{NCT}\",\n",
    "                    \"<clinical trials gov link>\": f\"https://clinicaltrials.gov/ct2/show/{NCT}\",\n",
    "                    \"<Summary date>\": datetime.now().strftime('%d-%b-%Y'),\n",
    "                   }\n",
    "    \n",
    "    return replacements\n",
    "\n",
    "def CTGovAPIcall(NCT, query):\n",
    "    file_format = '&fmt=JSON'\n",
    "    expr = NCT #'A+Phase+3+Randomized+Trial+of+Voxelotor+in+Sickle+Cell+Disease' #or give NCT number here NCT03036813\n",
    "    ctgov = 'https://classic.clinicaltrials.gov/api/query/full_studies?expr='\n",
    "\n",
    "    your_url = (ctgov + expr + file_format)\n",
    "\n",
    "    with urllib.request.urlopen(your_url) as url:\n",
    "        ini_dict = json.loads(url.read().decode())\n",
    "        \n",
    "    json_spec = JsonSpec(dict_=ini_dict[\"FullStudiesResponse\"][\"FullStudies\"][0][\"Study\"], max_value_length=31000)\n",
    "    json_toolkit = JsonToolkit(spec=json_spec)\n",
    "    \n",
    "    chat_box = st.empty()\n",
    "    stream_handler = StreamHandler(chat_box, display_method='write')\n",
    "    \n",
    "    json_agent_executor = create_json_agent(\n",
    "        llm=ChatOpenAI(temperature=0, model_name=\"gpt-4-32k\", streaming=True, callbacks=[stream_handler],), toolkit=json_toolkit, verbose=True\n",
    "    )\n",
    "    resp = json_agent_executor.run(query)\n",
    "    st.write(resp)\n",
    "    return resp\n",
    "    \n",
    "# Placeholder function for postprocessing into PPT template\n",
    "def postprocess_to_ppt(replacements, selected_template):\n",
    "    # Implement the postprocessing logic here\n",
    "    # For demonstration purposes, we'll load a presentation object and copy the text from replacements dictionary\n",
    "    \n",
    "    #rootdir = os.path.realpath('./')\n",
    "    \n",
    "    #selected_template = \"PLS_PPT_Template\"\n",
    "    selected_template = selected_template[:-4]\n",
    "    ppt_file = f\"{selected_template}.pptx\"\n",
    "    prs = Presentation(os.path.join(rootdir, ppt_file))\n",
    "\n",
    "    for slide in prs.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if shape.has_text_frame:\n",
    "                text_frame = shape.text_frame\n",
    "                for paragraph in text_frame.paragraphs:\n",
    "                    for run in paragraph.runs:\n",
    "                        for placeholder, new_text in replacements.items():\n",
    "                            if run.text == placeholder:\n",
    "                                # Preserve formatting of the first run in the paragraph\n",
    "                                first_run = paragraph.runs[0]\n",
    "                                font_size = first_run.font.size\n",
    "                                font_name = first_run.font.name\n",
    "                                font_bold = first_run.font.bold\n",
    "                                font_italic = first_run.font.italic\n",
    "\n",
    "                                # Check if font color is explicitly defined\n",
    "                                if first_run.font.color.type == \"rgb\":\n",
    "                                    font_color = first_run.font.color.rgb\n",
    "                                else:\n",
    "                                    font_color = None\n",
    "\n",
    "                                # Replace text while preserving formatting\n",
    "                                run.text = new_text\n",
    "\n",
    "                                # Apply preserved formatting to the entire paragraph\n",
    "                                for run in paragraph.runs:\n",
    "                                    run.font.size = font_size\n",
    "                                    run.font.name = font_name\n",
    "                                    run.font.bold = font_bold\n",
    "                                    run.font.italic = font_italic\n",
    "                                    if font_color:\n",
    "                                        run.font.color.rgb = font_color\n",
    "\n",
    "    # Return the modified presentation object\n",
    "    return prs\n",
    "\n",
    "\n",
    "# Placeholder function for postprocessing into DOC template\n",
    "def postprocess_to_doc(replacements):\n",
    "    \n",
    "    para_variable_list = [\"<Subtitle>\", \"<Key takeaway>\", \"<Phonetics>\", \"<Introduction>\", \"<Intro summary>\", \"<Demographics>\", \"<Inclusion criteria>\", \"<Exclusion criteria>\", \"<Results>\", \"<Aims>\", \"<Conclusions>\"]\n",
    "    table_variable_list = [\"<Study number>\", \"<Start date>\", \"<End date>\", \"<Participants>\", \"<Arms count>\", \"<treatment arm>\", \"<control arm>\", \"<Sponsor>\", \"<Summary date>\", \"<clinical trials gov link>\"]\n",
    "    # Create a new document\n",
    "    document = Document()\n",
    "\n",
    "    # Set the font size of the document\n",
    "    style = document.styles['Normal']\n",
    "    font = style.font\n",
    "    font.size = Pt(11)\n",
    "\n",
    "    # Set the title\n",
    "    title = replacements.get(\"<Title>\")\n",
    "    if title:\n",
    "        document.add_heading(title, level=1).bold = True\n",
    "\n",
    "    # Add paragraphs for para_variable_list with the same header formatting\n",
    "    for variable in para_variable_list:\n",
    "        value = replacements.get(variable)\n",
    "        if value:\n",
    "            p = document.add_paragraph(style='Heading 1')\n",
    "            p.text = variable[1:-1]\n",
    "            p.bold = True\n",
    "            document.add_paragraph(value)\n",
    "\n",
    "    # Add the table for table_variable_list\n",
    "    table_replacements = {variable: replacements.get(variable) for variable in table_variable_list}\n",
    "    if table_replacements:\n",
    "        table_heading = \"Additional Information\"\n",
    "        document.add_heading(table_heading, level=1)\n",
    "\n",
    "        # Create the table\n",
    "        table = document.add_table(rows=1, cols=2)\n",
    "        table.style = 'Table Grid'\n",
    "        \n",
    "        # Set table column widths\n",
    "        table.autofit = False\n",
    "        table.columns[0].width = Pt(200)\n",
    "        table.columns[1].width = Pt(300)\n",
    "\n",
    "        # Add table headers\n",
    "        table_header_cells = table.rows[0].cells\n",
    "        table_header_cells[0].text = \"Variable\"\n",
    "        table_header_cells[1].text = \"Value\"\n",
    "        for cell in table_header_cells:\n",
    "            cell.paragraphs[0].alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "            cell.paragraphs[0].bold = True\n",
    "\n",
    "        # Add table rows\n",
    "        for variable, value in table_replacements.items():\n",
    "            row_cells = table.add_row().cells\n",
    "            row_cells[0].text = variable[1:-1]\n",
    "            row_cells[1].text = value\n",
    "\n",
    "    return document\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    \n",
    "    #Page icons n tab name on browser tab\n",
    "    #img = Image.open(os.path.join(rootdir, 'pfizer.png'))\n",
    "    st.set_page_config(page_title = 'MAIA', page_icon = \":robot_face:\", layout=\"wide\")\n",
    "    \n",
    "    #to hide the hamburger running on top right and footer of streamlit\n",
    "    hide_default_format = \"\"\"\n",
    "       <style>\n",
    "       #MainMenu {visibility: hidden; }\n",
    "       footer {visibility: hidden;}\n",
    "       </style>\n",
    "       \"\"\"\n",
    "    st.markdown(hide_default_format, unsafe_allow_html=True)\n",
    "    \n",
    "    names = [\"admin\",\"shakti\"]\n",
    "    usernames = [\"adm\", \"shrp\"]\n",
    "    passwords = [\"abc123\", \"def456\"]\n",
    "\n",
    "    credentials = {\"usernames\":{}}\n",
    "    hashed_passwords = stauth.Hasher(passwords).generate()\n",
    "    \n",
    "    for uname, name, pwd in zip(usernames, names, hashed_passwords):\n",
    "        user_dict = {\"name\": name, \"password\": pwd}\n",
    "        credentials[\"usernames\"].update({uname: user_dict})\n",
    "\n",
    "    \n",
    "    #add a cookie which will be stored on client browser to save credentials till 30days\n",
    "    authenticator = stauth.Authenticate(credentials, \"pls_generator\", \"abcdef\", cookie_expiry_days = 30)\n",
    "\n",
    "    #u can locate the authenticator in the main body or the sidebar\n",
    "    name, authentication_status, username = authenticator.login(\"Login\", \"main\")\n",
    "    \n",
    "    if st.session_state[\"authentication_status\"] == False:\n",
    "        st.error(\"Username/password is incorrect\")\n",
    "        \n",
    "    if st.session_state[\"authentication_status\"] == None:\n",
    "        st.warning(\"Please enter your username and password\")\n",
    "        \n",
    "    if st.session_state[\"authentication_status\"]:\n",
    "        \n",
    "        #logout button on main container\n",
    "        authenticator.logout('Logout', 'main')\n",
    "        st.subheader(f'Welcome *{st.session_state[\"name\"]}*')\n",
    "        \n",
    "        #set bg image cover\n",
    "        #set_bg_hack(os.path.join(rootdir, 'iqvia-dark-blue.png'))\n",
    "        sidebar_bg(os.path.join(rootdir, 'iqvia-blue.png'))\n",
    "        #header_bg(os.path.join(rootdir, 'iqvia-dark-blue.png'))\n",
    "\n",
    "        #setting banner image\n",
    "        #st.image(Image.open(os.path.join(rootdir, 'Pfizer-AI.jpg')))\n",
    "        \n",
    "        selected_tab = option_menu(\n",
    "            menu_title=None,  # required\n",
    "            options=[\"PLS Generator\", \"RCT QnA\", \"RCT WordAnalytics\", \"RCT Chatbot\", \"Search PubMed/CTGov\"],  # required\n",
    "            icons=[\"house\", \"book\", \"envelope\", \"book\", \"envelope\"],  # optional\n",
    "            menu_icon=\"cast\",  # optional\n",
    "            default_index=0,  # optional\n",
    "            orientation=\"horizontal\",\n",
    "            # styles={\n",
    "            #     \"container\": {\"padding\": \"0!important\"},\n",
    "            #     \"icon\": {\"color\": \"orange\", \"font-size\": \"25px\"},\n",
    "            #     \"nav-link\": {\n",
    "            #         \"font-size\": \"25px\",\n",
    "            #         \"text-align\": \"left\",\n",
    "            #         \"margin\": \"0px\",\n",
    "            #         \"--hover-color\": \"#eee\",\n",
    "            #     },\n",
    "            #     \"nav-link-selected\": {\"background-color\": \"green\"},\n",
    "            # },\n",
    "        )\n",
    "        \n",
    "        #setting input components on sidebar\n",
    "        with st.sidebar:\n",
    "\n",
    "            st.image(Image.open(os.path.join(rootdir, 'iqvia-logo.png')))\n",
    "            #setting title\n",
    "            st.markdown(\"\"\"<h3 style='text-align: center'>*MAIA - Medical Affairs Intelligence Assistant*</h3>\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "            # Step 1: Document Upload\n",
    "            st.subheader(\"Step 1: Upload Clinical trial document\")\n",
    "            uploaded_file = st.file_uploader(\"Upload document\", accept_multiple_files=False, type=[\"pdf\"])\n",
    "            \n",
    "            NCT = st.text_input(\"Enter the NCT number:\", \"NCT\", key=\"NCT\")\n",
    "            \n",
    "            # Step 2: User Inputs\n",
    "            st.subheader(\"Step 2: Define the tone and Grade of PLS\")\n",
    "            # Set default values for radio button and slider\n",
    "            default_tense = \"Completed\"\n",
    "            default_pls_grade = \"Low\"\n",
    "\n",
    "            # Radio button for tense selection\n",
    "            tense = st.radio(\"Current status of the study for writing tense\", options=[\"On-going\", \"Completed\", \"Upcoming\"], key=\"tense\", index=[\"On-going\", \"Completed\", \"Upcoming\"].index(default_tense), horizontal=True)\n",
    "            #st.write('<style>div.row-widget.stRadio > div{flex-direction:row;}</style>', unsafe_allow_html=True)\n",
    "\n",
    "            # Slider for PLS grade selection\n",
    "            #pls_grade = st.slider(\"Health Literacy Grade Reading level\", min_value=0, max_value=10, step=5, key=\"pls_grade\", value=default_pls_grade)\n",
    "            pls_grade = st.select_slider(\"Health Literacy Grade of audience\", options=[\"Low\", \"High\"], key=\"pls_grade\", value = default_pls_grade)\n",
    "\n",
    "            st.session_state.process_button = False\n",
    "            process_button = st.button(\"Process Documents\")\n",
    "            st.session_state.process_button = process_button\n",
    "            st.session_state.uploaded_file = uploaded_file\n",
    "            st.session_state.selected_tab = selected_tab\n",
    "        \n",
    "        #if st.session_state.process_button and st.session_state.uploaded_file:\n",
    "        #if process_button and uploaded_file:\n",
    "            \n",
    "            # Retrieve user inputs if you haven't initialized them to any variable, then retrieve from streamlit session state\n",
    "            # st.session_state.tense = tense\n",
    "            # st.session_state.pls_grade = pls_grade\n",
    "            \n",
    "        if st.session_state.selected_tab == \"RCT QnA\":\n",
    "            st.subheader(\"Ask your PDF 💬\")\n",
    "            # show user input\n",
    "            user_question = st.text_input(\"Ask a question about your PDF:\", placeholder=\"Number of participants? \", disabled=not uploaded_file,)\n",
    "            \n",
    "            if st.session_state.uploaded_file:              \n",
    "                \n",
    "                # extract the text\n",
    "                if uploaded_file is not None:\n",
    "                  pdf_reader = PdfReader(uploaded_file)\n",
    "                  text = \"\"\n",
    "                  for page in pdf_reader.pages:\n",
    "                    text += page.extract_text()\n",
    "\n",
    "                  # split into chunks\n",
    "                  text_splitter = CharacterTextSplitter(\n",
    "                    separator=\"\\n\",\n",
    "                    chunk_size=1000,\n",
    "                    chunk_overlap=200,\n",
    "                    length_function=len\n",
    "                  )\n",
    "                  chunks = text_splitter.split_text(text)\n",
    "                    \n",
    "                  # create embeddings\n",
    "                  store_name = uploaded_file.name[:-4]\n",
    "                  if os.path.exists(os.path.join(datadir, f\"{store_name}.pkl\")):\n",
    "                    with open(os.path.join(datadir, f\"{store_name}.pkl\"), \"rb\") as f:\n",
    "                        knowledge_base = pickle.load(f)\n",
    "                        st.write('Embeddings loaded from the Disk:')\n",
    "                  else:\n",
    "                    embeddings = OpenAIEmbeddings()\n",
    "                    knowledge_base = FAISS.from_texts(chunks, embeddings)\n",
    "                    with open(os.path.join(datadir, f\"{store_name}.pkl\"), \"wb\") as f:\n",
    "                        pickle.dump(knowledge_base, f)\n",
    "                        st.write('Embeddings newly created')\n",
    "\n",
    "                  if user_question:\n",
    "                    docs = knowledge_base.similarity_search(user_question, k=3)\n",
    "\n",
    "                    chat_box = st.empty()\n",
    "                    stream_handler = StreamHandler(chat_box, display_method='write')\n",
    "        \n",
    "                    llm = ChatOpenAI(temperature=0, callbacks=[stream_handler], streaming=True)\n",
    "                    chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "                    \n",
    "                    #get_openai_callback() gives the cost on console\n",
    "                    # with get_openai_callback() as cb:\n",
    "                    #   response = chain.run(input_documents=docs, question=user_question)\n",
    "                    #   print(cb)\n",
    "                    response = chain.run(input_documents=docs, question=user_question)\n",
    "                    st.write(response)    \n",
    "        \n",
    "        if st.session_state.selected_tab == \"RCT Chatbot\":\n",
    "            # Ensure the directory exists\n",
    "            if not os.path.exists(saved_path):\n",
    "                os.makedirs(saved_path)\n",
    "        \n",
    "            if uploaded_file is not None:\n",
    "                # To read file as bytes:\n",
    "                bytes_data = uploaded_file.getvalue()\n",
    "\n",
    "                # Save the uploaded file to the 'data' directory\n",
    "                with open(os.path.join(saved_path, uploaded_file.name), 'wb') as out_file:\n",
    "                    out_file.write(bytes_data)\n",
    "\n",
    "                st.success('PDF file saved in data directory')\n",
    "                create_vector()\n",
    "                #remove_all_files(saved_path)\n",
    "                st.success('Vector created')\n",
    "\n",
    "            # Initialise session state variables\n",
    "            if 'generated' not in st.session_state:\n",
    "                st.session_state['generated'] = []\n",
    "            if 'past' not in st.session_state:\n",
    "                st.session_state['past'] = []\n",
    "            if 'messages' not in st.session_state:\n",
    "                st.session_state['messages'] = [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "                ]\n",
    "\n",
    "            response_container = st.container()\n",
    "            # container for text box\n",
    "            container = st.container()\n",
    "\n",
    "            with container:\n",
    "                with st.form(key='my_form', clear_on_submit=True):\n",
    "                    user_input = st.text_area(\"You:\", key='input', height=50)\n",
    "                    submit_button = st.form_submit_button(label='Send')\n",
    "\n",
    "                if submit_button and user_input:\n",
    "                    output = generate_response(user_input)\n",
    "                    st.session_state['past'].append(user_input)\n",
    "                    st.session_state['generated'].append(output)\n",
    "                    #st.session_state['model_name'].append(model_name)\n",
    "\n",
    "            if st.session_state['generated']:\n",
    "                with response_container:\n",
    "                    for i in range(len(st.session_state['generated'])):\n",
    "                        message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user1')\n",
    "                        message(st.session_state[\"generated\"][i], key=str(i))\n",
    "                        \n",
    "        if st.session_state.selected_tab == \"RCT WordAnalytics\":    \n",
    "            #st.subheader(f\"You have selected {selected_tab}\")\n",
    "            \n",
    "            # extract the text\n",
    "            if uploaded_file is not None:\n",
    "                pdf_reader = PdfReader(uploaded_file)\n",
    "                text = \"\"\n",
    "                for page in pdf_reader.pages:\n",
    "                    text += page.extract_text()\n",
    "                \n",
    "                #Remove un-important words:\n",
    "                stop_words = set(stopwords.words('english'))\n",
    "                query_words={'participants', 'Participants' }\n",
    "                stop_words.update(query_words)\n",
    "                for word in query_words:\n",
    "                    text = text.replace(word, '')\n",
    "                    \n",
    "                # Create and generate a word cloud image:\n",
    "                wordcloud = WordCloud(stopwords=stop_words, collocations=False, max_font_size=55, max_words=25, background_color=\"black\").generate(text)\n",
    "\n",
    "                # Display the generated image:\n",
    "                plt.figure(figsize=(10,12))\n",
    "                plt.imshow(wordcloud, interpolation='bilinear')\n",
    "                plt.axis(\"off\")\n",
    "                plt.show()\n",
    "                st.set_option('deprecation.showPyplotGlobalUse', False)\n",
    "                st.pyplot()\n",
    "                \n",
    "                col1, col2 = st.columns(2)\n",
    "                \n",
    "                with col1:\n",
    "                    #overall doc sentiment\n",
    "                    analyzer=SentimentIntensityAnalyzer()\n",
    "                    polarity = analyzer.polarity_scores(text)['compound']\n",
    "                    st.subheader(f\"\\nOverall Research document sentiment is: {get_sentiment(polarity)}\", )\n",
    "            \n",
    "                    # splitting modified single string into list of strings using groupby() function\n",
    "                    grouped_strings = [\"\".join(g) for k, g in itertools.groupby(text, lambda x: x == \" \") if not k]\n",
    "                    \n",
    "                    #word-wise sentiment\n",
    "                    df = pd.DataFrame()\n",
    "                    df['polarity']=[analyzer.polarity_scores(text)['compound'] for text in grouped_strings]\n",
    "                    df['sentiment']=df.polarity.apply(get_sentiment)\n",
    "                    plt.figure(figsize=(3,3))\n",
    "                    df.sentiment.value_counts().plot.bar()\n",
    "                    st.pyplot()\n",
    "                    \n",
    "                with col2:\n",
    "                    st.subheader(\"\\nWord frequency of the words in the research doc is: \")\n",
    "                    \n",
    "                    #Tokenization\n",
    "                    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "                    #compute freq distribution\n",
    "                    freq_dist = FreqDist(tokens)\n",
    "\n",
    "                    #plot the freq distribution\n",
    "                    freq_dist.plot(50, cumulative=True)\n",
    "\n",
    "                    #set labels and title\n",
    "                    # plt.xlabel('Words')\n",
    "                    # plt.ylabel('Frequency')\n",
    "                    plt.title('Frequency distribution of words')\n",
    "                    st.pyplot()\n",
    "                    \n",
    "                    data2,data3,data4 = word_frequency(text)\n",
    "                    fig, axes = plt.subplots(3,1,figsize=(8,20))\n",
    "                    sns.barplot(ax=axes[0],x='frequency',y='word',data=data2.head(30))\n",
    "                    sns.barplot(ax=axes[1],x='frequency',y='pairs',data=data3.head(30))\n",
    "                    sns.barplot(ax=axes[2],x='frequency',y='trigrams',data=data4.head(30))\n",
    "                    st.pyplot(fig)\n",
    "                \n",
    "        if st.session_state.selected_tab == \"PLS Generator\":\n",
    "            if st.session_state.process_button and st.session_state.uploaded_file and st.session_state.NCT!='NCT':\n",
    "                col1, col2 = st.columns([0.2,0.8], gap=\"large\")\n",
    "                with col1:\n",
    "                    input_file = save_uploadedfile(uploaded_file)\n",
    "                    pdf_file = os.path.join(datadir, uploaded_file.name) #rootdir + \"/\" + uploaded_file.name\n",
    "                    pdf_view = displayPDF(pdf_file)\n",
    "                with col2:\n",
    "                    with st.spinner(text='Processing research document you gave on the left to generate Plain Language Summary for you...⏳'):\n",
    "\n",
    "                        # Progress bar\n",
    "                        #progress_bar_method(50) or st.progress(0, \"text\")\n",
    "                        \n",
    "                        # Call the processing function on the uploaded documents with user inputs\n",
    "                        replacements = process_documents(NCT, pdf_file, tense, pls_grade)\n",
    "                        st.success(\"Processed Output to be filled up in the preferred PLS template\")\n",
    "\n",
    "                        #Display processed output\n",
    "                        #st.write(replacements)\n",
    "                        st.snow()\n",
    "                        st.balloons()\n",
    "                        \n",
    "                # Store the replacements dictionary in session state\n",
    "                st.session_state.replacements = replacements\n",
    "\n",
    "            # Step 3: PPT Template Selection and Download\n",
    "            st.subheader(\"Step 3: Select PLS Template and Download\")\n",
    "            \n",
    "            default_format = \"PPT format\"\n",
    "            st.session_state.select_format = pills(\"Select PPT or Word format\", [\"PPT format\", \"Word format\"], [\"🎈\", \"🌈\"], index=[\"PPT format\", \"Word format\"].index(default_format))\n",
    "            \n",
    "            if st.session_state.select_format == \"PPT format\":\n",
    "                # Add radio buttons for template selection here    \n",
    "                default_template = \"Blue_PLS_Template.png\"\n",
    "                selected_template = image_select(\n",
    "                    label=\"Select PPT Template\",\n",
    "                    images=[\n",
    "                        os.path.join(rootdir, 'Pfizer_Blue_PLS_Template.png'),\n",
    "                        os.path.join(rootdir, 'Pfizer_Red_PLS_Template.png'),\n",
    "                        os.path.join(rootdir, 'Pfizer_Long_PLS_Template.png'),\n",
    "                    ],\n",
    "                    captions=[\"Blue_PLS_Template\", \"Red_PLS_Template\", \"Long_PLS_Template\"],\n",
    "                    index=[\"Blue_PLS_Template.png\", \"Red_PLS_Template.png\", \"Long_PLS_Template.png\"].index(default_template),\n",
    "                    use_container_width = False,\n",
    "                )\n",
    "                #selected_template = st.radio(\"Select PPT Template\", options=[\"Blue_PLS_Template\", \"Red_PLS_Template\", \"Long_PLS_Template\"], index=[\"Blue_PLS_Template\", \"Red_PLS_Template\", \"Long_PLS_Template\"].index(default_template), horizontal=True)\n",
    "                #selected_template = pills(\"\", [\"Pfizer_Blue_PLS_Template\", \"Pfizer_Red_PLS_Template\", \"Pfizer_Long_PLS_Template\"], [\"🍀\", \"🎈\", \"🌈\"])\n",
    "            \n",
    "            if st.session_state.select_format == \"Word format\":\n",
    "                default_template = \"Word_PLS_Template\"\n",
    "                selected_template = \"Blue_PLS_Template.png\"\n",
    "                image_select(\n",
    "                    label=\"Select Word Template\",\n",
    "                    images=[\n",
    "                        os.path.join(rootdir, 'Pfizer_Word_PLS_Template.png'),\n",
    "                    ],\n",
    "                    captions=[\"Word_PLS_Template\"],\n",
    "                    index=[\"Word_PLS_Template\"].index(default_template),\n",
    "                    use_container_width = False,\n",
    "                )\n",
    "            \n",
    "            generate_ppt_button = st.button(\"Generate PLS\")\n",
    "\n",
    "            if generate_ppt_button:\n",
    "                # Retrieve the replacements dictionary from session state\n",
    "                replacements = st.session_state.replacements\n",
    "                st.session_state.process_button = False\n",
    "\n",
    "                if replacements:\n",
    "                    with st.spinner('Generating PLS slides for you...⏳'):\n",
    "                        # Call the postprocessing function to generate PPT content\n",
    "                        ppt_content = postprocess_to_ppt(replacements, selected_template)\n",
    "\n",
    "                        doc_content = postprocess_to_doc(replacements)\n",
    "\n",
    "                        # Display the PPT content using st.markdown or st.write\n",
    "                        #st.markdown(ppt_content, unsafe_allow_html=True)\n",
    "                        st.markdown(list(replacements.keys()))\n",
    "\n",
    "                        # Store the PPT content in session state\n",
    "                        st.session_state.ppt_content = ppt_content\n",
    "                        st.session_state.doc_content = doc_content\n",
    "\n",
    "                         # Step 4: PPT Download\n",
    "                        if \"ppt_content\" and \"doc_content\" in st.session_state:\n",
    "                            ppt_content = st.session_state.ppt_content\n",
    "                            doc_content = st.session_state.doc_content\n",
    "\n",
    "                            st.session_state.replacements = replacements\n",
    "                            st.session_state.process_button = False\n",
    "\n",
    "                            # Save the modified presentation object to a temporary file\n",
    "                            #ppt_output_file = f\"PLS_{replacements['<Title>']}_{datetime.now().strftime('%Y%m%d%H%M%S')}.pptx\"                    \n",
    "                            ppt_output_file = \"PLS_PPT.pptx\"\n",
    "                            #ppt_content.save(ppt_output_file)\n",
    "\n",
    "                            # save presentation as binary output\n",
    "                            binary_output = BytesIO()\n",
    "                            ppt_content.save(binary_output)\n",
    "\n",
    "                            binary_output_doc = BytesIO()\n",
    "                            doc_content.save(binary_output_doc)\n",
    "\n",
    "                            # display success message and download button\n",
    "                            st.success(':tada: The PLS template has been filled with above sections in ' + selected_template)\n",
    "\n",
    "                            # Provide the download link for the generated PPT and DOC\n",
    "                            if st.session_state.select_format == \"PPT format\":\n",
    "                                st.download_button(\"Download PLS PPT\", data=binary_output.getvalue(), file_name=ppt_output_file, mime=\"application/vnd.openxmlformats-officedocument.presentationml.presentation\")\n",
    "                            if st.session_state.select_format == \"Word format\":\n",
    "                                st.download_button(\"Download PLS Doc\", data=binary_output_doc.getvalue(), file_name=\"PLS_DOC.docx\", mime=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\")\n",
    "\n",
    "                                \n",
    "        if st.session_state.selected_tab == \"Search PubMed/CTGov\":\n",
    "            st.subheader(\"Search PubMed and ClinicalTrials.gov\")\n",
    "            query = st.text_input(\"Enter your query:\")\n",
    "            search_option = st.radio(\"Search Option\", [\"Search PubMed\", \"Search ClinicalTrials.gov\", \"Search Both\"], horizontal=True)\n",
    "\n",
    "            col1, col2 = st.columns(2)  # Split the main container into two columns\n",
    "            if query:\n",
    "                if search_option == \"Search PubMed\":\n",
    "                    pubmed_articles = search_pubmed(query)[:5]\n",
    "                    st.session_state.articles = pubmed_articles\n",
    "                    with col1:\n",
    "                        st.write(\"### PubMed Results\")\n",
    "                        display_articles(pubmed_articles)\n",
    "                    # Create a DataFrame in the second column with PubMed articles\n",
    "                    with col2:\n",
    "                        df_pubmed = pd.DataFrame(pubmed_articles)\n",
    "                        st.write(\"### PubMed DataFrame\")\n",
    "                        st.write(df_pubmed)\n",
    "\n",
    "                elif search_option == \"Search ClinicalTrials.gov\":\n",
    "                    ctgov_articles = search_ctgov(query)[:5]\n",
    "                    st.session_state.articles = ctgov_articles\n",
    "                    with col1:\n",
    "                        st.write(\"### ClinicalTrials.gov Results\")\n",
    "                        display_articles(ctgov_articles)\n",
    "                    # Create a DataFrame in the second column with ClinicalTrials.gov articles\n",
    "                    with col2:\n",
    "                        df_ctgov = pd.DataFrame(ctgov_articles)\n",
    "                        st.write(\"### ClinicalTrials.gov DataFrame\")\n",
    "                        st.write(df_ctgov)\n",
    "\n",
    "                else:  # Search Both\n",
    "                    pubmed_articles = search_pubmed(query)[:5]\n",
    "                    ctgov_articles = search_ctgov(query)[:5]\n",
    "                    st.session_state.articles = pubmed_articles + ctgov_articles\n",
    "                    with col1:\n",
    "                        st.write(\"### PubMed Results\")\n",
    "                        display_articles(pubmed_articles)\n",
    "                    with col1:  # Use the same column for ClinicalTrials.gov Results\n",
    "                        st.write(\"### ClinicalTrials.gov Results\")\n",
    "                        display_articles(ctgov_articles)\n",
    "                    # Concatenate both sets of articles and create a DataFrame in the second column\n",
    "                    with col2:\n",
    "                        combined_articles = pubmed_articles + ctgov_articles\n",
    "                        df_combined = pd.DataFrame(combined_articles)\n",
    "                        st.write(\"### Combined DataFrame\")\n",
    "                        st.write(df_combined)\n",
    "            # Placeholder for chatbot implementation in the second column\n",
    "            with col2:\n",
    "                st.write(\"Chatbot - Ask questions from only these Pubmed/CTGov articles\")\n",
    "                if 'articles' in st.session_state:      \n",
    "                    df = pd.DataFrame(st.session_state.articles)\n",
    "                    #user_prompt = st.text_area(label=\"prompt:\",placeholder=\"Number of patients..\",)\n",
    "                    #if st.button(\"Generate\"):\n",
    "                ########################################################LangChain CSV Agent (with Pandas)\n",
    "\n",
    "                    # langchain_pandas_agent = create_pandas_dataframe_agent(\n",
    "                    #     ChatOpenAI(temperature=0, model=\"gpt-4-32k\", streaming=True, ),\n",
    "                    #     df,\n",
    "                    #     verbose=True,\n",
    "                    #     agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "                    # )\n",
    "\n",
    "                    #st.write(\"Langchain pandas agent: \", langchain_pandas_agent.run(user_prompt))\n",
    "\n",
    "                    # Initialise session state variables\n",
    "                    if 'generated1' not in st.session_state:\n",
    "                        st.session_state['generated1'] = []\n",
    "                    if 'past1' not in st.session_state:\n",
    "                        st.session_state['past1'] = []\n",
    "                    if 'messages1' not in st.session_state:\n",
    "                        st.session_state['messages1'] = [\n",
    "                            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "                        ]\n",
    "\n",
    "\n",
    "                    # container for chat history\n",
    "                    response_container = st.container()\n",
    "\n",
    "                    # container for text box\n",
    "                    input_container = st.container()\n",
    "\n",
    "                    with input_container:\n",
    "                        # Create a form for user input\n",
    "                        with st.form(key='my_form', clear_on_submit=True):\n",
    "                            user_input = st.text_area(\"You:\", key='input', height=100)\n",
    "                            submit_button = st.form_submit_button(label='Send')\n",
    "\n",
    "                        if submit_button and user_input:\n",
    "                            # If user submits input, generate response and store input and response in session state variables\n",
    "                            try:\n",
    "                                query_response = generate_response1(user_input, df)\n",
    "                                st.session_state['past1'].append(user_input)\n",
    "                                st.session_state['generated1'].append(query_response)\n",
    "                            except Exception as e:\n",
    "                                st.error(\"An error occurred: {}\".format(e))\n",
    "\n",
    "                    if st.session_state['generated1']:\n",
    "                        # Display chat history in a container\n",
    "                        with response_container:\n",
    "                            for i in range(len(st.session_state['generated1'])):\n",
    "                                message(st.session_state[\"past1\"][i], is_user=True, key=str(i) + '_user')\n",
    "                                message(st.session_state[\"generated1\"][i], key=str(i))\n",
    "                        \n",
    "                        \n",
    "                        # Add a download button for the chat conversation\n",
    "                        #if st.button(\"Download Chat Conversation\"):\n",
    "                            #download_chat_conversation(st.session_state['past'], st.session_state['generated'])\n",
    "                                \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957b979-477b-4505-860d-3b994bab40b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c22926-6652-4701-9af6-ea04e1d981f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58024bc0-8de9-41ed-8cac-8401a6408ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414dffa9-1d05-4471-abea-8d58236b4ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
